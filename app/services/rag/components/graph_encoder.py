"""
å›¾ç¼–ç å™¨ (Graph Encoder)
ä¸“ä¸ºQAä»»åŠ¡è®¾è®¡çš„å›¾åˆ°å‘é‡ç¼–ç ç»„ä»¶
å°†å›¾ç»“æž„è½¬æ¢ä¸ºå¯†é›†å‘é‡è¡¨ç¤ºï¼Œç”¨äºŽComplexGProcessorçš„å¢žå¼ºæ¨¡å¼
"""
import torch
import numpy as np
from typing import Dict, Any, List, Optional, Tuple
import logging

try:
    import torch.nn.functional as F
    from torch_geometric.data import Data
    from torch_geometric.nn import GCNConv, global_mean_pool
    HAS_TORCH_GEOMETRIC = True
except ImportError:
    HAS_TORCH_GEOMETRIC = False
    # åˆ›å»ºç®€å•æ›¿ä»£Dataç±»
    class Data:
        def __init__(self, x=None, edge_index=None, edge_attr=None):
            self.x = x
            self.edge_index = edge_index
            self.edge_attr = edge_attr

logger = logging.getLogger(__name__)

# =============================================================================
# GNNæ¨¡åž‹ - ä¸“ä¸ºQAä»»åŠ¡ä¼˜åŒ–
# =============================================================================

class QAGraphEncoder(torch.nn.Module):
    """é¢å‘QAä»»åŠ¡çš„å›¾ç¼–ç å™¨"""
    
    def __init__(self, input_dim: int = 768, hidden_dim: int = 256, output_dim: int = 128):
        super().__init__()
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        
        if HAS_TORCH_GEOMETRIC:
            # ä½¿ç”¨GCNå±‚
            self.conv1 = GCNConv(input_dim, hidden_dim)
            self.conv2 = GCNConv(hidden_dim, output_dim)
            self.dropout = torch.nn.Dropout(0.2)
        else:
            # ç®€åŒ–ç‰ˆæœ¬ - çº¿æ€§å˜æ¢
            self.linear1 = torch.nn.Linear(input_dim, hidden_dim)
            self.linear2 = torch.nn.Linear(hidden_dim, output_dim)
            self.dropout = torch.nn.Dropout(0.2)
    
    def forward(self, data):
        """å‰å‘ä¼ æ’­"""
        if not HAS_TORCH_GEOMETRIC:
            # ç®€åŒ–ç‰ˆæœ¬ï¼šèŠ‚ç‚¹ç‰¹å¾çš„åŠ æƒå¹³å‡
            if hasattr(data, 'x') and data.x.size(0) > 0:
                x = self.linear1(data.x)
                x = F.relu(x)
                x = self.dropout(x)
                x = self.linear2(x)
                # è¿”å›žå›¾çº§åˆ«è¡¨ç¤º
                return torch.mean(x, dim=0)
            else:
                return torch.zeros(self.output_dim)
        
        x, edge_index = data.x, data.edge_index
        
        # ç¬¬ä¸€å±‚GCN
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = self.dropout(x)
        
        # ç¬¬äºŒå±‚GCN
        x = self.conv2(x, edge_index)
        
        # å…¨å±€æ± åŒ–èŽ·å¾—å›¾çº§åˆ«è¡¨ç¤º
        batch = torch.zeros(x.size(0), dtype=torch.long)
        graph_embedding = global_mean_pool(x, batch)
        
        return graph_embedding.squeeze()

# =============================================================================
# å›¾ç¼–ç å™¨ç»„ä»¶
# =============================================================================

class GraphEncoder:
    """å›¾ç¼–ç å™¨ç»„ä»¶ - QAä»»åŠ¡å¢žå¼º"""
    
    def __init__(self, input_dim: int = 768, hidden_dim: int = 256, 
                 output_dim: int = 128, device: str = 'cpu'):
        """åˆå§‹åŒ–å›¾ç¼–ç å™¨
        
        Args:
            input_dim: è¾“å…¥ç‰¹å¾ç»´åº¦
            hidden_dim: éšè—å±‚ç»´åº¦
            output_dim: è¾“å‡ºåµŒå…¥ç»´åº¦
            device: è®¡ç®—è®¾å¤‡
        """
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.device = device
        
        # åˆ›å»ºæ¨¡åž‹
        self.model = QAGraphEncoder(input_dim, hidden_dim, output_dim)
        self.model.to(device)
        self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
        
        self.is_initialized = False
        logger.info(f"ðŸ§  åˆ›å»ºå›¾ç¼–ç å™¨ï¼Œè¾“å‡ºç»´åº¦: {output_dim}")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–å›¾ç¼–ç å™¨"""
        try:
            logger.info("ðŸ”„ åˆå§‹åŒ–å›¾ç¼–ç å™¨...")
            
            # æ£€æŸ¥torch_geometricå¯ç”¨æ€§
            if not HAS_TORCH_GEOMETRIC:
                logger.warning("âš ï¸ torch_geometricæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆå›¾ç¼–ç å™¨")
            
            self.is_initialized = True
            logger.info("âœ… å›¾ç¼–ç å™¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ å›¾ç¼–ç å™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def encode_graph(self, graph_data, query: str = "") -> Dict[str, Any]:
        """å°†å›¾æ•°æ®ç¼–ç ä¸ºå‘é‡è¡¨ç¤º
        
        Args:
            graph_data: torch_geometric.data.Dataå¯¹è±¡æˆ–å­—å…¸æ ¼å¼çš„å›¾æ•°æ®
            query: æŸ¥è¯¢æ–‡æœ¬ï¼ˆç”¨äºŽä¸Šä¸‹æ–‡ï¼‰
            
        Returns:
            åŒ…å«å›¾åµŒå…¥çš„å­—å…¸
        """
        if not self.is_initialized:
            raise RuntimeError("å›¾ç¼–ç å™¨æœªåˆå§‹åŒ–")
        
        try:
            logger.info("ðŸ”„ å¼€å§‹å›¾ç¼–ç ...")
            
            # å¦‚æžœè¾“å…¥æ˜¯å­—å…¸ï¼Œå…ˆè½¬æ¢ä¸ºDataå¯¹è±¡
            if isinstance(graph_data, dict):
                graph_data = self._convert_subgraph_to_data(graph_data)
            
            with torch.no_grad():
                # å°†æ•°æ®ç§»åˆ°æŒ‡å®šè®¾å¤‡
                if hasattr(graph_data, 'to'):
                    graph_data = graph_data.to(self.device)
                
                # èŽ·å–å›¾åµŒå…¥
                graph_embedding = self.model(graph_data)
                
                # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
                if isinstance(graph_embedding, torch.Tensor):
                    embedding_list = graph_embedding.cpu().numpy().tolist()
                else:
                    embedding_list = graph_embedding
                
                # ç¡®ä¿æ˜¯åˆ—è¡¨æ ¼å¼
                if not isinstance(embedding_list, list):
                    embedding_list = [float(embedding_list)]
                
                result = {
                    'success': True,
                    'embedding': embedding_list,  # æ”¹ä¸ºembeddingè€Œä¸æ˜¯graph_embedding
                    'embedding_dim': len(embedding_list),
                    'embedding_shape': f"({len(embedding_list)},)",
                    'model_type': 'QAGraphEncoder',
                    'query_context': query,
                    'graph_info': {
                        'num_nodes': graph_data.x.size(0) if hasattr(graph_data, 'x') and graph_data.x is not None else 0,
                        'num_edges': graph_data.edge_index.size(1) if hasattr(graph_data, 'edge_index') and graph_data.edge_index is not None else 0,
                        'feature_dim': graph_data.x.size(1) if hasattr(graph_data, 'x') and graph_data.x is not None else 0
                    }
                }
                
                logger.info(f"âœ… å›¾ç¼–ç å®Œæˆï¼ŒåµŒå…¥ç»´åº¦: {result['embedding_dim']}")
                return result
                
        except Exception as e:
            logger.error(f"âŒ å›¾ç¼–ç å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'embedding': [],
                'embedding_dim': 0,
                'query_context': query
            }
    
    def encode_subgraph_dict(self, subgraph: Dict[str, Any], query: str = "") -> Dict[str, Any]:
        """ä»Žå­å›¾å­—å…¸ç›´æŽ¥ç¼–ç ï¼ˆä¾¿æ·æ–¹æ³•ï¼‰
        
        Args:
            subgraph: åŒ…å«nodes/edgesçš„å­å›¾å­—å…¸
            query: æŸ¥è¯¢æ–‡æœ¬
            
        Returns:
            åŒ…å«å›¾åµŒå…¥çš„å­—å…¸
        """
        try:
            # è½¬æ¢ä¸ºtorch_geometric.data.Dataæ ¼å¼
            graph_data = self._convert_subgraph_to_data(subgraph)
            
            # è¿›è¡Œç¼–ç 
            return self.encode_graph(graph_data, query)
            
        except Exception as e:
            logger.error(f"âŒ ä»Žå­å›¾å­—å…¸ç¼–ç å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'graph_embedding': [],
                'embedding_dim': 0,
                'query_context': query
            }
    
    def _convert_subgraph_to_data(self, subgraph: Dict[str, Any]) -> Data:
        """å°†å­å›¾å­—å…¸è½¬æ¢ä¸ºtorch_geometric.data.Dataæ ¼å¼"""
        nodes = subgraph.get('nodes', [])
        edges = subgraph.get('edges', [])
        
        if not nodes:
            # ç©ºå›¾æƒ…å†µ
            return Data(
                x=torch.empty((0, self.input_dim)),
                edge_index=torch.empty((2, 0), dtype=torch.long),
                edge_attr=None
            )
        
        # æž„å»ºèŠ‚ç‚¹æ˜ å°„
        node_mapping = {node['id']: i for i, node in enumerate(nodes)}
        
        # æž„å»ºèŠ‚ç‚¹ç‰¹å¾
        node_features = []
        for node in nodes:
            # åˆ›å»ºç®€å•ç‰¹å¾å‘é‡
            feature_vector = torch.zeros(self.input_dim)
            
            # èŠ‚ç‚¹ç±»åž‹ç¼–ç 
            node_type = node.get('type', 'unknown')
            if node_type == 'player':
                feature_vector[0] = 1.0
                # å¹´é¾„ç‰¹å¾
                age = node.get('age', 0)
                feature_vector[1] = float(age) / 100.0 if age else 0.0
            elif node_type == 'team':
                feature_vector[2] = 1.0
            
            node_features.append(feature_vector)
        
        # æž„å»ºè¾¹ç´¢å¼•
        edge_list = []
        for edge in edges:
            source = edge.get('source', '')
            target = edge.get('target', '')
            
            if source in node_mapping and target in node_mapping:
                source_idx = node_mapping[source]
                target_idx = node_mapping[target]
                
                # æ·»åŠ åŒå‘è¾¹
                edge_list.append([source_idx, target_idx])
                edge_list.append([target_idx, source_idx])
        
        # è½¬æ¢ä¸ºtensor
        x = torch.stack(node_features) if node_features else torch.empty((0, self.input_dim))
        edge_index = torch.LongTensor(edge_list).t().contiguous() if edge_list else torch.empty((2, 0), dtype=torch.long)
        
        return Data(x=x, edge_index=edge_index, edge_attr=None)
    
    def get_config(self) -> Dict[str, Any]:
        """èŽ·å–ç¼–ç å™¨é…ç½®"""
        return {
            'input_dim': self.input_dim,
            'hidden_dim': self.hidden_dim,
            'output_dim': self.output_dim,
            'device': self.device,
            'torch_geometric_available': HAS_TORCH_GEOMETRIC,
            'is_initialized': self.is_initialized
        }
    
    def get_stats(self) -> Dict[str, Any]:
        """èŽ·å–ç¼–ç å™¨ç»Ÿè®¡ä¿¡æ¯"""
        return {
            'model_params': {
                'input_dim': self.input_dim,
                'hidden_dim': self.hidden_dim,
                'output_dim': self.output_dim
            },
            'device': self.device,
            'torch_geometric_available': HAS_TORCH_GEOMETRIC,
            'is_initialized': self.is_initialized
        }

# =============================================================================
# å·¥åŽ‚å‡½æ•°
# =============================================================================

def create_graph_encoder(config: Optional[Dict[str, Any]] = None) -> GraphEncoder:
    """åˆ›å»ºå›¾ç¼–ç å™¨å®žä¾‹
    
    Args:
        config: é…ç½®å­—å…¸ï¼Œå¯ä»¥åŒ…å«model_configç­‰åµŒå¥—é…ç½®
        
    Returns:
        GraphEncoderå®žä¾‹
    """
    if config is None:
        config = {}
    
    # æ”¯æŒåµŒå¥—é…ç½®ç»“æž„
    model_config = config.get('model_config', config)
    
    return GraphEncoder(
        input_dim=model_config.get('input_dim', 768),
        hidden_dim=model_config.get('hidden_dim', 256),
        output_dim=model_config.get('output_dim', 128),
        device=config.get('device', 'cpu')
    )

# =============================================================================
# æ•°æ®ç»“æž„å®šä¹‰ - MultimodalContext
# =============================================================================

class MultimodalContext:
    """å¤šæ¨¡æ€ä¸Šä¸‹æ–‡æ•°æ®ç»“æž„ - åŒ…å«æ–‡æœ¬å’Œå›¾åµŒå…¥"""
    
    def __init__(self, text_context: str, graph_embedding: List[float], 
                 metadata: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
        
        Args:
            text_context: æ–‡æœ¬ä¸Šä¸‹æ–‡
            graph_embedding: å›¾åµŒå…¥å‘é‡
            metadata: å…ƒæ•°æ®ä¿¡æ¯
        """
        self.text_context = text_context
        self.graph_embedding = graph_embedding
        self.metadata = metadata or {}
        
        # éªŒè¯æ•°æ®
        if not isinstance(text_context, str):
            raise ValueError("text_contextå¿…é¡»æ˜¯å­—ç¬¦ä¸²")
        if not isinstance(graph_embedding, list):
            raise ValueError("graph_embeddingå¿…é¡»æ˜¯åˆ—è¡¨")
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'text_context': self.text_context,
            'graph_embedding': self.graph_embedding,
            'embedding_dim': len(self.graph_embedding),
            'metadata': self.metadata,
            'modalities': ['text', 'graph'],
            'format_version': '1.0'
        }
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'MultimodalContext':
        """ä»Žå­—å…¸åˆ›å»ºå®žä¾‹"""
        return cls(
            text_context=data['text_context'],
            graph_embedding=data['graph_embedding'],
            metadata=data.get('metadata', {})
        )
    
    def get_combined_representation(self) -> Dict[str, Any]:
        """èŽ·å–ç»„åˆè¡¨ç¤ºï¼ˆä¸ºLLMå‡†å¤‡ï¼‰"""
        return {
            'context_text': self.text_context,
            'graph_features': {
                'embedding': self.graph_embedding,
                'dimension': len(self.graph_embedding),
                'summary': f"å›¾ç»“æž„åµŒå…¥ï¼ˆ{len(self.graph_embedding)}ç»´å‘é‡ï¼‰"
            },
            'integration_info': {
                'modality_count': 2,
                'text_length': len(self.text_context),
                'graph_dim': len(self.graph_embedding)
            },
            'metadata': self.metadata
        }
    
    def __str__(self) -> str:
        """å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"MultimodalContext(text_len={len(self.text_context)}, graph_dim={len(self.graph_embedding)})"
    
    def __repr__(self) -> str:
        """è¯¦ç»†å­—ç¬¦ä¸²è¡¨ç¤º"""
        return f"MultimodalContext(text_context='{self.text_context[:50]}...', graph_embedding_dim={len(self.graph_embedding)}, metadata={self.metadata})"
