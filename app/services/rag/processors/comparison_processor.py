"""
æ¯”è¾ƒæŸ¥è¯¢å¤„ç†å™¨ (Comparison Processor)
ç”¨äºå¤„ç† COMPARATIVE_QUERY ç±»å‹çš„æŸ¥è¯¢
é€‚ç”¨äºæ¯”è¾ƒç±»æŸ¥è¯¢ï¼Œå¦‚"ç§‘æ¯”å’Œè©¹å§†æ–¯è°æ›´å¼º"ã€"æ¹–äººå’Œå‹‡å£«å“ªä¸ªé˜Ÿæ›´å¥½"
"""
from typing import Dict, Any, Optional, List, Tuple
import logging
from .base_processor import BaseProcessor, ProcessorUtils
from app.rag.components import ProcessorDefaultConfigs

logger = logging.getLogger(__name__)

class ComparisonProcessor(BaseProcessor):
    """æ¯”è¾ƒæŸ¥è¯¢å¤„ç†å™¨"""
    
    def __init__(self, config: Optional[ProcessorDefaultConfigs] = None):
        """åˆå§‹åŒ–æ¯”è¾ƒæŸ¥è¯¢å¤„ç†å™¨"""
        if config is None:
            config = ProcessorDefaultConfigs.get_comparison_processor_config()
        
        super().__init__(config)
        logger.info(f"âš–ï¸ åˆ›å»ºæ¯”è¾ƒæŸ¥è¯¢å¤„ç†å™¨")
    
    def _process_impl(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """å¤„ç†æ¯”è¾ƒæŸ¥è¯¢"""
        logger.info(f"ğŸ” æ¯”è¾ƒæŸ¥è¯¢å¤„ç†: {query}")
        
        try:
            # 1. æ¯”è¾ƒæŸ¥è¯¢åˆ†æ
            query_analysis = self._analyze_comparison_query(query, context)
            
            # 2. åˆ†åˆ«æ£€ç´¢æ¯”è¾ƒå®ä½“
            comparison_entities = query_analysis.get('comparison_entities', [])
            entity_nodes = self._retrieve_comparison_entities(query, comparison_entities)
            
            if not entity_nodes:
                return self._create_empty_result(query, "No comparable entities found")
            
            # 3. æ„å»ºæ¯”è¾ƒå­å›¾
            all_seed_nodes = []
            for entity_group in entity_nodes.values():
                all_seed_nodes.extend([node['node_id'] for node in entity_group[:3]])
            
            subgraph = self.graph_builder.build_subgraph(all_seed_nodes, query)
            
            if not ProcessorUtils.validate_subgraph(subgraph):
                return self._create_fallback_result(query, entity_nodes)
            
            # 4. æ‰§è¡Œæ¯”è¾ƒåˆ†æ
            comparison_analysis = self._perform_comparison_analysis(
                subgraph, entity_nodes, query_analysis
            )
            
            # 5. ç”Ÿæˆæ¯”è¾ƒæ–‡æœ¬
            comparison_text = self._generate_comparison_text(
                comparison_analysis, query_analysis, subgraph
            )
            
            # 6. é™åˆ¶tokenæ•°é‡
            final_text = ProcessorUtils.limit_tokens(
                comparison_text, 
                self.config.max_tokens
            )
            
            # 7. æ„å»ºç»“æœ
            result = {
                'success': True,
                'query': query,
                'context': context or {},
                'query_analysis': query_analysis,
                'comparison_entities': list(entity_nodes.keys()),
                'entity_nodes_count': sum(len(nodes) for nodes in entity_nodes.values()),
                'subgraph_summary': {
                    'nodes': subgraph['node_count'],
                    'edges': subgraph['edge_count'],
                    'algorithm': subgraph.get('algorithm', 'pcst')
                },
                'comparison_analysis': comparison_analysis,
                'contextualized_text': final_text,
                'processing_strategy': 'comparative_analysis',
                'confidence': self._calculate_confidence(entity_nodes, comparison_analysis)
            }
            
            logger.info(f"âœ… æ¯”è¾ƒæŸ¥è¯¢å¤„ç†å®Œæˆï¼Œæ¯”è¾ƒå®ä½“æ•°: {len(entity_nodes)}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ æ¯”è¾ƒæŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            raise
    
    def _analyze_comparison_query(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææ¯”è¾ƒæŸ¥è¯¢"""
        analysis = {
            'query_type': 'comparative_query',
            'comparison_type': self._detect_comparison_type(query),
            'comparison_entities': self._extract_comparison_entities(query),
            'comparison_aspects': self._extract_comparison_aspects(query),
            'comparison_pattern': self._detect_comparison_pattern(query)
        }
        
        # åˆ†æä¸Šä¸‹æ–‡
        if context:
            analysis['context_entities'] = context.get('entities', [])
            analysis['context_comparisons'] = context.get('comparisons', [])
        
        return analysis
    
    def _detect_comparison_type(self, query: str) -> str:
        """æ£€æµ‹æ¯”è¾ƒç±»å‹"""
        query_lower = query.lower()
        
        # ä¼˜åŠ£æ¯”è¾ƒ
        if any(word in query for word in ['æ›´å¥½', 'æ›´å¼º', 'æ›´å‰å®³', 'è°æ›´', 'å“ªä¸ªæ›´']):
            return 'superiority'
        
        # ç›¸ä¼¼æ€§æ¯”è¾ƒ
        elif any(word in query for word in ['ç›¸ä¼¼', 'ç±»ä¼¼', 'å·®ä¸å¤š', 'åƒ']):
            return 'similarity'
        
        # å·®å¼‚æ¯”è¾ƒ
        elif any(word in query for word in ['ä¸åŒ', 'åŒºåˆ«', 'å·®å¼‚', 'å¯¹æ¯”']):
            return 'difference'
        
        # æ•°é‡æ¯”è¾ƒ
        elif any(word in query for word in ['å¤šå°‘', 'å“ªä¸ªå¤š', 'å“ªä¸ªå°‘', 'æ›´å¤š']):
            return 'quantity'
        
        # æ’åæ¯”è¾ƒ
        elif any(word in query for word in ['æ’å', 'æ’è¡Œ', 'ç¬¬ä¸€', 'æœ€å¥½']):
            return 'ranking'
        
        return 'general'
    
    def _extract_comparison_entities(self, query: str) -> List[str]:
        """æå–æ¯”è¾ƒå®ä½“"""
        entities = []
        
        # ç®€å•çš„å®ä½“æå–é€»è¾‘
        # æŸ¥æ‰¾è¿æ¥è¯åˆ†éš”çš„å®ä½“
        conjunctions = ['å’Œ', 'ä¸', 'è·Ÿ', 'è¿˜æ˜¯', 'æˆ–è€…']
        
        for conjunction in conjunctions:
            if conjunction in query:
                parts = query.split(conjunction)
                if len(parts) == 2:
                    # å°è¯•ä»æ¯éƒ¨åˆ†æå–å®ä½“åç§°
                    entity1 = self._extract_entity_from_text(parts[0])
                    entity2 = self._extract_entity_from_text(parts[1])
                    
                    if entity1:
                        entities.append(entity1)
                    if entity2:
                        entities.append(entity2)
                    break
        
        return entities
    
    def _extract_entity_from_text(self, text: str) -> Optional[str]:
        """ä»æ–‡æœ¬ä¸­æå–å®ä½“åç§°"""
        # ç®€å•çš„å®ä½“æå–ï¼ˆå¯ä»¥åç»­æ”¹è¿›ï¼‰
        text = text.strip()
        
        # å¸¸è§çƒå‘˜åç§°
        player_names = ['ç§‘æ¯”', 'è©¹å§†æ–¯', 'ä¹”ä¸¹', 'åº“é‡Œ', 'æœå…°ç‰¹', 'å¨å°‘', 'å“ˆç™»']
        for name in player_names:
            if name in text:
                return name
        
        # å¸¸è§çƒé˜Ÿåç§°
        team_names = ['æ¹–äºº', 'å‹‡å£«', 'å…¬ç‰›', 'é©¬åˆº', 'éª‘å£«', 'çƒ­ç«', 'å‡¯å°”ç‰¹äºº']
        for name in team_names:
            if name in text:
                return name
        
        # æå–å¯èƒ½çš„å®ä½“ï¼ˆä¸­æ–‡å­—ç¬¦åºåˆ—ï¼‰
        import re
        chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
        matches = chinese_pattern.findall(text)
        
        if matches:
            # è¿”å›æœ€é•¿çš„åŒ¹é…
            return max(matches, key=len)
        
        return None
    
    def _extract_comparison_aspects(self, query: str) -> List[str]:
        """æå–æ¯”è¾ƒæ–¹é¢"""
        aspects = []
        query_lower = query.lower()
        
        # æŠ€èƒ½æ–¹é¢
        if any(word in query for word in ['å¾—åˆ†', 'æŠ•ç¯®', 'è¿›æ”»']):
            aspects.append('scoring')
        if any(word in query for word in ['é˜²å®ˆ', 'é˜²å®ˆèƒ½åŠ›']):
            aspects.append('defense')
        if any(word in query for word in ['åŠ©æ”»', 'ä¼ çƒ']):
            aspects.append('assists')
        if any(word in query for word in ['ç¯®æ¿']):
            aspects.append('rebounds')
        
        # èŒä¸šæ–¹é¢
        if any(word in query for word in ['å† å†›', 'æ€»å† å†›']):
            aspects.append('championships')
        if any(word in query for word in ['MVP', 'æœ€æœ‰ä»·å€¼çƒå‘˜']):
            aspects.append('mvp')
        if any(word in query for word in ['å¹´é¾„', 'å²æ•°']):
            aspects.append('age')
        
        # çƒé˜Ÿæ–¹é¢
        if any(word in query for word in ['æˆ˜ç»©', 'èƒœç‡']):
            aspects.append('record')
        if any(word in query for word in ['çƒå‘˜', 'é˜µå®¹']):
            aspects.append('roster')
        
        return aspects if aspects else ['overall']
    
    def _detect_comparison_pattern(self, query: str) -> Dict[str, Any]:
        """æ£€æµ‹æ¯”è¾ƒæ¨¡å¼"""
        pattern = {
            'pattern_type': 'binary',  # binary, multiple, ranking
            'comparison_direction': 'neutral',  # positive, negative, neutral
            'expectation': 'objective'  # objective, subjective
        }
        
        # æ£€æµ‹æ¨¡å¼ç±»å‹
        if any(word in query for word in ['æ’å', 'æ’è¡Œ', 'å‰å‡ ', 'æœ€å¥½çš„']):
            pattern['pattern_type'] = 'ranking'
        elif len(self._extract_comparison_entities(query)) > 2:
            pattern['pattern_type'] = 'multiple'
        
        # æ£€æµ‹æ¯”è¾ƒæ–¹å‘
        if any(word in query for word in ['æ›´å¥½', 'æ›´å¼º', 'æ›´å‰å®³']):
            pattern['comparison_direction'] = 'positive'
        elif any(word in query for word in ['æ›´å·®', 'ä¸å¦‚', 'è¾ƒå¼±']):
            pattern['comparison_direction'] = 'negative'
        
        # æ£€æµ‹æœŸæœ›ç±»å‹
        if any(word in query for word in ['æˆ‘è§‰å¾—', 'æˆ‘è®¤ä¸º', 'ä¸ªäººè®¤ä¸º']):
            pattern['expectation'] = 'subjective'
        
        return pattern
    
    def _retrieve_comparison_entities(self, query: str, entities: List[str]) -> Dict[str, List[Dict]]:
        """æ£€ç´¢æ¯”è¾ƒå®ä½“"""
        entity_nodes = {}
        
        if not entities:
            # å¦‚æœæ²¡æœ‰æ˜ç¡®å®ä½“ï¼Œä½¿ç”¨æ•´ä¸ªæŸ¥è¯¢æ£€ç´¢
            all_nodes = self.retriever.retrieve(query, top_k=10)
            entity_nodes['general'] = all_nodes
        else:
            # ä¸ºæ¯ä¸ªå®ä½“å•ç‹¬æ£€ç´¢
            for entity in entities:
                entity_query = f"{entity} {query}"
                nodes = self.retriever.retrieve(entity_query, top_k=6)
                if nodes:
                    entity_nodes[entity] = nodes
        
        return entity_nodes
    
    def _perform_comparison_analysis(self, subgraph: Dict[str, Any], 
                                   entity_nodes: Dict[str, List[Dict]], 
                                   query_analysis: Dict[str, Any]) -> Dict[str, Any]:
        """æ‰§è¡Œæ¯”è¾ƒåˆ†æ"""
        analysis = {
            'entity_profiles': {},
            'comparison_metrics': {},
            'similarity_analysis': {},
            'difference_analysis': {},
            'conclusion': ''
        }
        
        # æ„å»ºå®ä½“æ¡£æ¡ˆ
        for entity_name, nodes in entity_nodes.items():
            profile = self._build_entity_profile(entity_name, nodes, subgraph)
            analysis['entity_profiles'][entity_name] = profile
        
        # è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡
        if len(entity_nodes) >= 2:
            analysis['comparison_metrics'] = self._calculate_comparison_metrics(
                analysis['entity_profiles']
            )
            
            analysis['similarity_analysis'] = self._analyze_similarities(
                analysis['entity_profiles']
            )
            
            analysis['difference_analysis'] = self._analyze_differences(
                analysis['entity_profiles']
            )
            
            analysis['conclusion'] = self._generate_comparison_conclusion(
                analysis, query_analysis
            )
        
        return analysis
    
    def _build_entity_profile(self, entity_name: str, nodes: List[Dict], 
                            subgraph: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºå®ä½“æ¡£æ¡ˆ"""
        profile = {
            'name': entity_name,
            'type': 'unknown',
            'attributes': {},
            'connections': [],
            'importance_score': 0.0
        }
        
        # åˆ†æèŠ‚ç‚¹ç±»å‹å’Œå±æ€§
        entity_nodes = [n for n in nodes if entity_name in n.get('name', '')]
        
        if entity_nodes:
            primary_node = entity_nodes[0]
            profile['type'] = primary_node.get('type', 'unknown')
            profile['attributes'] = primary_node.get('properties', {})
            profile['importance_score'] = primary_node.get('similarity', 0.0)
        
        # åˆ†æè¿æ¥
        subgraph_edges = subgraph.get('edges', [])
        for edge in subgraph_edges:
            if entity_name in edge.get('source', '') or entity_name in edge.get('target', ''):
                connection = {
                    'relation': edge.get('relation', 'unknown'),
                    'target': edge.get('target', '') if entity_name in edge.get('source', '') else edge.get('source', ''),
                    'weight': edge.get('weight', 1.0)
                }
                profile['connections'].append(connection)
        
        return profile
    
    def _calculate_comparison_metrics(self, entity_profiles: Dict[str, Dict]) -> Dict[str, Any]:
        """è®¡ç®—æ¯”è¾ƒæŒ‡æ ‡"""
        metrics = {
            'attribute_comparison': {},
            'connection_comparison': {},
            'overall_scores': {}
        }
        
        entity_names = list(entity_profiles.keys())
        
        # å±æ€§æ¯”è¾ƒ
        for entity_name, profile in entity_profiles.items():
            attributes = profile.get('attributes', {})
            
            # æ•°å€¼å±æ€§æ¯”è¾ƒ
            for attr_name, attr_value in attributes.items():
                if isinstance(attr_value, (int, float)):
                    if attr_name not in metrics['attribute_comparison']:
                        metrics['attribute_comparison'][attr_name] = {}
                    metrics['attribute_comparison'][attr_name][entity_name] = attr_value
        
        # è¿æ¥åº¦æ¯”è¾ƒ
        for entity_name, profile in entity_profiles.items():
            connection_count = len(profile.get('connections', []))
            metrics['connection_comparison'][entity_name] = connection_count
        
        # æ•´ä½“åˆ†æ•°
        for entity_name, profile in entity_profiles.items():
            overall_score = (
                profile.get('importance_score', 0.0) * 0.4 +
                len(profile.get('connections', [])) * 0.3 +
                len(profile.get('attributes', {})) * 0.3
            )
            metrics['overall_scores'][entity_name] = overall_score
        
        return metrics
    
    def _analyze_similarities(self, entity_profiles: Dict[str, Dict]) -> Dict[str, Any]:
        """åˆ†æç›¸ä¼¼æ€§"""
        similarities = {
            'common_attributes': [],
            'common_connections': [],
            'similarity_score': 0.0
        }
        
        entity_names = list(entity_profiles.keys())
        if len(entity_names) < 2:
            return similarities
        
        # æŸ¥æ‰¾å…±åŒå±æ€§
        all_attributes = []
        for profile in entity_profiles.values():
            all_attributes.append(set(profile.get('attributes', {}).keys()))
        
        if all_attributes:
            common_attrs = set.intersection(*all_attributes)
            similarities['common_attributes'] = list(common_attrs)
        
        # æŸ¥æ‰¾å…±åŒè¿æ¥
        all_connections = []
        for profile in entity_profiles.values():
            connections = set(conn.get('target', '') for conn in profile.get('connections', []))
            all_connections.append(connections)
        
        if all_connections:
            common_connections = set.intersection(*all_connections)
            similarities['common_connections'] = list(common_connections)
        
        # è®¡ç®—ç›¸ä¼¼åº¦åˆ†æ•°
        similarity_factors = [
            len(similarities['common_attributes']) * 0.4,
            len(similarities['common_connections']) * 0.6
        ]
        similarities['similarity_score'] = sum(similarity_factors) / 10  # å½’ä¸€åŒ–
        
        return similarities
    
    def _analyze_differences(self, entity_profiles: Dict[str, Dict]) -> Dict[str, Any]:
        """åˆ†æå·®å¼‚"""
        differences = {
            'unique_attributes': {},
            'unique_connections': {},
            'attribute_differences': {},
            'difference_score': 0.0
        }
        
        entity_names = list(entity_profiles.keys())
        
        # æŸ¥æ‰¾ç‹¬ç‰¹å±æ€§
        for entity_name, profile in entity_profiles.items():
            attributes = set(profile.get('attributes', {}).keys())
            
            other_attributes = set()
            for other_name, other_profile in entity_profiles.items():
                if other_name != entity_name:
                    other_attributes.update(other_profile.get('attributes', {}).keys())
            
            unique_attrs = attributes - other_attributes
            differences['unique_attributes'][entity_name] = list(unique_attrs)
        
        # æŸ¥æ‰¾ç‹¬ç‰¹è¿æ¥
        for entity_name, profile in entity_profiles.items():
            connections = set(conn.get('target', '') for conn in profile.get('connections', []))
            
            other_connections = set()
            for other_name, other_profile in entity_profiles.items():
                if other_name != entity_name:
                    other_connections.update(
                        conn.get('target', '') for conn in other_profile.get('connections', [])
                    )
            
            unique_connections = connections - other_connections
            differences['unique_connections'][entity_name] = list(unique_connections)
        
        # å±æ€§å€¼å·®å¼‚
        for entity_name, profile in entity_profiles.items():
            attributes = profile.get('attributes', {})
            for attr_name, attr_value in attributes.items():
                if isinstance(attr_value, (int, float)):
                    if attr_name not in differences['attribute_differences']:
                        differences['attribute_differences'][attr_name] = {}
                    differences['attribute_differences'][attr_name][entity_name] = attr_value
        
        # è®¡ç®—å·®å¼‚åˆ†æ•°
        total_unique_attrs = sum(len(attrs) for attrs in differences['unique_attributes'].values())
        total_unique_connections = sum(len(conns) for conns in differences['unique_connections'].values())
        
        differences['difference_score'] = (total_unique_attrs * 0.4 + total_unique_connections * 0.6) / 10
        
        return differences
    
    def _generate_comparison_conclusion(self, analysis: Dict[str, Any], 
                                      query_analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¯”è¾ƒç»“è®º"""
        comparison_type = query_analysis.get('comparison_type', 'general')
        entity_profiles = analysis.get('entity_profiles', {})
        metrics = analysis.get('comparison_metrics', {})
        
        if len(entity_profiles) < 2:
            return "éœ€è¦è‡³å°‘ä¸¤ä¸ªå®ä½“è¿›è¡Œæ¯”è¾ƒã€‚"
        
        entity_names = list(entity_profiles.keys())
        
        if comparison_type == 'superiority':
            # ä¼˜åŠ£æ¯”è¾ƒ
            overall_scores = metrics.get('overall_scores', {})
            if overall_scores:
                best_entity = max(overall_scores, key=overall_scores.get)
                return f"åŸºäºç»¼åˆåˆ†æï¼Œ{best_entity} åœ¨ç›¸å…³æŒ‡æ ‡ä¸Šè¡¨ç°æ›´å¥½ã€‚"
        
        elif comparison_type == 'similarity':
            # ç›¸ä¼¼æ€§æ¯”è¾ƒ
            similarity_analysis = analysis.get('similarity_analysis', {})
            similarity_score = similarity_analysis.get('similarity_score', 0.0)
            
            if similarity_score > 0.5:
                return f"{' å’Œ '.join(entity_names)} æœ‰è¾ƒå¤šç›¸ä¼¼ä¹‹å¤„ã€‚"
            else:
                return f"{' å’Œ '.join(entity_names)} å·®å¼‚è¾ƒå¤§ã€‚"
        
        elif comparison_type == 'difference':
            # å·®å¼‚æ¯”è¾ƒ
            difference_analysis = analysis.get('difference_analysis', {})
            difference_score = difference_analysis.get('difference_score', 0.0)
            
            if difference_score > 0.5:
                return f"{' å’Œ '.join(entity_names)} åœ¨å¤šä¸ªæ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚ã€‚"
            else:
                return f"{' å’Œ '.join(entity_names)} æ¯”è¾ƒç›¸ä¼¼ã€‚"
        
        return f"å·²å®Œæˆ {' å’Œ '.join(entity_names)} çš„æ¯”è¾ƒåˆ†æã€‚"
    
    def _generate_comparison_text(self, comparison_analysis: Dict[str, Any], 
                                query_analysis: Dict[str, Any], 
                                subgraph: Dict[str, Any]) -> str:
        """ç”Ÿæˆæ¯”è¾ƒæ–‡æœ¬"""
        text_parts = []
        text_parts.append("=== æ¯”è¾ƒåˆ†æç»“æœ ===")
        
        entity_profiles = comparison_analysis.get('entity_profiles', {})
        
        # å®ä½“æ¦‚è¿°
        if entity_profiles:
            text_parts.append("\n## æ¯”è¾ƒå®ä½“:")
            for entity_name, profile in entity_profiles.items():
                entity_type = profile.get('type', 'æœªçŸ¥')
                text_parts.append(f"- {entity_name} ({entity_type})")
        
        # æ¯”è¾ƒæŒ‡æ ‡
        metrics = comparison_analysis.get('comparison_metrics', {})
        if metrics.get('overall_scores'):
            text_parts.append("\n## ç»¼åˆè¯„åˆ†:")
            for entity_name, score in metrics['overall_scores'].items():
                text_parts.append(f"- {entity_name}: {score:.2f}")
        
        # ç›¸ä¼¼æ€§åˆ†æ
        similarity_analysis = comparison_analysis.get('similarity_analysis', {})
        if similarity_analysis.get('common_attributes'):
            text_parts.append(f"\n## å…±åŒç‰¹å¾:")
            for attr in similarity_analysis['common_attributes']:
                text_parts.append(f"- {attr}")
        
        # å·®å¼‚åˆ†æ
        difference_analysis = comparison_analysis.get('difference_analysis', {})
        if difference_analysis.get('unique_attributes'):
            text_parts.append(f"\n## ç‹¬ç‰¹ç‰¹å¾:")
            for entity_name, unique_attrs in difference_analysis['unique_attributes'].items():
                if unique_attrs:
                    text_parts.append(f"- {entity_name}: {', '.join(unique_attrs)}")
        
        # ç»“è®º
        conclusion = comparison_analysis.get('conclusion', '')
        if conclusion:
            text_parts.append(f"\n## ç»“è®º:")
            text_parts.append(conclusion)
        
        return "\n".join(text_parts)
    
    def _create_empty_result(self, query: str, reason: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'success': True,
            'query': query,
            'context': {},
            'query_analysis': {'query_type': 'comparative_query'},
            'comparison_entities': [],
            'entity_nodes_count': 0,
            'subgraph_summary': {'nodes': 0, 'edges': 0, 'algorithm': 'none'},
            'comparison_analysis': {'entity_profiles': {}, 'conclusion': ''},
            'contextualized_text': f"Sorry, {reason}. Please provide specific comparison objects.",
            'processing_strategy': 'comparative_analysis',
            'confidence': 0.0,
            'empty_reason': reason
        }
    
    def _create_fallback_result(self, query: str, entity_nodes: Dict[str, List[Dict]]) -> Dict[str, Any]:
        """åˆ›å»ºå›é€€ç»“æœ"""
        fallback_text = self._format_comparison_fallback(entity_nodes, query)
        
        return {
            'success': True,
            'query': query,
            'context': {},
            'query_analysis': {'query_type': 'comparative_query'},
            'comparison_entities': list(entity_nodes.keys()),
            'entity_nodes_count': sum(len(nodes) for nodes in entity_nodes.values()),
            'subgraph_summary': {'nodes': 0, 'edges': 0, 'algorithm': 'fallback'},
            'comparison_analysis': {'entity_profiles': {}, 'conclusion': ''},
            'contextualized_text': fallback_text,
            'processing_strategy': 'comparative_analysis_fallback',
            'confidence': 0.6
        }
    
    def _format_comparison_fallback(self, entity_nodes: Dict[str, List[Dict]], query: str) -> str:
        """æ ¼å¼åŒ–æ¯”è¾ƒå›é€€ç»“æœ"""
        text_parts = ["åŸºäºæ£€ç´¢ç»“æœçš„ç®€å•æ¯”è¾ƒï¼š"]
        
        for entity_name, nodes in entity_nodes.items():
            if nodes:
                text_parts.append(f"\n{entity_name}:")
                for node in nodes[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ªèŠ‚ç‚¹
                    name = node.get('name', 'æœªçŸ¥')
                    node_type = node.get('type', 'æœªçŸ¥')
                    text_parts.append(f"  - {name} ({node_type})")
        
        text_parts.append("\næ³¨ï¼šéœ€è¦æ›´å®Œæ•´çš„å›¾ç»“æ„è¿›è¡Œè¯¦ç»†æ¯”è¾ƒã€‚")
        
        return "\n".join(text_parts)
    
    def _calculate_confidence(self, entity_nodes: Dict[str, List[Dict]], 
                            comparison_analysis: Dict[str, Any]) -> float:
        """è®¡ç®—ç»“æœç½®ä¿¡åº¦"""
        if not entity_nodes:
            return 0.0
        
        # åŸºç¡€ç½®ä¿¡åº¦
        base_confidence = 0.55
        
        # å®ä½“æ•°é‡åŠ æˆ
        entity_count = len(entity_nodes)
        if entity_count >= 2:
            entity_bonus = min(0.2, entity_count * 0.1)
        else:
            entity_bonus = -0.2  # ç¼ºå°‘æ¯”è¾ƒå¯¹è±¡
        
        # æ£€ç´¢è´¨é‡åŠ æˆ
        all_similarities = []
        for nodes in entity_nodes.values():
            similarities = [node.get('similarity', 0) for node in nodes]
            all_similarities.extend(similarities)
        
        if all_similarities:
            avg_similarity = sum(all_similarities) / len(all_similarities)
            similarity_bonus = avg_similarity * 0.15
        else:
            similarity_bonus = 0
        
        # æ¯”è¾ƒåˆ†æå®Œæ•´æ€§åŠ æˆ
        analysis_bonus = 0
        if comparison_analysis.get('entity_profiles'):
            analysis_bonus += 0.1
        if comparison_analysis.get('conclusion'):
            analysis_bonus += 0.1
        
        total_confidence = base_confidence + entity_bonus + similarity_bonus + analysis_bonus
        return min(1.0, max(0.0, total_confidence))

# =============================================================================
# å·¥å‚å‡½æ•°
# =============================================================================

def create_comparison_processor(custom_config: Optional[Dict[str, Any]] = None) -> ComparisonProcessor:
    """åˆ›å»ºæ¯”è¾ƒæŸ¥è¯¢å¤„ç†å™¨å®ä¾‹"""
    if custom_config:
        config = ProcessorDefaultConfigs.get_comparison_processor_config()
        
        # æ›´æ–°é…ç½®
        if 'retriever' in custom_config:
            config.retriever_config.config.update(custom_config['retriever'])
        if 'graph_builder' in custom_config:
            config.graph_builder_config.config.update(custom_config['graph_builder'])
        if 'textualizer' in custom_config:
            config.textualizer_config.config.update(custom_config['textualizer'])
        
        for key in ['cache_enabled', 'cache_ttl', 'max_tokens']:
            if key in custom_config:
                setattr(config, key, custom_config[key])
        
        return ComparisonProcessor(config)
    else:
        return ComparisonProcessor()
