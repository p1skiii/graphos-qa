"""
LLMå·¥å‚ç±»
æä¾›ç»Ÿä¸€çš„LLMç»„ä»¶åˆ›å»ºå’Œç®¡ç†æ¥å£
æ”¯æŒä¸åŒé…ç½®å’Œä½¿ç”¨åœºæ™¯
"""
import logging
from typing import Dict, Any, Optional, List, Type, Union
from dataclasses import dataclass

from .config import LLMConfig, Phi3Config, get_macos_optimized_config, get_default_llm_config
from .llm_engine import LLMEngine, create_llm_engine
from .input_router import InputRouter, LLMInputConfig, create_input_router
from .prompt_templates import PromptTemplateManager, create_prompt_template_manager
from .response_formatter import ResponseFormatter, create_response_formatter

logger = logging.getLogger(__name__)

@dataclass
class LLMSystemConfig:
    """LLMç³»ç»Ÿæ€»é…ç½®"""
    llm_config: LLMConfig
    input_config: LLMInputConfig
    formatter_config: Dict[str, Any]
    auto_load_model: bool = False
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'llm_config': self.llm_config.to_dict(),
            'input_config': {
                'processor_type': self.input_config.processor_type,
                'enable_multimodal': self.input_config.enable_multimodal,
                'max_tokens': self.input_config.max_tokens,
                'include_metadata': self.input_config.include_metadata
            },
            'formatter_config': self.formatter_config,
            'auto_load_model': self.auto_load_model
        }

class LLMSystem:
    """å®Œæ•´çš„LLMç³»ç»Ÿ"""
    
    def __init__(self, config: LLMSystemConfig):
        """åˆå§‹åŒ–LLMç³»ç»Ÿ"""
        self.config = config
        
        # æ ¸å¿ƒç»„ä»¶
        self.engine: Optional[LLMEngine] = None
        self.input_router: Optional[InputRouter] = None
        self.prompt_manager: Optional[PromptTemplateManager] = None
        self.response_formatter: Optional[ResponseFormatter] = None
        
        # çŠ¶æ€
        self.is_initialized = False
        self.is_ready = False
        
        logger.info("ğŸ—ï¸ LLMSystemåˆå§‹åŒ–å¼€å§‹")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶"""
        try:
            logger.info("ğŸ”„ åˆå§‹åŒ–LLMç³»ç»Ÿç»„ä»¶...")
            
            # 1. åˆ›å»ºè¾“å…¥è·¯ç”±å™¨
            self.input_router = create_input_router(self.config.input_config)
            logger.info("âœ… è¾“å…¥è·¯ç”±å™¨åˆ›å»ºå®Œæˆ")
            
            # 2. åˆ›å»ºpromptç®¡ç†å™¨
            self.prompt_manager = create_prompt_template_manager()
            logger.info("âœ… Promptç®¡ç†å™¨åˆ›å»ºå®Œæˆ")
            
            # 3. åˆ›å»ºå“åº”æ ¼å¼åŒ–å™¨
            self.response_formatter = create_response_formatter(self.config.formatter_config)
            logger.info("âœ… å“åº”æ ¼å¼åŒ–å™¨åˆ›å»ºå®Œæˆ")
            
            # 4. åˆ›å»ºLLMå¼•æ“
            self.engine = create_llm_engine(self.config.llm_config)
            logger.info("âœ… LLMå¼•æ“åˆ›å»ºå®Œæˆ")
            
            self.is_initialized = True
            
            # 5. è‡ªåŠ¨åŠ è½½æ¨¡å‹ï¼ˆå¦‚æœé…ç½®ï¼‰
            if self.config.auto_load_model:
                logger.info("ğŸ”„ è‡ªåŠ¨åŠ è½½æ¨¡å‹...")
                if self.engine.load_model():
                    self.is_ready = True
                    logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆï¼Œç³»ç»Ÿå°±ç»ª")
                else:
                    logger.warning("âš ï¸ æ¨¡å‹åŠ è½½å¤±è´¥ï¼Œç³»ç»Ÿæœªå°±ç»ª")
            else:
                logger.info("â„¹ï¸ æ¨¡å‹éœ€è¦æ‰‹åŠ¨åŠ è½½")
            
            logger.info("ğŸ‰ LLMç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ LLMç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def load_model(self) -> bool:
        """åŠ è½½æ¨¡å‹"""
        if not self.is_initialized:
            logger.error("âŒ ç³»ç»Ÿæœªåˆå§‹åŒ–ï¼Œæ— æ³•åŠ è½½æ¨¡å‹")
            return False
        
        if not self.engine:
            logger.error("âŒ LLMå¼•æ“æœªåˆ›å»º")
            return False
        
        try:
            logger.info("ğŸ”„ å¼€å§‹åŠ è½½LLMæ¨¡å‹...")
            success = self.engine.load_model()
            
            if success:
                self.is_ready = True
                logger.info("âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼Œç³»ç»Ÿå°±ç»ª")
            else:
                logger.error("âŒ æ¨¡å‹åŠ è½½å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åŠ è½½å¼‚å¸¸: {str(e)}")
            return False
    
    def process_query(self, query: str, processor_output: Dict[str, Any]) -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢"""
        if not self.is_ready:
            return {
                'success': False,
                'error': 'ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹',
                'content': 'Sorry, the system is initializing, please try again later.'
            }
        
        try:
            # 1. è¾“å…¥è·¯ç”±
            unified_input = self.input_router.route_processor_output(processor_output, query)
            
            # 2. LLMæ¨ç†
            llm_response = self.engine.generate_response(unified_input)
            
            # 3. å“åº”æ ¼å¼åŒ–
            formatted_response = self.response_formatter.format_response(llm_response, unified_input)
            
            # 4. æ„å»ºæœ€ç»ˆå“åº”
            final_response = {
                'success': True,
                'content': formatted_response.content,
                'metadata': formatted_response.metadata,
                'format_type': formatted_response.format_type,
                'processing_info': formatted_response.processing_info,
                'system_info': {
                    'model_name': self.config.llm_config.model_config.model_name,
                    'processor_type': unified_input.processor_type,
                    'multimodal': unified_input.has_multimodal_data()
                }
            }
            
            logger.info(f"âœ… æŸ¥è¯¢å¤„ç†å®Œæˆ: {query[:50]}...")
            return final_response
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'content': f'Sorry, an error occurred while processing your request: {str(e)}'
            }
    
    def get_system_status(self) -> Dict[str, Any]:
        """è·å–ç³»ç»ŸçŠ¶æ€"""
        status = {
            'initialized': self.is_initialized,
            'ready': self.is_ready,
            'components': {
                'engine': self.engine is not None,
                'input_router': self.input_router is not None,
                'prompt_manager': self.prompt_manager is not None,
                'response_formatter': self.response_formatter is not None
            }
        }
        
        # å¦‚æœç»„ä»¶å­˜åœ¨ï¼Œæ·»åŠ è¯¦ç»†çŠ¶æ€
        if self.engine:
            status['engine_stats'] = self.engine.get_stats()
        
        if self.input_router:
            status['router_stats'] = self.input_router.get_stats()
        
        if self.response_formatter:
            status['formatter_stats'] = self.response_formatter.get_stats()
        
        return status

class LLMFactory:
    """LLMå·¥å‚ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥å‚"""
        self.presets = {
            'macos_optimized': self._create_macos_optimized_config,
            'default': self._create_default_config,
            'production': self._create_production_config,
            'development': self._create_development_config
        }
        
        logger.info(f"ğŸ­ LLMFactoryåˆå§‹åŒ–å®Œæˆï¼Œå¯ç”¨é¢„è®¾: {list(self.presets.keys())}")
    
    def create_system(self, preset: str = 'macos_optimized', custom_config: Optional[Dict[str, Any]] = None) -> LLMSystem:
        """åˆ›å»ºLLMç³»ç»Ÿ
        
        Args:
            preset: é¢„è®¾é…ç½®åç§°
            custom_config: è‡ªå®šä¹‰é…ç½®è¦†ç›–
            
        Returns:
            LLMSystem: é…ç½®å¥½çš„LLMç³»ç»Ÿ
        """
        try:
            # è·å–é¢„è®¾é…ç½®
            if preset in self.presets:
                config = self.presets[preset]()
            else:
                logger.warning(f"âš ï¸ æœªçŸ¥é¢„è®¾: {preset}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
                config = self._create_default_config()
            
            # åº”ç”¨è‡ªå®šä¹‰é…ç½®
            if custom_config:
                config = self._apply_custom_config(config, custom_config)
            
            # åˆ›å»ºç³»ç»Ÿ
            system = LLMSystem(config)
            
            logger.info(f"âœ… LLMç³»ç»Ÿåˆ›å»ºå®Œæˆï¼Œé¢„è®¾: {preset}")
            return system
            
        except Exception as e:
            logger.error(f"âŒ LLMç³»ç»Ÿåˆ›å»ºå¤±è´¥: {str(e)}")
            raise
    
    def _create_macos_optimized_config(self) -> LLMSystemConfig:
        """åˆ›å»ºMacOSä¼˜åŒ–é…ç½®"""
        llm_config = get_macos_optimized_config()
        
        input_config = LLMInputConfig(
            processor_type='auto',
            enable_multimodal=True,
            max_tokens=3072,
            include_metadata=True
        )
        
        formatter_config = {
            'enable_markdown': True,
            'add_metadata': True,
            'clean_output': True,
            'max_response_length': 2048,
            'format_lists': True,
            'highlight_keywords': False
        }
        
        return LLMSystemConfig(
            llm_config=llm_config,
            input_config=input_config,
            formatter_config=formatter_config,
            auto_load_model=False  # MacOSç¯å¢ƒæ‰‹åŠ¨åŠ è½½
        )
    
    def _create_default_config(self) -> LLMSystemConfig:
        """åˆ›å»ºé»˜è®¤é…ç½®"""
        llm_config = get_default_llm_config()
        
        input_config = LLMInputConfig(
            processor_type='auto',
            enable_multimodal=True,
            max_tokens=3072,
            include_metadata=True
        )
        
        formatter_config = {
            'enable_markdown': True,
            'add_metadata': False,
            'clean_output': True,
            'max_response_length': 1024,
            'format_lists': True
        }
        
        return LLMSystemConfig(
            llm_config=llm_config,
            input_config=input_config,
            formatter_config=formatter_config,
            auto_load_model=False
        )
    
    def _create_production_config(self) -> LLMSystemConfig:
        """åˆ›å»ºç”Ÿäº§ç¯å¢ƒé…ç½®"""
        # ç”Ÿäº§ç¯å¢ƒä½¿ç”¨æ›´ä¸¥æ ¼çš„é…ç½®
        llm_config = get_default_llm_config()
        llm_config.enable_cache = True
        llm_config.cache_ttl = 7200  # 2å°æ—¶ç¼“å­˜
        
        input_config = LLMInputConfig(
            processor_type='auto',
            enable_multimodal=True,
            max_tokens=3072,
            include_metadata=False  # ç”Ÿäº§ç¯å¢ƒå‡å°‘å…ƒæ•°æ®
        )
        
        formatter_config = {
            'enable_markdown': True,
            'add_metadata': False,
            'clean_output': True,
            'max_response_length': 1536,
            'format_lists': True,
            'highlight_keywords': False
        }
        
        return LLMSystemConfig(
            llm_config=llm_config,
            input_config=input_config,
            formatter_config=formatter_config,
            auto_load_model=True  # ç”Ÿäº§ç¯å¢ƒè‡ªåŠ¨åŠ è½½
        )
    
    def _create_development_config(self) -> LLMSystemConfig:
        """åˆ›å»ºå¼€å‘ç¯å¢ƒé…ç½®"""
        llm_config = get_macos_optimized_config()
        llm_config.enable_cache = False  # å¼€å‘ç¯å¢ƒä¸ç¼“å­˜
        
        input_config = LLMInputConfig(
            processor_type='auto',
            enable_multimodal=True,
            max_tokens=2048,  # å¼€å‘ç¯å¢ƒè¾ƒå°
            include_metadata=True
        )
        
        formatter_config = {
            'enable_markdown': True,
            'add_metadata': True,
            'clean_output': False,  # å¼€å‘ç¯å¢ƒä¿ç•™åŸå§‹è¾“å‡º
            'max_response_length': 1024,
            'format_lists': True,
            'highlight_keywords': True
        }
        
        return LLMSystemConfig(
            llm_config=llm_config,
            input_config=input_config,
            formatter_config=formatter_config,
            auto_load_model=False
        )
    
    def _apply_custom_config(self, base_config: LLMSystemConfig, custom_config: Dict[str, Any]) -> LLMSystemConfig:
        """åº”ç”¨è‡ªå®šä¹‰é…ç½®"""
        # è¿™é‡Œå¯ä»¥å®ç°æ›´å¤æ‚çš„é…ç½®åˆå¹¶é€»è¾‘
        # ç®€å•å®ç°ï¼šç›´æ¥è¦†ç›–æŒ‡å®šå­—æ®µ
        
        if 'llm_config' in custom_config:
            llm_custom = custom_config['llm_config']
            for key, value in llm_custom.items():
                if hasattr(base_config.llm_config, key):
                    setattr(base_config.llm_config, key, value)
        
        if 'input_config' in custom_config:
            input_custom = custom_config['input_config']
            for key, value in input_custom.items():
                if hasattr(base_config.input_config, key):
                    setattr(base_config.input_config, key, value)
        
        if 'formatter_config' in custom_config:
            base_config.formatter_config.update(custom_config['formatter_config'])
        
        if 'auto_load_model' in custom_config:
            base_config.auto_load_model = custom_config['auto_load_model']
        
        return base_config
    
    def list_presets(self) -> List[str]:
        """åˆ—å‡ºå¯ç”¨é¢„è®¾"""
        return list(self.presets.keys())
    
    def get_preset_info(self, preset: str) -> Optional[Dict[str, Any]]:
        """è·å–é¢„è®¾ä¿¡æ¯"""
        if preset not in self.presets:
            return None
        
        try:
            config = self.presets[preset]()
            return {
                'name': preset,
                'model_name': config.llm_config.model_config.model_name,
                'device': config.llm_config.model_config.device,
                'multimodal_enabled': config.llm_config.enable_multimodal,
                'auto_load_model': config.auto_load_model,
                'description': self._get_preset_description(preset)
            }
        except Exception as e:
            logger.error(f"âŒ è·å–é¢„è®¾ä¿¡æ¯å¤±è´¥: {str(e)}")
            return None
    
    def _get_preset_description(self, preset: str) -> str:
        """è·å–é¢„è®¾æè¿°"""
        descriptions = {
            'macos_optimized': 'MacOSç¯å¢ƒä¼˜åŒ–é…ç½®ï¼Œä½¿ç”¨CPUæ¨ç†ï¼Œé€‚åˆæœ¬åœ°å¼€å‘',
            'default': 'é»˜è®¤é…ç½®ï¼Œå¹³è¡¡æ€§èƒ½å’Œèµ„æºä½¿ç”¨',
            'production': 'ç”Ÿäº§ç¯å¢ƒé…ç½®ï¼Œå¯ç”¨ç¼“å­˜å’Œè‡ªåŠ¨åŠ è½½',
            'development': 'å¼€å‘ç¯å¢ƒé…ç½®ï¼Œè¯¦ç»†æ—¥å¿—å’Œè°ƒè¯•ä¿¡æ¯'
        }
        return descriptions.get(preset, 'è‡ªå®šä¹‰é…ç½®')

# =============================================================================
# å…¨å±€å·¥å‚å®ä¾‹
# =============================================================================

llm_factory = LLMFactory()

# =============================================================================
# ä¾¿æ·å‡½æ•°
# =============================================================================

def create_llm_system(preset: str = 'macos_optimized', custom_config: Optional[Dict[str, Any]] = None) -> LLMSystem:
    """åˆ›å»ºLLMç³»ç»Ÿçš„ä¾¿æ·å‡½æ•°"""
    return llm_factory.create_system(preset, custom_config)

def get_available_presets() -> List[str]:
    """è·å–å¯ç”¨é¢„è®¾åˆ—è¡¨"""
    return llm_factory.list_presets()

# =============================================================================
# æµ‹è¯•å’Œæ¼”ç¤º
# =============================================================================

if __name__ == "__main__":
    print("ğŸ­ LLMå·¥å‚æµ‹è¯•")
    
    # æ˜¾ç¤ºå¯ç”¨é¢„è®¾
    presets = get_available_presets()
    print(f"å¯ç”¨é¢„è®¾: {presets}")
    
    # è·å–æ¯ä¸ªé¢„è®¾çš„ä¿¡æ¯
    for preset in presets:
        info = llm_factory.get_preset_info(preset)
        if info:
            print(f"\nğŸ“‹ {preset}:")
            print(f"   æ¨¡å‹: {info['model_name']}")
            print(f"   è®¾å¤‡: {info['device']}")
            print(f"   å¤šæ¨¡æ€: {info['multimodal_enabled']}")
            print(f"   æè¿°: {info['description']}")
    
    # åˆ›å»ºæµ‹è¯•ç³»ç»Ÿ
    print(f"\nğŸ§ª åˆ›å»ºæµ‹è¯•ç³»ç»Ÿ...")
    system = create_llm_system('macos_optimized')
    
    print(f"âœ… ç³»ç»Ÿåˆ›å»ºå®Œæˆ")
    print(f"åˆå§‹åŒ–çŠ¶æ€: {system.is_initialized}")
    
    # åˆå§‹åŒ–ç³»ç»Ÿ
    if system.initialize():
        print(f"âœ… ç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
        status = system.get_system_status()
        print(f"ç³»ç»ŸçŠ¶æ€: åˆå§‹åŒ–={status['initialized']}, å°±ç»ª={status['ready']}")
    else:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥")
