"""
GNNæ•°æ®æ„å»ºå™¨ (GNN Data Builder)
è´Ÿè´£ä»NebulaGraphä¸­æå–å­å›¾æ•°æ®å¹¶è½¬æ¢ä¸ºtorch_geometric.data.Dataæ ¼å¼
é€‚ç”¨äºGNNæ¨¡å‹çš„å›¾ç¥ç»ç½‘ç»œå¤„ç†
"""
import torch
import numpy as np
import networkx as nx
from typing import Dict, Any, List, Optional, Tuple, Set
from app.database import NebulaGraphConnection
from app.rag.component_factory import BaseGraphBuilder, component_factory
import logging

try:
    from torch_geometric.data import Data
    HAS_TORCH_GEOMETRIC = True
except ImportError:
    HAS_TORCH_GEOMETRIC = False
    # åˆ›å»ºç®€å•çš„æ›¿ä»£Dataç±»ç”¨äºå¼€å‘
    class Data:
        def __init__(self, x=None, edge_index=None, edge_attr=None, node_id=None):
            self.x = x
            self.edge_index = edge_index
            self.edge_attr = edge_attr
            self.node_id = node_id

logger = logging.getLogger(__name__)

class GNNDataBuilder(BaseGraphBuilder):
    """GNNæ•°æ®æ„å»ºå™¨ - å°†å­å›¾è½¬æ¢ä¸ºtorch_geometric.data.Dataæ ¼å¼"""
    
    def __init__(self, max_nodes: int = 50, max_hops: int = 2, 
                 feature_dim: int = 768, include_edge_features: bool = True, nebula_conn=None):
        """åˆå§‹åŒ–GNNæ•°æ®æ„å»ºå™¨
        
        Args:
            max_nodes: æœ€å¤§èŠ‚ç‚¹æ•°
            max_hops: æœ€å¤§è·³æ•°
            feature_dim: èŠ‚ç‚¹ç‰¹å¾ç»´åº¦
            include_edge_features: æ˜¯å¦åŒ…å«è¾¹ç‰¹å¾
            nebula_conn: NebulaGraphè¿æ¥å®ä¾‹
        """
        self.max_nodes = max_nodes
        self.max_hops = max_hops
        self.feature_dim = feature_dim
        self.include_edge_features = include_edge_features
        
        # ä½¿ç”¨ä¼ é€’çš„è¿æ¥æˆ–åˆ›å»ºæ–°è¿æ¥
        self.nebula_conn = nebula_conn if nebula_conn is not None else NebulaGraphConnection()
        self.graph = nx.Graph()
        self.node_features = {}  # èŠ‚ç‚¹ç‰¹å¾ç¼“å­˜
        self.edge_features = {}  # è¾¹ç‰¹å¾ç¼“å­˜
        self.is_initialized = False
        
        # æ£€æŸ¥torch_geometricå¯ç”¨æ€§
        if not HAS_TORCH_GEOMETRIC:
            logger.warning("âš ï¸ torch_geometricæœªå®‰è£…ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆDataç±»")
    
    def initialize(self) -> bool:
        """åˆå§‹åŒ–GNNæ•°æ®æ„å»ºå™¨"""
        try:
            logger.info("ğŸ”„ åˆå§‹åŒ–GNNæ•°æ®æ„å»ºå™¨...")
            
            # è¿æ¥æ•°æ®åº“
            if not self.nebula_conn.connect():
                logger.error("âŒ NebulaGraphè¿æ¥å¤±è´¥")
                return False
            
            # æ„å»ºåŸºç¡€å›¾ç»“æ„
            self._build_base_graph()
            
            self.is_initialized = True
            logger.info("âœ… GNNæ•°æ®æ„å»ºå™¨åˆå§‹åŒ–å®Œæˆ")
            return True
            
        except Exception as e:
            logger.error(f"âŒ GNNæ•°æ®æ„å»ºå™¨åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            return False
    
    def _build_base_graph(self):
        """æ„å»ºåŸºç¡€å›¾ç»“æ„"""
        logger.info("ğŸ—ï¸ æ„å»ºåŸºç¡€å›¾ç»“æ„...")
        
        # è·å–çƒå‘˜-çƒé˜Ÿå…³ç³»æ•°æ®
        query = """
        MATCH (p:player)-[r:serve]->(t:team)
        RETURN p.player.name AS player_name, p.player.age AS player_age,
               t.team.name AS team_name
        LIMIT 300
        """
        
        result = self.nebula_conn.execute_query(query)
        if result['success']:
            for row in result['rows']:
                player_name, player_age, team_name = row[0], row[1], row[2]
                
                # å¤„ç†NULLå€¼
                if player_name is None or team_name is None:
                    continue
                if player_age is None:
                    player_age = 0
                
                player_id = f"player:{player_name}"
                team_id = f"team:{team_name}"
                
                # æ·»åŠ çƒå‘˜èŠ‚ç‚¹
                if not self.graph.has_node(player_id):
                    self.graph.add_node(player_id,
                                      type='player',
                                      name=player_name,
                                      age=player_age,
                                      description=f"çƒå‘˜ {player_name}, å¹´é¾„ {player_age} å²")
                
                # æ·»åŠ çƒé˜ŸèŠ‚ç‚¹
                if not self.graph.has_node(team_id):
                    self.graph.add_node(team_id,
                                      type='team',
                                      name=team_name,
                                      description=f"çƒé˜Ÿ {team_name}")
                
                # æ·»åŠ è¾¹
                self.graph.add_edge(player_id, team_id,
                                  relation='serve',
                                  weight=1.0)
        
        logger.info(f"âœ… åŸºç¡€å›¾æ„å»ºå®Œæˆï¼ŒèŠ‚ç‚¹: {len(self.graph.nodes)}, è¾¹: {len(self.graph.edges)}")
    
    def build_subgraph(self, seed_nodes: List[str], query: str) -> Dict[str, Any]:
        """æ„å»ºå­å›¾å¹¶è½¬æ¢ä¸ºGNNæ•°æ®æ ¼å¼"""
        if not self.is_initialized:
            raise RuntimeError("GNNæ•°æ®æ„å»ºå™¨æœªåˆå§‹åŒ–")
        
        logger.info(f"ğŸŒ± æ„å»ºGNNæ•°æ®æ ¼å¼å­å›¾ï¼Œç§å­èŠ‚ç‚¹: {len(seed_nodes)}")
        
        # éªŒè¯ç§å­èŠ‚ç‚¹
        valid_seeds = [node for node in seed_nodes if node in self.graph.nodes]
        if not valid_seeds:
            logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ç§å­èŠ‚ç‚¹")
            return self._create_empty_gnn_data()
        
        try:
            # 1. æå–å­å›¾èŠ‚ç‚¹
            subgraph_nodes = self._extract_subgraph_nodes(valid_seeds)
            
            # 2. æ„å»ºèŠ‚ç‚¹ç‰¹å¾
            node_features, node_mapping = self._build_node_features(subgraph_nodes, query)
            
            # 3. æ„å»ºè¾¹æ•°æ®
            edge_index, edge_attr = self._build_edge_data(subgraph_nodes, node_mapping)
            
            # 4. åˆ›å»ºtorch_geometric.data.Dataå¯¹è±¡
            data_obj = self._create_data_object(node_features, edge_index, edge_attr, 
                                              list(subgraph_nodes), node_mapping)
            
            # 5. è¿”å›æ ‡å‡†æ ¼å¼
            result = {
                'data': data_obj,
                'node_mapping': node_mapping,
                'node_ids': list(subgraph_nodes),
                'num_nodes': len(subgraph_nodes),
                'num_edges': edge_index.shape[1] if edge_index is not None else 0,
                'feature_dim': self.feature_dim,
                'algorithm': 'gnn_data_builder'
            }
            
            logger.info(f"âœ… GNNæ•°æ®æ„å»ºå®Œæˆï¼ŒèŠ‚ç‚¹: {result['num_nodes']}, è¾¹: {result['num_edges']}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ GNNæ•°æ®æ„å»ºå¤±è´¥: {str(e)}")
            return self._create_empty_gnn_data()
    
    def _extract_subgraph_nodes(self, seed_nodes: List[str]) -> Set[str]:
        """æå–å­å›¾èŠ‚ç‚¹"""
        # éªŒè¯ç§å­èŠ‚ç‚¹
        valid_seeds = [node for node in seed_nodes if node in self.graph.nodes]
        if not valid_seeds:
            return set()
        
        # BFSæ‰©å±•
        subgraph_nodes = set(valid_seeds)
        current_level = set(valid_seeds)
        
        for hop in range(self.max_hops):
            if len(subgraph_nodes) >= self.max_nodes:
                break
            
            next_level = set()
            for node in current_level:
                neighbors = list(self.graph.neighbors(node))
                
                # é™åˆ¶æ¯å±‚æ·»åŠ çš„èŠ‚ç‚¹æ•°
                remaining_slots = self.max_nodes - len(subgraph_nodes)
                neighbors = neighbors[:remaining_slots]
                
                for neighbor in neighbors:
                    if neighbor not in subgraph_nodes:
                        next_level.add(neighbor)
                        subgraph_nodes.add(neighbor)
                        
                        if len(subgraph_nodes) >= self.max_nodes:
                            break
                
                if len(subgraph_nodes) >= self.max_nodes:
                    break
            
            current_level = next_level
            if not current_level:
                break
        
        return subgraph_nodes
    
    def _build_node_features(self, nodes: Set[str], query: str) -> Tuple[torch.Tensor, Dict[str, int]]:
        """æ„å»ºèŠ‚ç‚¹ç‰¹å¾çŸ©é˜µ"""
        node_list = list(nodes)
        node_mapping = {node: i for i, node in enumerate(node_list)}
        
        # æ„å»ºç‰¹å¾çŸ©é˜µ
        features = []
        
        for node_id in node_list:
            node_data = self.graph.nodes[node_id]
            
            # åŸºç¡€ç‰¹å¾å‘é‡
            feature_vector = np.zeros(self.feature_dim)
            
            # èŠ‚ç‚¹ç±»å‹ç¼–ç 
            if node_data['type'] == 'player':
                feature_vector[0] = 1.0  # çƒå‘˜æ ‡è®°
                feature_vector[1] = float(node_data.get('age', 0)) / 100.0  # å¹´é¾„å½’ä¸€åŒ–
            else:  # team
                feature_vector[2] = 1.0  # çƒé˜Ÿæ ‡è®°
            
            # åº¦æ•°ç‰¹å¾
            degree = self.graph.degree(node_id)
            feature_vector[3] = float(degree) / 10.0  # åº¦æ•°å½’ä¸€åŒ–
            
            # æŸ¥è¯¢ç›¸å…³ç‰¹å¾ï¼ˆç®€åŒ–ç‰ˆæœ¬ï¼‰
            query_features = self._compute_query_features(query, [node_id])
            if len(query_features) > 0:
                # å°†æŸ¥è¯¢ç‰¹å¾åŠ å…¥ç‰¹å¾å‘é‡çš„åé¢éƒ¨åˆ†
                end_idx = min(len(query_features), self.feature_dim - 4)
                feature_vector[4:4+end_idx] = query_features[:end_idx]
            
            features.append(feature_vector)
        
        # è½¬æ¢ä¸ºPyTorchå¼ é‡
        features_tensor = torch.FloatTensor(np.array(features))
        
        return features_tensor, node_mapping
    
    def _compute_query_features(self, query: str, node_list: List[str]) -> np.ndarray:
        """è®¡ç®—æŸ¥è¯¢ç›¸å…³ç‰¹å¾"""
        # ç®€åŒ–å®ç°ï¼šåŸºäºæŸ¥è¯¢è¯åŒ¹é…è®¡ç®—ç›¸ä¼¼åº¦
        query_lower = query.lower()
        features = []
        
        for node_id in node_list:
            node_data = self.graph.nodes[node_id]
            
            # è®¡ç®—æ–‡æœ¬ç›¸ä¼¼åº¦
            text_content = f"{node_data.get('name', '')} {node_data.get('description', '')}"
            text_lower = text_content.lower()
            
            # ç®€å•çš„å…³é”®è¯åŒ¹é…åˆ†æ•°
            query_words = query_lower.split()
            match_score = 0.0
            for word in query_words:
                if word in text_lower:
                    match_score += 1.0
            
            if len(query_words) > 0:
                match_score /= len(query_words)
            
            features.append(match_score)
        
        return np.array(features)
    
    def _build_edge_data(self, nodes: Set[str], node_mapping: Dict[str, int]) -> Tuple[torch.Tensor, Optional[torch.Tensor]]:
        """æ„å»ºè¾¹ç´¢å¼•å’Œè¾¹ç‰¹å¾"""
        edge_list = []
        edge_attributes = []
        
        subgraph = self.graph.subgraph(nodes)
        
        for edge in subgraph.edges(data=True):
            source, target, edge_data = edge
            
            if source in node_mapping and target in node_mapping:
                source_idx = node_mapping[source]
                target_idx = node_mapping[target]
                
                # æ·»åŠ åŒå‘è¾¹ï¼ˆæ— å‘å›¾ï¼‰
                edge_list.append([source_idx, target_idx])
                edge_list.append([target_idx, source_idx])
                
                if self.include_edge_features:
                    # è¾¹ç‰¹å¾ï¼šæƒé‡ã€å…³ç³»ç±»å‹ç­‰
                    edge_feat = [
                        edge_data.get('weight', 1.0),
                        1.0 if edge_data.get('relation') == 'serve' else 0.0
                    ]
                    edge_attributes.append(edge_feat)
                    edge_attributes.append(edge_feat)  # åŒå‘è¾¹ä½¿ç”¨ç›¸åŒç‰¹å¾
        
        if not edge_list:
            # æ²¡æœ‰è¾¹çš„æƒ…å†µ
            edge_index = torch.empty((2, 0), dtype=torch.long)
            edge_attr = None
        else:
            edge_index = torch.LongTensor(edge_list).t().contiguous()
            edge_attr = torch.FloatTensor(edge_attributes) if self.include_edge_features else None
        
        return edge_index, edge_attr
    
    def _create_data_object(self, node_features: torch.Tensor, edge_index: torch.Tensor, 
                          edge_attr: Optional[torch.Tensor], node_ids: List[str], 
                          node_mapping: Dict[str, int]) -> Data:
        """åˆ›å»ºtorch_geometric.data.Dataå¯¹è±¡"""
        data = Data(
            x=node_features,
            edge_index=edge_index,
            edge_attr=edge_attr,
        )
        
        # æ·»åŠ é¢å¤–ä¿¡æ¯
        data.node_id = node_ids
        data.num_nodes = len(node_ids)
        
        return data
    
    def _create_empty_gnn_data(self) -> Dict[str, Any]:
        """åˆ›å»ºç©ºçš„GNNæ•°æ®"""
        empty_data = Data(
            x=torch.empty((0, self.feature_dim)),
            edge_index=torch.empty((2, 0), dtype=torch.long),
            edge_attr=None
        )
        empty_data.node_id = []
        empty_data.num_nodes = 0
        
        return {
            'data': empty_data,
            'node_mapping': {},
            'node_ids': [],
            'num_nodes': 0,
            'num_edges': 0,
            'feature_dim': self.feature_dim,
            'algorithm': 'gnn_data_builder'
        }

# =============================================================================
# æ³¨å†ŒGNNæ•°æ®æ„å»ºå™¨
# =============================================================================

def register_gnn_data_builder():
    """æ³¨å†ŒGNNæ•°æ®æ„å»ºå™¨åˆ°å·¥å‚"""
    component_factory.register_graph_builder('gnn', GNNDataBuilder)
    logger.info("âœ… GNNæ•°æ®æ„å»ºå™¨å·²æ³¨å†Œåˆ°ç»„ä»¶å·¥å‚")

# è‡ªåŠ¨æ³¨å†Œ
register_gnn_data_builder()
