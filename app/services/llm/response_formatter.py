"""
å“åº”æ ¼å¼åŒ–å™¨
ç»Ÿä¸€å¤„ç†LLMè¾“å‡ºï¼Œæ”¯æŒä¸åŒæ ¼å¼å’Œåå¤„ç†éœ€æ±‚
"""
import time
import logging
from typing import Dict, Any, Optional, List, Union
from dataclasses import dataclass
import json
import re

from .llm_engine import LLMResponse
from .input_router import UnifiedInput

logger = logging.getLogger(__name__)

@dataclass
class FormattedResponse:
    """æ ¼å¼åŒ–åçš„å“åº”"""
    content: str
    metadata: Dict[str, Any]
    format_type: str
    processing_info: Dict[str, Any]
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'content': self.content,
            'metadata': self.metadata,
            'format_type': self.format_type,
            'processing_info': self.processing_info
        }

class ResponseFormatter:
    """å“åº”æ ¼å¼åŒ–å™¨"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """åˆå§‹åŒ–å“åº”æ ¼å¼åŒ–å™¨"""
        self.config = config or {}
        
        # é»˜è®¤é…ç½®
        self.default_config = {
            'enable_markdown': True,
            'add_metadata': True,
            'clean_output': True,
            'max_response_length': 2048,
            'add_citations': False,
            'format_lists': True,
            'highlight_keywords': False
        }
        
        # åˆå¹¶é…ç½®
        self.settings = {**self.default_config, **self.config}
        
        # æ ¼å¼åŒ–ç»Ÿè®¡
        self.stats = {
            'total_formatted': 0,
            'by_processor_type': {},
            'formatting_time': 0.0,
            'truncated_responses': 0,
            'error_responses': 0
        }
        
        # å…³é”®è¯é«˜äº®é…ç½®
        self.basketball_keywords = [
            'ç§‘æ¯”', 'è©¹å§†æ–¯', 'ä¹”ä¸¹', 'åº“é‡Œ', 'æœå…°ç‰¹', 'å­—æ¯å“¥',
            'NBA', 'æ¹–äºº', 'å‹‡å£«', 'å…¬ç‰›', 'å‡¯å°”ç‰¹äºº', 'çƒ­ç«',
            'ç¯®çƒ', 'å¾—åˆ†', 'åŠ©æ”»', 'ç¯®æ¿', 'æ€»å† å†›', 'å­£åèµ›',
            'å¸¸è§„èµ›', 'å…¨æ˜æ˜Ÿ', 'MVP', 'FMVP'
        ]
        
        logger.info(f"ğŸ“ ResponseFormatteråˆå§‹åŒ–å®Œæˆï¼Œé…ç½®: {self.settings}")
    
    def format_response(self, llm_response: LLMResponse, unified_input: UnifiedInput) -> FormattedResponse:
        """æ ¼å¼åŒ–å“åº”"""
        start_time = time.time()
        
        try:
            # æ›´æ–°ç»Ÿè®¡
            self.stats['total_formatted'] += 1
            processor_type = unified_input.processor_type
            if processor_type not in self.stats['by_processor_type']:
                self.stats['by_processor_type'][processor_type] = 0
            self.stats['by_processor_type'][processor_type] += 1
            
            # åŸºç¡€æ¸…ç†
            content = self._clean_content(llm_response.content)
            
            # é•¿åº¦æ£€æŸ¥å’Œæˆªæ–­
            if len(content) > self.settings['max_response_length']:
                content = self._truncate_content(content)
                self.stats['truncated_responses'] += 1
            
            # æ ¹æ®å¤„ç†å™¨ç±»å‹é€‰æ‹©æ ¼å¼åŒ–ç­–ç•¥
            content = self._format_by_processor_type(content, unified_input)
            
            # Markdownæ ¼å¼åŒ–
            if self.settings['enable_markdown']:
                content = self._format_markdown(content)
            
            # åˆ—è¡¨æ ¼å¼åŒ–
            if self.settings['format_lists']:
                content = self._format_lists(content)
            
            # å…³é”®è¯é«˜äº®
            if self.settings['highlight_keywords']:
                content = self._highlight_keywords(content)
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = self._build_metadata(llm_response, unified_input)
            
            # å¤„ç†ä¿¡æ¯
            processing_info = self._build_processing_info(llm_response, start_time)
            
            # ç¡®å®šæ ¼å¼ç±»å‹
            format_type = self._determine_format_type(unified_input, content)
            
            formatting_time = time.time() - start_time
            self.stats['formatting_time'] += formatting_time
            
            logger.info(f"âœ… å“åº”æ ¼å¼åŒ–å®Œæˆï¼Œå¤„ç†å™¨: {processor_type}ï¼Œè€—æ—¶: {formatting_time:.3f}ç§’")
            
            return FormattedResponse(
                content=content,
                metadata=metadata,
                format_type=format_type,
                processing_info=processing_info
            )
            
        except Exception as e:
            logger.error(f"âŒ å“åº”æ ¼å¼åŒ–å¤±è´¥: {str(e)}")
            self.stats['error_responses'] += 1
            return self._create_error_formatted_response(llm_response, unified_input, str(e))
    
    def _clean_content(self, content: str) -> str:
        """æ¸…ç†å†…å®¹"""
        if not self.settings['clean_output']:
            return content
        
        # ç§»é™¤å¤šä½™çš„ç©ºç™½å­—ç¬¦
        content = re.sub(r'\n\s*\n\s*\n', '\n\n', content)  # å¤šä¸ªè¿ç»­æ¢è¡Œ
        content = re.sub(r' +', ' ', content)  # å¤šä¸ªè¿ç»­ç©ºæ ¼
        content = content.strip()
        
        # ç§»é™¤å¯èƒ½çš„æ¨¡å‹ç”Ÿæˆçš„ç‰¹æ®Šæ ‡è®°
        content = re.sub(r'<\|.*?\|>', '', content)
        
        # ç§»é™¤é‡å¤çš„å¥å­ï¼ˆç®€å•æ£€æµ‹ï¼‰
        sentences = content.split('ã€‚')
        unique_sentences = []
        for sentence in sentences:
            sentence = sentence.strip()
            if sentence and sentence not in unique_sentences:
                unique_sentences.append(sentence)
        
        if len(unique_sentences) < len(sentences):
            content = 'ã€‚'.join(unique_sentences)
            if content and not content.endswith('ã€‚'):
                content += 'ã€‚'
        
        return content
    
    def _truncate_content(self, content: str) -> str:
        """æˆªæ–­å†…å®¹"""
        max_length = self.settings['max_response_length']
        
        if len(content) <= max_length:
            return content
        
        # å°è¯•åœ¨å¥å·å¤„æˆªæ–­
        truncated = content[:max_length]
        last_period = truncated.rfind('ã€‚')
        
        if last_period > max_length * 0.7:  # å¦‚æœå¥å·ä½ç½®åˆç†
            truncated = truncated[:last_period + 1]
        else:
            # åœ¨ç©ºæ ¼å¤„æˆªæ–­
            last_space = truncated.rfind(' ')
            if last_space > max_length * 0.8:
                truncated = truncated[:last_space]
        
        # æ·»åŠ çœç•¥å·
        if not truncated.endswith('ã€‚'):
            truncated += '...'
        
        logger.warning(f"âš ï¸ å“åº”è¢«æˆªæ–­ï¼ŒåŸé•¿åº¦: {len(content)}ï¼Œæˆªæ–­å: {len(truncated)}")
        return truncated
    
    def _format_by_processor_type(self, content: str, unified_input: UnifiedInput) -> str:
        """æ ¹æ®å¤„ç†å™¨ç±»å‹æ ¼å¼åŒ–"""
        processor_type = unified_input.processor_type
        
        if processor_type == 'comparison':
            return self._format_comparison_response(content)
        elif processor_type == 'chitchat':
            return self._format_chitchat_response(content)
        elif processor_type == 'complex_g':
            return self._format_complex_response(content, unified_input)
        else:
            return self._format_simple_response(content)
    
    def _format_comparison_response(self, content: str) -> str:
        """æ ¼å¼åŒ–æ¯”è¾ƒç±»å“åº”"""
        # æ·»åŠ æ¯”è¾ƒç»“æ„
        if 'æ¯”è¾ƒ' in content and not content.startswith('## æ¯”è¾ƒåˆ†æ'):
            content = f"## æ¯”è¾ƒåˆ†æ\n\n{content}"
        
        # è¯†åˆ«å¹¶æ ¼å¼åŒ–å¯¹æ¯”ç‚¹
        content = re.sub(r'(\d+\.|[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å]+ã€)', r'\n**\1**', content)
        
        return content
    
    def _format_chitchat_response(self, content: str) -> str:
        """æ ¼å¼åŒ–é—²èŠç±»å“åº”"""
        # ä½¿ç”¨æ›´è½»æ¾çš„è¯­è°ƒ
        if not any(emoji in content for emoji in ['ğŸ˜Š', 'ğŸ‘', 'ğŸ€']):
            if 'ç¯®çƒ' in content:
                content += ' ğŸ€'
        
        return content
    
    def _format_complex_response(self, content: str, unified_input: UnifiedInput) -> str:
        """æ ¼å¼åŒ–å¤æ‚æŸ¥è¯¢å“åº”"""
        # å¦‚æœæœ‰å¤šæ¨¡æ€æ•°æ®ï¼Œæ·»åŠ è¯´æ˜
        if unified_input.has_multimodal_data():
            if not content.startswith('åŸºäºå›¾è°±åˆ†æ'):
                content = f"åŸºäºå›¾è°±åˆ†æå’Œæ–‡æœ¬ä¿¡æ¯ï¼š\n\n{content}"
        
        return content
    
    def _format_simple_response(self, content: str) -> str:
        """æ ¼å¼åŒ–ç®€å•å“åº”"""
        return content
    
    def _format_markdown(self, content: str) -> str:
        """Markdownæ ¼å¼åŒ–"""
        # è‡ªåŠ¨è¯†åˆ«æ ‡é¢˜
        lines = content.split('\n')
        formatted_lines = []
        
        for line in lines:
            line = line.strip()
            if not line:
                formatted_lines.append('')
                continue
            
            # æ£€æµ‹å¯èƒ½çš„æ ‡é¢˜
            if (len(line) < 50 and 
                ('åˆ†æ' in line or 'æ€»ç»“' in line or 'ç»“è®º' in line) and 
                line.endswith(('ï¼š', ':'))):
                formatted_lines.append(f"### {line}")
            else:
                formatted_lines.append(line)
        
        return '\n'.join(formatted_lines)
    
    def _format_lists(self, content: str) -> str:
        """æ ¼å¼åŒ–åˆ—è¡¨"""
        # è¯†åˆ«å¹¶æ ¼å¼åŒ–æ•°å­—åˆ—è¡¨
        content = re.sub(r'^(\d+)\.\s*', r'- **\1.** ', content, flags=re.MULTILINE)
        
        # è¯†åˆ«å¹¶æ ¼å¼åŒ–ä¸­æ–‡æ•°å­—åˆ—è¡¨
        chinese_numbers = ['ä¸€', 'äºŒ', 'ä¸‰', 'å››', 'äº”', 'å…­', 'ä¸ƒ', 'å…«', 'ä¹', 'å']
        for i, num in enumerate(chinese_numbers):
            pattern = f'^{num}ã€\\s*'
            replacement = f'- **{i+1}.** '
            content = re.sub(pattern, replacement, content, flags=re.MULTILINE)
        
        return content
    
    def _highlight_keywords(self, content: str) -> str:
        """é«˜äº®å…³é”®è¯"""
        for keyword in self.basketball_keywords:
            if keyword in content:
                # ä½¿ç”¨Markdownç²—ä½“
                content = content.replace(keyword, f"**{keyword}**")
        
        return content
    
    def _build_metadata(self, llm_response: LLMResponse, unified_input: UnifiedInput) -> Dict[str, Any]:
        """æ„å»ºå…ƒæ•°æ®"""
        metadata = llm_response.metadata.copy()
        
        if self.settings['add_metadata']:
            metadata.update({
                'query': unified_input.query,
                'processor_type': unified_input.processor_type,
                'response_length': len(llm_response.content),
                'has_multimodal_data': unified_input.has_multimodal_data(),
                'formatting_applied': True,
                'formatting_config': self.settings
            })
        
        return metadata
    
    def _build_processing_info(self, llm_response: LLMResponse, start_time: float) -> Dict[str, Any]:
        """æ„å»ºå¤„ç†ä¿¡æ¯"""
        formatting_time = time.time() - start_time
        
        return {
            'llm_processing_time': llm_response.processing_time,
            'formatting_time': formatting_time,
            'total_time': llm_response.processing_time + formatting_time,
            'token_usage': llm_response.token_usage,
            'formatted_at': time.time()
        }
    
    def _determine_format_type(self, unified_input: UnifiedInput, content: str) -> str:
        """ç¡®å®šæ ¼å¼ç±»å‹"""
        if unified_input.processor_type == 'comparison':
            return 'comparison_analysis'
        elif unified_input.processor_type == 'chitchat':
            return 'conversational'
        elif unified_input.has_multimodal_data():
            return 'multimodal_qa'
        elif len(content) > 500:
            return 'detailed_explanation'
        else:
            return 'simple_answer'
    
    def _create_error_formatted_response(self, llm_response: LLMResponse, unified_input: UnifiedInput, error: str) -> FormattedResponse:
        """åˆ›å»ºé”™è¯¯æ ¼å¼åŒ–å“åº”"""
        return FormattedResponse(
            content=llm_response.content,  # è¿”å›åŸå§‹å†…å®¹
            metadata={
                'error': True,
                'formatting_error': error,
                'query': unified_input.query,
                'processor_type': unified_input.processor_type
            },
            format_type='error',
            processing_info={
                'llm_processing_time': llm_response.processing_time,
                'formatting_time': 0.0,
                'total_time': llm_response.processing_time,
                'token_usage': llm_response.token_usage
            }
        )
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç»Ÿè®¡ä¿¡æ¯"""
        total_formatted = max(1, self.stats['total_formatted'])
        
        return {
            'total_formatted': self.stats['total_formatted'],
            'processor_distribution': self.stats['by_processor_type'].copy(),
            'performance': {
                'avg_formatting_time': self.stats['formatting_time'] / total_formatted,
                'total_formatting_time': self.stats['formatting_time']
            },
            'quality_metrics': {
                'truncated_responses': self.stats['truncated_responses'],
                'truncation_rate': self.stats['truncated_responses'] / total_formatted,
                'error_responses': self.stats['error_responses'],
                'error_rate': self.stats['error_responses'] / total_formatted
            },
            'configuration': self.settings
        }
    
    def reset_stats(self):
        """é‡ç½®ç»Ÿè®¡ä¿¡æ¯"""
        self.stats = {
            'total_formatted': 0,
            'by_processor_type': {},
            'formatting_time': 0.0,
            'truncated_responses': 0,
            'error_responses': 0
        }

# =============================================================================
# å·¥å‚å‡½æ•°
# =============================================================================

def create_response_formatter(config: Optional[Dict[str, Any]] = None) -> ResponseFormatter:
    """åˆ›å»ºå“åº”æ ¼å¼åŒ–å™¨"""
    return ResponseFormatter(config)

# =============================================================================
# æµ‹è¯•å’Œæ¼”ç¤º
# =============================================================================

if __name__ == "__main__":
    from .llm_engine import LLMResponse
    from .input_router import UnifiedInput
    
    print("ğŸ“ å“åº”æ ¼å¼åŒ–å™¨æµ‹è¯•")
    
    # åˆ›å»ºæ ¼å¼åŒ–å™¨
    formatter = create_response_formatter()
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    test_llm_response = LLMResponse(
        content="ç§‘æ¯”Â·å¸ƒè±æ©ç‰¹æ˜¯æ´›æ‰çŸ¶æ¹–äººé˜Ÿçš„ä¼ å¥‡çƒå‘˜ã€‚ä»–åœ¨NBAç”Ÿæ¶¯ä¸­è·å¾—äº†5æ¬¡æ€»å† å†›ï¼Œè¢«èª‰ä¸ºç¯®çƒç•Œçš„ä¼ å¥‡äººç‰©ã€‚ç§‘æ¯”çš„èŒä¸šç²¾ç¥å’ŒæŠ€æœ¯æ°´å¹³éƒ½è¾¾åˆ°äº†é¡¶å³°ã€‚",
        metadata={'model': 'test'},
        processing_time=1.5,
        token_usage={'input_tokens': 50, 'output_tokens': 100, 'total_tokens': 150}
    )
    
    test_unified_input = UnifiedInput(
        query="ç§‘æ¯”æ˜¯è°ï¼Ÿ",
        processor_type="direct",
        text_context="ç§‘æ¯”ç›¸å…³ä¿¡æ¯"
    )
    
    # æµ‹è¯•æ ¼å¼åŒ–
    formatted_response = formatter.format_response(test_llm_response, test_unified_input)
    
    print(f"âœ… æ ¼å¼åŒ–å®Œæˆ")
    print(f"åŸå§‹é•¿åº¦: {len(test_llm_response.content)}")
    print(f"æ ¼å¼åŒ–åé•¿åº¦: {len(formatted_response.content)}")
    print(f"æ ¼å¼ç±»å‹: {formatted_response.format_type}")
    print(f"å¤„ç†æ—¶é—´: {formatted_response.processing_info['formatting_time']:.3f}ç§’")
    
    # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print(f"\nğŸ“Š æ ¼å¼åŒ–å™¨ç»Ÿè®¡: {formatter.get_stats()}")
