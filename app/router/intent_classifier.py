"""
BERTæ„å›¾åˆ†ç±»å™¨ - äºŒåˆ†ç±»ç®€å•æŸ¥è¯¢å’Œå¤æ‚æŸ¥è¯¢
"""
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
from transformers import (
    AutoTokenizer, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
from datasets import Dataset
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
import json
from pathlib import Path
import logging
from typing import Tuple, Dict, List
import warnings
warnings.filterwarnings('ignore')

logger = logging.getLogger(__name__)

class BERTIntentClassifier:
    """BERTæ„å›¾åˆ†ç±»å™¨"""
    
    def __init__(self, model_name: str = "bert-base-uncased"):
        self.model_name = model_name
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.tokenizer = None
        self.model = None
        
        # ç²¾ç»†åŒ–æ„å›¾æ ‡ç­¾æ˜ å°„ï¼ˆ5ç±»åˆ†ç±»ï¼‰
        self.id2label = {
            0: "ATTRIBUTE_QUERY",        # å±æ€§æŸ¥è¯¢
            1: "SIMPLE_RELATION_QUERY",  # ç®€å•å…³ç³»æŸ¥è¯¢  
            2: "COMPLEX_RELATION_QUERY", # å¤æ‚å…³ç³»æŸ¥è¯¢
            3: "COMPARATIVE_QUERY",      # æ¯”è¾ƒæŸ¥è¯¢
            4: "DOMAIN_CHITCHAT"         # é¢†åŸŸå†…é—²èŠ
        }
        self.label2id = {
            "ATTRIBUTE_QUERY": 0,
            "SIMPLE_RELATION_QUERY": 1, 
            "COMPLEX_RELATION_QUERY": 2,
            "COMPARATIVE_QUERY": 3,
            "DOMAIN_CHITCHAT": 4
        }
        
        # è·¯å¾„é…ç½®
        self.model_dir = Path("models")
        self.model_dir.mkdir(exist_ok=True)
        self.results_dir = Path("results/evaluations")
        self.results_dir.mkdir(parents=True, exist_ok=True)
        
        logger.info(f"ğŸ’» è®¾å¤‡: {self.device}")
        logger.info(f"ğŸ¤– æ¨¡å‹: {self.model_name}")
    
    def load_model(self, model_path: str = "models/bert_english_5class_final"):
        """åŠ è½½æ¨¡å‹"""
        
        if model_path and Path(model_path).exists():
            # åŠ è½½å¾®è°ƒåçš„æ¨¡å‹
            logger.info(f"ğŸ“¥ åŠ è½½å¾®è°ƒæ¨¡å‹: {model_path}")
            self.tokenizer = AutoTokenizer.from_pretrained(model_path)
            self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        else:
            # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
            logger.info(f"ğŸ“¥ åŠ è½½é¢„è®­ç»ƒæ¨¡å‹: {self.model_name}")
            self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)
            self.model = AutoModelForSequenceClassification.from_pretrained(
                self.model_name,
                num_labels=5,  # 5ç±»ç²¾ç»†åˆ†ç±»
                id2label=self.id2label,
                label2id=self.label2id
            )
        
        self.model.to(self.device)
        self.model.eval()
        logger.info("âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    def load_training_data(self, csv_path: str) -> Tuple[Dataset, Dataset]:
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        
        logger.info(f"ğŸ“Š åŠ è½½è®­ç»ƒæ•°æ®: {csv_path}")
        
        # è¯»å–CSVæ•°æ®
        df = pd.read_csv(csv_path)
        
        # æ•°æ®ç»Ÿè®¡
        logger.info(f"ğŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        logger.info(f"   æ€»æ•°æ®é‡: {len(df)}")
        for label_id, label_name in self.id2label.items():
            count = (df['label'] == label_id).sum()
            logger.info(f"   {label_name}: {count} samples")
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            df['text'].tolist(),
            df['label'].tolist(),
            test_size=0.2,
            random_state=42,
            stratify=df['label']
        )
        
        # åˆ›å»ºDatasetå¯¹è±¡
        train_dataset = Dataset.from_dict({
            'text': train_texts,
            'labels': train_labels
        })
        
        test_dataset = Dataset.from_dict({
            'text': test_texts,
            'labels': test_labels
        })
        
        logger.info(f"ğŸ“‹ æ•°æ®åˆ’åˆ†:")
        logger.info(f"   è®­ç»ƒé›†: {len(train_dataset)}")
        logger.info(f"   æµ‹è¯•é›†: {len(test_dataset)}")
        
        return train_dataset, test_dataset
    
    def tokenize_function(self, examples):
        """åˆ†è¯å‡½æ•°"""
        return self.tokenizer(
            examples["text"],
            padding="max_length",
            truncation=True,
            max_length=128
        )
    
    def compute_metrics(self, eval_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)
        
        accuracy = accuracy_score(labels, predictions)
        
        return {"accuracy": accuracy}
    
    def train(self, csv_path: str, epochs: int = 3, batch_size: int = 16, learning_rate: float = 2e-5):
        """è®­ç»ƒæ¨¡å‹"""
        
        logger.info("ğŸš€ å¼€å§‹BERTå¾®è°ƒè®­ç»ƒ...")
        
        # åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        self.load_model()
        
        # åŠ è½½è®­ç»ƒæ•°æ®
        train_dataset, test_dataset = self.load_training_data(csv_path)
        
        # æ•°æ®é¢„å¤„ç†
        train_dataset = train_dataset.map(self.tokenize_function, batched=True)
        test_dataset = test_dataset.map(self.tokenize_function, batched=True)
        
        # è®­ç»ƒå‚æ•°
        output_dir = self.model_dir / "bert_intent_classifier"
        
        training_args = TrainingArguments(
            output_dir=str(output_dir),
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=50,
            weight_decay=0.01,
            logging_dir=str(self.results_dir / "logs"),
            logging_steps=10,
            evaluation_strategy="epoch",  # ä¿®æ­£å‚æ•°å
            save_strategy="epoch",  # æ”¹ä¸ºæŒ‰epochä¿å­˜
            load_best_model_at_end=True,  # EarlyStoppingCallbackéœ€è¦è¿™ä¸ª
            metric_for_best_model="eval_accuracy",
            greater_is_better=True,
            save_total_limit=2,
            seed=42
        )
        
        # è®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=self.compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
        )
        
        # å¼€å§‹è®­ç»ƒ
        logger.info("â³ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        # æ‰‹åŠ¨ä¿å­˜æœ€ç»ˆæ¨¡å‹
        final_model_path = self.model_dir / "bert_intent_classifier_final"
        final_model_path.mkdir(parents=True, exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹çŠ¶æ€
        self.model.save_pretrained(str(final_model_path))
        self.tokenizer.save_pretrained(str(final_model_path))
        
        logger.info(f"ğŸ’¾ æ¨¡å‹å·²ä¿å­˜åˆ°: {final_model_path}")
        
        # è¯„ä¼°æ¨¡å‹
        eval_results = self.evaluate_model(trainer, test_dataset)
        
        return trainer, eval_results
    
    def evaluate_model(self, trainer, test_dataset) -> Dict:
        """è¯¦ç»†è¯„ä¼°æ¨¡å‹"""
        
        logger.info("ğŸ“Š å¼€å§‹è¯¦ç»†è¯„ä¼°...")
        
        # è·å–é¢„æµ‹ç»“æœ
        predictions = trainer.predict(test_dataset)
        y_pred = np.argmax(predictions.predictions, axis=1)
        y_true = predictions.label_ids
        y_proba = torch.softmax(torch.tensor(predictions.predictions), dim=1).numpy()
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(y_true, y_pred)
        
        # åˆ†ç±»æŠ¥å‘Š
        report = classification_report(
            y_true, y_pred,
            target_names=["Simple", "Complex"],
            output_dict=True
        )
        
        # æ··æ·†çŸ©é˜µ
        cm = confusion_matrix(y_true, y_pred)
        
        # è¯¦ç»†ç»“æœ
        evaluation_results = {
            "accuracy": accuracy,
            "classification_report": report,
            "confusion_matrix": cm.tolist(),
            "predictions": {
                "y_true": y_true.tolist(),
                "y_pred": y_pred.tolist(),
                "y_proba": y_proba.tolist()
            }
        }
        
        # æ‰“å°ç»“æœ
        logger.info("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        logger.info(f"   å‡†ç¡®ç‡: {accuracy:.4f}")
        logger.info("ğŸ“‹ åˆ†ç±»æŠ¥å‘Š:")
        print(classification_report(y_true, y_pred, target_names=["Simple", "Complex"]))
        logger.info("ğŸ” æ··æ·†çŸ©é˜µ:")
        print("       Simple  Complex")
        print(f"Simple   {cm[0][0]:4d}    {cm[0][1]:4d}")
        print(f"Complex  {cm[1][0]:4d}    {cm[1][1]:4d}")
        
        # ä¿å­˜è¯„ä¼°ç»“æœ
        results_path = self.results_dir / "evaluation_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(evaluation_results, f, ensure_ascii=False, indent=2)
        
        logger.info(f"ğŸ’¾ è¯„ä¼°ç»“æœå·²ä¿å­˜: {results_path}")
        
        return evaluation_results
    
    def classify(self, text: str) -> Tuple[str, float]:
        """åˆ†ç±»å•ä¸ªæ–‡æœ¬"""
        
        if self.model is None:
            raise ValueError("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆè°ƒç”¨load_model()æˆ–train()")
        
        # é¢„å¤„ç†
        inputs = self.tokenizer(
            text,
            padding=True,
            truncation=True,
            max_length=128,
            return_tensors="pt"
        )
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        # æ¨ç†
        self.model.eval()
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits
            probs = torch.softmax(logits, dim=-1)
        
        # è§£æç»“æœ
        predicted_id = torch.argmax(probs, dim=-1).item()
        confidence = probs[0][predicted_id].item()
        predicted_label = self.id2label[predicted_id]
        
        return predicted_label, confidence
    
    def batch_classify(self, texts: List[str]) -> List[Tuple[str, float]]:
        """æ‰¹é‡åˆ†ç±»"""
        
        results = []
        for text in texts:
            label, confidence = self.classify(text)
            results.append((label, confidence))
        
        return results
    
    def test_examples(self):
        """æµ‹è¯•ç¤ºä¾‹"""
        
        test_cases = [
            "How old is Yao Ming?",                           # ATTRIBUTE_QUERY
            "Which team does LeBron James play for?",         # SIMPLE_RELATION_QUERY
            "What's Kobe's height?",                          # ATTRIBUTE_QUERY
            "Who is better, LeBron James or Kobe Bryant?",    # COMPARATIVE_QUERY
            "Which city are the Lakers located in?",         # ATTRIBUTE_QUERY
            "Analyze the Lakers' historical achievements",    # COMPLEX_RELATION_QUERY
            "What do you think about basketball?",            # DOMAIN_CHITCHAT
            "List all MVP players who played with Shaq",     # COMPLEX_RELATION_QUERY
        ]
        
        logger.info("ğŸ§ª æµ‹è¯•ç¤ºä¾‹:")
        for text in test_cases:
            label, confidence = self.classify(text)
            logger.info(f"   '{text}' -> {label} ({confidence:.3f})")

# å…¨å±€å®ä¾‹
intent_classifier = BERTIntentClassifier()

if __name__ == "__main__":
    # è®­ç»ƒç¤ºä¾‹ - ä½¿ç”¨æ–°çš„è‹±æ–‡5ç±»æ•°æ®
    csv_path = "data/training/english_fine_grained_training_dataset.csv"
    trainer, results = intent_classifier.train(csv_path, epochs=5)
    intent_classifier.test_examples()
