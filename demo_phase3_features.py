"""
Phase 3 åŠŸèƒ½æ¼”ç¤ºè„šæœ¬
å±•ç¤ºGraphEncoderå’ŒComplexGProcessoråŒæ¨¡å¼åŠŸèƒ½çš„å®é™…åº”ç”¨
"""
import sys
import os
import time
import json

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.append('/Users/wang/i/graphos-qa')

try:
    from app.rag.components.graph_encoder import GraphEncoder, MultimodalContext, create_graph_encoder
    from app.rag.processors.complex_g_processor import ComplexGProcessor, ComplexGProcessorConfig, create_complex_g_processor
    print("âœ… æˆåŠŸå¯¼å…¥æ‰€æœ‰æ¨¡å—")
except ImportError as e:
    print(f"âŒ æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    print("è¯·æ£€æŸ¥æ¨¡å—è·¯å¾„æ˜¯å¦æ­£ç¡®")
    sys.exit(1)

def create_sample_graph_data():
    """åˆ›å»ºç¤ºä¾‹å›¾æ•°æ®"""
    return {
        'nodes': [
            {'id': 'player:ç§‘æ¯”', 'type': 'player', 'name': 'ç§‘æ¯”', 'age': 41, 'position': 'å¾—åˆ†åå«'},
            {'id': 'player:è©¹å§†æ–¯', 'type': 'player', 'name': 'è©¹å§†æ–¯', 'age': 39, 'position': 'å°å‰é”‹'},
            {'id': 'team:æ¹–äºº', 'type': 'team', 'name': 'æ´›æ‰çŸ¶æ¹–äºº'},
            {'id': 'team:éª‘å£«', 'type': 'team', 'name': 'å…‹åˆ©å¤«å…°éª‘å£«'},
            {'id': 'player:éŸ¦å¾·', 'type': 'player', 'name': 'éŸ¦å¾·', 'age': 42, 'position': 'å¾—åˆ†åå«'}
        ],
        'edges': [
            {'source': 'player:ç§‘æ¯”', 'target': 'team:æ¹–äºº', 'relation': 'plays_for', 'weight': 1.0},
            {'source': 'player:è©¹å§†æ–¯', 'target': 'team:æ¹–äºº', 'relation': 'plays_for', 'weight': 1.0},
            {'source': 'player:è©¹å§†æ–¯', 'target': 'team:éª‘å£«', 'relation': 'played_for', 'weight': 0.8},
            {'source': 'player:ç§‘æ¯”', 'target': 'player:è©¹å§†æ–¯', 'relation': 'teammate', 'weight': 0.6},
            {'source': 'player:è©¹å§†æ–¯', 'target': 'player:éŸ¦å¾·', 'relation': 'friend', 'weight': 0.9}
        ]
    }

def demo_graph_encoder():
    """æ¼”ç¤ºGraphEncoderåŠŸèƒ½"""
    print("ğŸ¯ æ¼”ç¤º1: GraphEncoderå›¾ç¼–ç åŠŸèƒ½")
    print("="*50)
    
    try:
        # 1. åˆ›å»ºGraphEncoder
        encoder_config = {
            'model_config': {
                'input_dim': 768,
                'hidden_dim': 256,
                'output_dim': 128
            }
        }
        
        print("ğŸ”§ æ­£åœ¨åˆ›å»ºGraphEncoder...")
        encoder = create_graph_encoder(encoder_config)
        
        print("ğŸ”§ æ­£åœ¨åˆå§‹åŒ–GraphEncoder...")
        init_result = encoder.initialize()
        
        if not init_result:
            print(f"âŒ GraphEncoderåˆå§‹åŒ–å¤±è´¥")
            return None
        
        print(f"ğŸ“Š GraphEncoderé…ç½®:")
        print(f"   è¾“å…¥ç»´åº¦: {encoder.input_dim}")
        print(f"   éšè—ç»´åº¦: {encoder.hidden_dim}")
        print(f"   è¾“å‡ºç»´åº¦: {encoder.output_dim}")
        print()
        
        # 2. åˆ›å»ºç¤ºä¾‹å›¾æ•°æ®
        graph_data = create_sample_graph_data()
        print(f"ğŸ“ˆ è¾“å…¥å›¾æ•°æ®:")
        print(f"   èŠ‚ç‚¹æ•°: {len(graph_data['nodes'])}")
        print(f"   è¾¹æ•°: {len(graph_data['edges'])}")
        
        for node in graph_data['nodes'][:3]:  # æ˜¾ç¤ºå‰3ä¸ªèŠ‚ç‚¹
            print(f"   èŠ‚ç‚¹: {node['name']} ({node['type']})")
        print(f"   ... å…±{len(graph_data['nodes'])}ä¸ªèŠ‚ç‚¹")
        print()
        
        # 3. å›¾ç¼–ç 
        print("ğŸ”„ æ‰§è¡Œå›¾ç¼–ç ...")
        start_time = time.time()
        result = encoder.encode_graph(graph_data, "ç§‘æ¯”å’Œè©¹å§†æ–¯å“ªä¸ªè·å¾—æ€»å† å†›çš„æ¦‚ç‡å¤§ä¸€äº›åœ¨2025å¹´ï¼Ÿ")   
        encoding_time = time.time() - start_time
        
        if result['success']:
            print(f"âœ… å›¾ç¼–ç æˆåŠŸ!")
            print(f"   åµŒå…¥ç»´åº¦: {result['embedding_dim']}")
            print(f"   ç¼–ç æ—¶é—´: {encoding_time:.3f}ç§’")
            print(f"   åµŒå…¥å‘é‡: {result['embedding'][:5]}...") # æ˜¾ç¤ºå‰5ä¸ªæ•°å€¼
            print()
            return result['embedding']
        else:
            print(f"âŒ å›¾ç¼–ç å¤±è´¥: {result['error']}")
            return None
            
    except Exception as e:
        print(f"âŒ GraphEncoderæ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def demo_multimodal_context():
    """æ¼”ç¤ºMultimodalContextæ•°æ®ç»“æ„"""
    print("ğŸ¯ æ¼”ç¤º2: MultimodalContextå¤šæ¨¡æ€ä¸Šä¸‹æ–‡")
    print("="*50)
    
    # 1. åˆ›å»ºæ–‡æœ¬å’Œå›¾åµŒå…¥
    text_context = """
    æ ¹æ®å›¾è°±åˆ†æï¼Œç§‘æ¯”å’Œè©¹å§†æ–¯éƒ½æ˜¯NBAçš„é¡¶çº§çƒå‘˜ã€‚ç§‘æ¯”æ•ˆåŠ›äºæ´›æ‰çŸ¶æ¹–äººé˜Ÿï¼Œ
    æ˜¯ä¸€åå¾—åˆ†åå«ã€‚è©¹å§†æ–¯æ›¾æ•ˆåŠ›äºå…‹åˆ©å¤«å…°éª‘å£«é˜Ÿï¼Œåæ¥ä¹ŸåŠ å…¥äº†æ¹–äººé˜Ÿï¼Œ
    æ˜¯ä¸€åå°å‰é”‹ã€‚ä»–ä»¬æ›¾ç»æ˜¯é˜Ÿå‹ï¼Œå¹¶ä¸”éƒ½å–å¾—äº†è¾‰ç…Œçš„æˆå°±ã€‚
    """
    
    # æ¨¡æ‹Ÿå›¾åµŒå…¥ï¼ˆå®é™…åº”è¯¥æ¥è‡ªGraphEncoderï¼‰
    graph_embedding = [0.23, -0.15, 0.67, 0.42, -0.31, 0.89, -0.56, 0.78, 0.12, -0.44]
    
    # 2. åˆ›å»ºMultimodalContext
    multimodal_context = MultimodalContext(
        text_context=text_context.strip(),
        graph_embedding=graph_embedding,
        metadata={
            'query': 'ç§‘æ¯”å’Œè©¹å§†æ–¯çš„å…³ç³»',
            'creation_time': time.time(),
            'source': 'demo',
            'version': '1.0'
        }
    )
    
    print(f"ğŸ“ å¤šæ¨¡æ€ä¸Šä¸‹æ–‡åˆ›å»º:")
    print(f"   æ–‡æœ¬é•¿åº¦: {len(multimodal_context.text_context)} å­—ç¬¦")
    print(f"   å›¾åµŒå…¥ç»´åº¦: {len(multimodal_context.graph_embedding)}")
    print(f"   å…ƒæ•°æ®: {list(multimodal_context.metadata.keys())}")
    print()
    
    # 3. åºåˆ—åŒ–å’Œååºåˆ—åŒ–æµ‹è¯•
    print("ğŸ”„ åºåˆ—åŒ–æµ‹è¯•...")
    context_dict = multimodal_context.to_dict()
    restored_context = MultimodalContext.from_dict(context_dict)
    
    print(f"âœ… åºåˆ—åŒ–æˆåŠŸï¼Œå­—å…¸é”®: {list(context_dict.keys())}")
    print(f"âœ… ååºåˆ—åŒ–æˆåŠŸï¼Œæ–‡æœ¬é•¿åº¦: {len(restored_context.text_context)}")
    print()
    
    # 4. ç»„åˆè¡¨ç¤º
    combined_repr = multimodal_context.get_combined_representation()
    print(f"ğŸ­ ç»„åˆè¡¨ç¤º:")
    print(f"   ç±»å‹: {type(combined_repr)}")
    print(f"   åŒ…å«é”®: {list(combined_repr.keys())}")
    print(f"   æ¨¡æ€æ•°é‡: {combined_repr['integration_info']['modality_count']}")
    print(f"   æ–‡æœ¬é•¿åº¦: {combined_repr['integration_info']['text_length']}")
    print()
    
    return multimodal_context

def demo_complex_g_processor():
    """æ¼”ç¤ºComplexGProcessoråŒæ¨¡å¼åŠŸèƒ½"""
    print("ğŸ¯ æ¼”ç¤º3: ComplexGProcessoråŒæ¨¡å¼å¤„ç†")
    print("="*50)
    
    try:
        # 1. åˆ›å»ºä¼ ç»Ÿæ¨¡å¼å¤„ç†å™¨
        traditional_config = {
            'processor_name': 'demo_traditional_processor',
            'cache_enabled': False,
            'use_enhanced_mode': False,
            'graph_encoder_enabled': False
        }
        
        print("ğŸ”§ åˆ›å»ºä¼ ç»Ÿæ¨¡å¼å¤„ç†å™¨...")
        traditional_processor = create_complex_g_processor(traditional_config)
        print(f"ğŸ“Š ä¼ ç»Ÿæ¨¡å¼å¤„ç†å™¨:")
        print(f"   å¤„ç†å™¨åç§°: {traditional_processor.processor_name}")
        print(f"   å½“å‰æ¨¡å¼: {traditional_processor.current_mode}")
        print(f"   GraphEncoderå¯ç”¨: {traditional_processor.graph_encoder is not None}")
        print()
        
        # 2. åˆ›å»ºå¢å¼ºæ¨¡å¼å¤„ç†å™¨
        enhanced_config = {
            'processor_name': 'demo_enhanced_processor',
            'cache_enabled': False,
            'use_enhanced_mode': True,
            'graph_encoder_enabled': True,
            'graph_encoder_config': {
                'model_config': {
                    'input_dim': 768,
                    'hidden_dim': 256,
                    'output_dim': 128
                }
            },
            'enable_multimodal_fusion': True,
            'fusion_strategy': 'concatenate',
            'min_graph_nodes': 2
        }
        
        print("ğŸ”§ åˆ›å»ºå¢å¼ºæ¨¡å¼å¤„ç†å™¨...")
        enhanced_processor = create_complex_g_processor(enhanced_config)
        
        # æ£€æŸ¥GraphEncoderæ˜¯å¦æ­£ç¡®åˆ›å»º
        if enhanced_processor.graph_encoder is None:
            print("âš ï¸ GraphEncoderåˆ›å»ºå¤±è´¥ï¼Œå°è¯•æ‰‹åŠ¨åˆ›å»º...")
            try:
                encoder = create_graph_encoder(enhanced_config['graph_encoder_config'])
                init_result = encoder.initialize()
                if init_result:
                    enhanced_processor.graph_encoder = encoder
                    print("âœ… æ‰‹åŠ¨åˆ›å»ºGraphEncoderæˆåŠŸ")
                else:
                    print(f"âŒ æ‰‹åŠ¨åˆ›å»ºGraphEncoderå¤±è´¥")
            except Exception as e:
                print(f"âŒ æ‰‹åŠ¨åˆ›å»ºGraphEncoderå¼‚å¸¸: {str(e)}")
        
        print(f"ğŸš€ å¢å¼ºæ¨¡å¼å¤„ç†å™¨:")
        print(f"   å¤„ç†å™¨åç§°: {enhanced_processor.processor_name}")
        print(f"   å½“å‰æ¨¡å¼: {enhanced_processor.current_mode}")
        print(f"   GraphEncoderå¯ç”¨: {enhanced_processor.graph_encoder is not None}")
        if hasattr(enhanced_processor, 'complex_config'):
            print(f"   å¤šæ¨¡æ€èåˆ: {enhanced_processor.complex_config.enable_multimodal_fusion}")
            print(f"   èåˆç­–ç•¥: {enhanced_processor.complex_config.fusion_strategy}")
        print()
        
        # 3. æ¨¡å¼åˆ‡æ¢æ¼”ç¤º
        print("ğŸ”„ æ¨¡å¼åˆ‡æ¢æ¼”ç¤º:")
        print(f"   å½“å‰æ¨¡å¼: {enhanced_processor.current_mode}")
        
        enhanced_processor.switch_mode('traditional')
        print(f"   åˆ‡æ¢åæ¨¡å¼: {enhanced_processor.current_mode}")
        
        if enhanced_processor.graph_encoder:
            enhanced_processor.switch_mode('enhanced')
            print(f"   å†æ¬¡åˆ‡æ¢åæ¨¡å¼: {enhanced_processor.current_mode}")
        print()
        
        # 4. GraphEncoderæµ‹è¯•
        if enhanced_processor.graph_encoder:
            print("ğŸ§  GraphEncoderæµ‹è¯•:")
            test_result = enhanced_processor.test_graph_encoder()
            
            if test_result['success']:
                print(f"   âœ… æµ‹è¯•é€šè¿‡")
                print(f"   ç¼–ç å™¨ç±»å‹: {test_result['encoder_info']['model_type']}")
            else:
                print(f"   âŒ æµ‹è¯•å¤±è´¥: {test_result['error']}")
            print()
        
        # 5. ç»Ÿè®¡ä¿¡æ¯
        stats = enhanced_processor.get_enhanced_stats()
        enhanced_info = stats['enhanced_info']
        
        print("ğŸ“ˆ å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   ä¼ ç»Ÿæ¨¡å¼å¤„ç†æ¬¡æ•°: {enhanced_info['processing_modes']['traditional_mode_count']}")
        print(f"   å¢å¼ºæ¨¡å¼å¤„ç†æ¬¡æ•°: {enhanced_info['processing_modes']['enhanced_mode_count']}")
        print(f"   æ¨¡å¼åˆ‡æ¢æ¬¡æ•°: {enhanced_info['processing_modes']['mode_switches']}")
        print()
        
        return enhanced_processor
        
    except Exception as e:
        print(f"âŒ ComplexGProcessoræ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def demo_integration_workflow():
    """æ¼”ç¤ºå®Œæ•´çš„é›†æˆå·¥ä½œæµ"""
    print("ğŸ¯ æ¼”ç¤º4: å®Œæ•´é›†æˆå·¥ä½œæµ")
    print("="*50)
    
    try:
        # 1. åˆ›å»ºå¢å¼ºæ¨¡å¼å¤„ç†å™¨
        config = {
            'processor_name': 'integration_demo_processor',
            'use_enhanced_mode': True,
            'graph_encoder_enabled': True,
            'graph_encoder_config': {
                'model_config': {
                    'input_dim': 768,
                    'hidden_dim': 256,
                    'output_dim': 128
                }
            },
            'enable_multimodal_fusion': True,
            'fusion_strategy': 'concatenate'
        }
        
        processor = create_complex_g_processor(config)
        print(f"ğŸ”§ åˆ›å»ºå¤„ç†å™¨: {processor.processor_name}")
        
        # æ£€æŸ¥GraphEncoderçŠ¶æ€
        if processor.graph_encoder is None:
            print("âš ï¸ GraphEncoderæœªæ­£ç¡®åˆå§‹åŒ–ï¼Œå°è¯•ä¿®å¤...")
            try:
                encoder = create_graph_encoder(config['graph_encoder_config'])
                init_result = encoder.initialize()
                if init_result:
                    processor.graph_encoder = encoder
                    print("âœ… GraphEncoderä¿®å¤æˆåŠŸ")
                else:
                    print(f"âŒ GraphEncoderä¿®å¤å¤±è´¥")
                    return None
            except Exception as e:
                print(f"âŒ GraphEncoderä¿®å¤å¼‚å¸¸: {str(e)}")
                return None
        
        # 2. æ¨¡æ‹Ÿæ•°æ®å¤„ç†æµç¨‹
        query = "ç§‘æ¯”å’Œè©¹å§†æ–¯æœ‰ä»€ä¹ˆå…±åŒç‚¹ï¼Ÿ"
        graph_data = create_sample_graph_data()
        
        print(f"ğŸ“ æŸ¥è¯¢: {query}")
        print(f"ğŸ“Š å›¾æ•°æ®: {len(graph_data['nodes'])}ä¸ªèŠ‚ç‚¹, {len(graph_data['edges'])}æ¡è¾¹")
        
        # 3. å›¾ç¼–ç 
        if processor.graph_encoder:
            print("\nğŸ”„ æ‰§è¡Œå›¾ç¼–ç ...")
            encoding_result = processor._encode_graph_data(graph_data)
            
            if encoding_result and encoding_result['encoding_success']:
                print(f"âœ… å›¾ç¼–ç æˆåŠŸï¼ŒåµŒå…¥ç»´åº¦: {len(encoding_result['embedding'])}")
                
                # 4. å¤šæ¨¡æ€ä¸Šä¸‹æ–‡åˆ›å»º
                textual_context = {
                    'formatted_text': 'ç§‘æ¯”å’Œè©¹å§†æ–¯éƒ½æ˜¯NBAå†å²ä¸Šçš„ä¼Ÿå¤§çƒå‘˜ï¼Œä»–ä»¬éƒ½æ•ˆåŠ›è¿‡æ´›æ‰çŸ¶æ¹–äººé˜Ÿã€‚',
                    'content': 'åŸºäºå›¾è°±çš„åˆ†æç»“æœ'
                }
                
                print("\nğŸ­ åˆ›å»ºå¤šæ¨¡æ€ä¸Šä¸‹æ–‡...")
                multimodal_context = processor._create_multimodal_context(
                    textual_context,
                    encoding_result,
                    query
                )
                
                print(f"âœ… å¤šæ¨¡æ€ä¸Šä¸‹æ–‡åˆ›å»ºæˆåŠŸ")
                print(f"   æ–‡æœ¬é•¿åº¦: {len(multimodal_context.text_context)}")
                print(f"   å›¾åµŒå…¥: {'æœ‰' if multimodal_context.graph_embedding else 'æ— '}")
                print(f"   å…ƒæ•°æ®: {list(multimodal_context.metadata.keys())}")
                
                return multimodal_context
            else:
                print("âŒ å›¾ç¼–ç å¤±è´¥")
        else:
            print("âš ï¸ GraphEncoderæœªå¯ç”¨")
        
        return None
        
    except Exception as e:
        print(f"âŒ é›†æˆå·¥ä½œæµæ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()
        return None

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸš€ Phase 3 åŠŸèƒ½æ¼”ç¤º")
    print("GraphEncoder + ComplexGProcessor åŒæ¨¡å¼å¢å¼º")
    print("="*60)
    print()
    
    # æ£€æŸ¥Pythonç¯å¢ƒ
    print(f"ğŸ Pythonç‰ˆæœ¬: {sys.version}")
    print(f"ğŸ“ å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"ğŸ“¦ é¡¹ç›®è·¯å¾„: /Users/wang/i/graphos-qa")
    print()
    
    try:
        # æ¼”ç¤º1: GraphEncoder
        print("å¼€å§‹æ¼”ç¤º1...")
        graph_embedding = demo_graph_encoder()
        
        print()
        # æ¼”ç¤º2: MultimodalContext
        print("å¼€å§‹æ¼”ç¤º2...")
        multimodal_context = demo_multimodal_context()
        
        print()
        # æ¼”ç¤º3: ComplexGProcessor
        print("å¼€å§‹æ¼”ç¤º3...")
        processor = demo_complex_g_processor()
        
        print()
        # æ¼”ç¤º4: é›†æˆå·¥ä½œæµ
        print("å¼€å§‹æ¼”ç¤º4...")
        integration_result = demo_integration_workflow()
        
        print()
        print("="*60)
        print("ğŸ‰ Phase 3 åŠŸèƒ½æ¼”ç¤ºå®Œæˆï¼")
        print()
        print("ğŸ“‹ æ¼”ç¤ºæ€»ç»“:")
        print(f"   {'âœ…' if graph_embedding is not None else 'âŒ'} GraphEncoder: {'å›¾åˆ°å‘é‡ç¼–ç åŠŸèƒ½æ­£å¸¸' if graph_embedding is not None else 'å›¾ç¼–ç åŠŸèƒ½å¼‚å¸¸'}")
        print(f"   {'âœ…' if multimodal_context is not None else 'âŒ'} MultimodalContext: {'å¤šæ¨¡æ€æ•°æ®ç»“æ„å®Œæ•´' if multimodal_context is not None else 'å¤šæ¨¡æ€æ•°æ®ç»“æ„å¼‚å¸¸'}")
        print(f"   {'âœ…' if processor is not None else 'âŒ'} ComplexGProcessor: {'åŒæ¨¡å¼åˆ‡æ¢åŠŸèƒ½æ­£å¸¸' if processor is not None else 'åŒæ¨¡å¼åˆ‡æ¢åŠŸèƒ½å¼‚å¸¸'}")
        print(f"   {'âœ…' if integration_result is not None else 'âŒ'} é›†æˆå·¥ä½œæµ: {'ç«¯åˆ°ç«¯å¤„ç†æµç¨‹å®Œæ•´' if integration_result is not None else 'ç«¯åˆ°ç«¯å¤„ç†æµç¨‹å¼‚å¸¸'}")
        print()
        
        if all([graph_embedding is not None, multimodal_context is not None, processor is not None]):
            print("ğŸš€ Ready for production use!")
        else:
            print("âš ï¸ éƒ¨åˆ†åŠŸèƒ½å­˜åœ¨é—®é¢˜ï¼Œè¯·æ£€æŸ¥ç›¸å…³æ¨¡å—")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
