"""
ç›´æ¥æŸ¥è¯¢å¤„ç†å™¨ (Direct Processor)
ç”¨äºå¤„ç† ATTRIBUTE_QUERY ç±»å‹çš„æŸ¥è¯¢
é€‚ç”¨äºç›´æ¥çš„å±æ€§æŸ¥è¯¢ï¼Œå¦‚"ç§‘æ¯”å¤šå°‘å²"ã€"æ¹–äººé˜Ÿä¸»åœºåœ¨å“ªé‡Œ"
"""
from typing import Dict, Any, Optional, List
import logging
from .base_processor import BaseProcessor, ProcessorUtils
from app.rag.components import ProcessorDefaultConfigs

logger = logging.getLogger(__name__)

class DirectProcessor(BaseProcessor):
    """ç›´æ¥æŸ¥è¯¢å¤„ç†å™¨"""
    
    def __init__(self, config: Optional[ProcessorDefaultConfigs] = None):
        """åˆå§‹åŒ–ç›´æ¥æŸ¥è¯¢å¤„ç†å™¨"""
        if config is None:
            config = ProcessorDefaultConfigs.get_direct_processor_config()
        
        super().__init__(config)
        logger.info(f"ğŸ¯ åˆ›å»ºç›´æ¥æŸ¥è¯¢å¤„ç†å™¨")
    
    def _process_impl(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """å¤„ç†ç›´æ¥æŸ¥è¯¢"""
        logger.info(f"ğŸ” ç›´æ¥æŸ¥è¯¢å¤„ç†: {query}")
        
        try:
            # 1. å®ä½“æå–å’ŒæŸ¥è¯¢åˆ†æ
            query_analysis = self._analyze_query(query, context)
            
            # 2. æ£€ç´¢ç›¸å…³èŠ‚ç‚¹ (ä½¿ç”¨å…³é”®è¯æ£€ç´¢ï¼Œæ›´é€‚åˆç›´æ¥æŸ¥è¯¢)
            retrieved_nodes = self.retriever.retrieve(
                query, 
                top_k=min(8, self.config.max_tokens // 200)  # æ ¹æ®tokené™åˆ¶è°ƒæ•´
            )
            
            if not retrieved_nodes:
                return self._create_empty_result(query, "No relevant entities found")
            
            # 3. æ„å»ºç®€å•å­å›¾ (ç›´æ¥æŸ¥è¯¢é€šå¸¸ä¸éœ€è¦å¤æ‚å›¾ç»“æ„)
            seed_nodes = [node['node_id'] for node in retrieved_nodes[:5]]
            subgraph = self.graph_builder.build_subgraph(seed_nodes, query)
            
            if not ProcessorUtils.validate_subgraph(subgraph):
                return self._create_fallback_result(query, retrieved_nodes)
            
            # 4. æ–‡æœ¬åŒ– (ä½¿ç”¨ç´§å‡‘æ ¼å¼)
            contextualized_text = self.textualizer.textualize(subgraph, query)
            
            # 5. é™åˆ¶tokenæ•°é‡
            final_text = ProcessorUtils.limit_tokens(
                contextualized_text, 
                self.config.max_tokens
            )
            
            # 6. æ„å»ºç»“æœ
            result = {
                'success': True,
                'query': query,
                'context': context or {},
                'query_analysis': query_analysis,
                'retrieved_nodes_count': len(retrieved_nodes),
                'subgraph_summary': {
                    'nodes': subgraph['node_count'],
                    'edges': subgraph['edge_count'],
                    'algorithm': subgraph.get('algorithm', 'unknown')
                },
                'contextualized_text': final_text,
                'processing_strategy': 'direct_attribute_query',
                'confidence': self._calculate_confidence(retrieved_nodes, subgraph)
            }
            
            logger.info(f"âœ… ç›´æ¥æŸ¥è¯¢å¤„ç†å®Œæˆï¼ŒèŠ‚ç‚¹æ•°: {len(retrieved_nodes)}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ ç›´æ¥æŸ¥è¯¢å¤„ç†å¤±è´¥: {str(e)}")
            raise
    
    def _analyze_query(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææŸ¥è¯¢ç‰¹å¾"""
        analysis = {
            'query_type': 'attribute_query',
            'entities': ProcessorUtils.extract_entities_from_query(query),
            'intent': self._detect_attribute_intent(query),
            'direct_answer_expected': True,
            'complexity': 'simple'
        }
        
        # åˆ†æä¸Šä¸‹æ–‡
        if context:
            analysis['context_entities'] = context.get('entities', [])
            analysis['previous_queries'] = context.get('query_history', [])
        
        return analysis
    
    def _detect_attribute_intent(self, query: str) -> Dict[str, Any]:
        """æ£€æµ‹å±æ€§æŸ¥è¯¢æ„å›¾"""
        query_lower = query.lower()
        
        intent = {
            'attribute_type': 'unknown',
            'question_words': [],
            'target_entity': None
        }
        
        # æ‰©å±•çš„é—®è¯æ£€æµ‹ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        question_words_map = {
            # ä¸­æ–‡é—®è¯
            'å¤šå°‘': 'how_many', 'å¤šå¤§': 'how_old', 'ä»€ä¹ˆ': 'what', 'å“ªé‡Œ': 'where', 
            'å“ªä¸ª': 'which', 'è°': 'who', 'ä½•æ—¶': 'when', 'æ€ä¹ˆ': 'how',
            # è‹±æ–‡é—®è¯
            'how': 'how', 'what': 'what', 'where': 'where', 'which': 'which',
            'who': 'who', 'when': 'when', 'why': 'why', 'is': 'is', 'are': 'are'
        }
        
        for word, word_type in question_words_map.items():
            if word in query_lower:
                intent['question_words'].append(word_type)
        
        # æ‰©å±•çš„å±æ€§ç±»å‹æ£€æµ‹ï¼ˆæ”¯æŒä¸­è‹±æ–‡ï¼‰
        if any(word in query_lower for word in ['å¹´é¾„', 'å¤šå¤§', 'å²', 'age', 'old', 'years']):
            intent['attribute_type'] = 'age'
        elif any(word in query_lower for word in ['èº«é«˜', 'å¤šé«˜', 'height', 'tall']):
            intent['attribute_type'] = 'height'
        elif any(word in query_lower for word in ['ä½“é‡', 'å¤šé‡', 'weight']):
            intent['attribute_type'] = 'weight'
        elif any(word in query_lower for word in ['çƒé˜Ÿ', 'æ•ˆåŠ›', 'å“ªä¸ªé˜Ÿ', 'team', 'plays for']):
            intent['attribute_type'] = 'team'
        elif any(word in query_lower for word in ['ä½ç½®', 'æ‰“ä»€ä¹ˆä½ç½®', 'position']):
            intent['attribute_type'] = 'position'
        elif any(word in query_lower for word in ['å¾—åˆ†', 'åœºå‡å¾—åˆ†', 'points', 'scoring']):
            intent['attribute_type'] = 'scoring'
        elif any(word in query_lower for word in ['çƒè¡£', 'å·ç ', 'jersey', 'number']):
            intent['attribute_type'] = 'jersey_number'
        elif any(word in query_lower for word in ['ç”Ÿæ—¥', 'å‡ºç”Ÿ', 'born', 'birthday']):
            intent['attribute_type'] = 'birthday'
        
        # å°è¯•æå–ç›®æ ‡å®ä½“
        entities = ProcessorUtils.extract_entities_from_query(query)
        if entities['players']:
            intent['target_entity'] = entities['players'][0]
        elif entities['teams']:
            intent['target_entity'] = entities['teams'][0]
        
        return intent
    
    def _create_empty_result(self, query: str, reason: str) -> Dict[str, Any]:
        """åˆ›å»ºç©ºç»“æœ"""
        return {
            'success': True,
            'query': query,
            'context': {},
            'query_analysis': {'query_type': 'attribute_query'},
            'retrieved_nodes_count': 0,
            'subgraph_summary': {'nodes': 0, 'edges': 0, 'algorithm': 'none'},
            'contextualized_text': f"Sorry, {reason}. Please try a more specific query.",
            'processing_strategy': 'direct_attribute_query',
            'confidence': 0.0,
            'empty_reason': reason
        }
    
    def _create_fallback_result(self, query: str, retrieved_nodes: List[Dict]) -> Dict[str, Any]:
        """åˆ›å»ºå›é€€ç»“æœï¼ˆå½“å­å›¾æ„å»ºå¤±è´¥æ—¶ï¼‰"""
        # ç›´æ¥ä½¿ç”¨æ£€ç´¢åˆ°çš„èŠ‚ç‚¹ä¿¡æ¯
        fallback_text = self._format_retrieved_nodes(retrieved_nodes, query)
        
        return {
            'success': True,
            'query': query,
            'context': {},
            'query_analysis': {'query_type': 'attribute_query'},
            'retrieved_nodes_count': len(retrieved_nodes),
            'subgraph_summary': {'nodes': len(retrieved_nodes), 'edges': 0, 'algorithm': 'fallback'},
            'contextualized_text': fallback_text,
            'processing_strategy': 'direct_attribute_query_fallback',
            'confidence': 0.7
        }
    
    def _format_retrieved_nodes(self, nodes: List[Dict], query: str) -> str:
        """æ ¼å¼åŒ–æ£€ç´¢åˆ°çš„èŠ‚ç‚¹ä¿¡æ¯"""
        if not nodes:
            return "No relevant information found."
        
        text_parts = ["Found the following relevant information based on the query:"]
        
        # æŒ‰ç±»å‹åˆ†ç»„
        players = [n for n in nodes if n.get('type') == 'player']
        teams = [n for n in nodes if n.get('type') == 'team']
        
        # æ ¼å¼åŒ–çƒå‘˜ä¿¡æ¯
        if players:
            text_parts.append("\nçƒå‘˜ä¿¡æ¯ï¼š")
            for player in players[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                name = player.get('name', 'æœªçŸ¥çƒå‘˜')
                properties = player.get('properties', {})
                
                info_parts = [f"- {name}"]
                if properties.get('age'):
                    info_parts.append(f"å¹´é¾„{properties['age']}å²")
                
                text_parts.append(" ".join(info_parts))
        
        # æ ¼å¼åŒ–çƒé˜Ÿä¿¡æ¯
        if teams:
            text_parts.append("\nçƒé˜Ÿä¿¡æ¯ï¼š")
            for team in teams[:3]:  # æœ€å¤šæ˜¾ç¤º3ä¸ª
                name = team.get('name', 'æœªçŸ¥çƒé˜Ÿ')
                text_parts.append(f"- {name}")
        
        return "\n".join(text_parts)
    
    def _calculate_confidence(self, retrieved_nodes: List[Dict], subgraph: Dict[str, Any]) -> float:
        """è®¡ç®—ç»“æœç½®ä¿¡åº¦"""
        if not retrieved_nodes:
            return 0.0
        
        # åŸºç¡€ç½®ä¿¡åº¦
        base_confidence = 0.6
        
        # æ ¹æ®æ£€ç´¢èŠ‚ç‚¹æ•°é‡è°ƒæ•´
        node_bonus = min(0.2, len(retrieved_nodes) * 0.05)
        
        # æ ¹æ®ç›¸ä¼¼åº¦è°ƒæ•´
        similarities = [node.get('similarity', 0) for node in retrieved_nodes]
        if similarities:
            avg_similarity = sum(similarities) / len(similarities)
            similarity_bonus = avg_similarity * 0.2
        else:
            similarity_bonus = 0
        
        # æ ¹æ®å­å›¾è´¨é‡è°ƒæ•´
        subgraph_bonus = 0
        if subgraph and subgraph.get('node_count', 0) > 0:
            subgraph_bonus = min(0.1, subgraph['node_count'] * 0.02)
        
        total_confidence = base_confidence + node_bonus + similarity_bonus + subgraph_bonus
        return min(1.0, total_confidence)

# =============================================================================
# å·¥å‚å‡½æ•°
# =============================================================================

def create_direct_processor(custom_config: Optional[Dict[str, Any]] = None) -> DirectProcessor:
    """åˆ›å»ºç›´æ¥æŸ¥è¯¢å¤„ç†å™¨å®ä¾‹"""
    if custom_config:
        # å¦‚æœæä¾›äº†è‡ªå®šä¹‰é…ç½®ï¼Œæ›´æ–°é»˜è®¤é…ç½®
        config = ProcessorDefaultConfigs.get_direct_processor_config()
        
        # æ›´æ–°æ£€ç´¢å™¨é…ç½®
        if 'retriever' in custom_config:
            retriever_updates = custom_config['retriever']
            config.retriever_config.config.update(retriever_updates)
        
        # æ›´æ–°å›¾æ„å»ºå™¨é…ç½®
        if 'graph_builder' in custom_config:
            builder_updates = custom_config['graph_builder']
            config.graph_builder_config.config.update(builder_updates)
        
        # æ›´æ–°æ–‡æœ¬åŒ–å™¨é…ç½®
        if 'textualizer' in custom_config:
            textualizer_updates = custom_config['textualizer']
            config.textualizer_config.config.update(textualizer_updates)
        
        # æ›´æ–°å¤„ç†å™¨çº§åˆ«é…ç½®
        if 'cache_enabled' in custom_config:
            config.cache_enabled = custom_config['cache_enabled']
        if 'cache_ttl' in custom_config:
            config.cache_ttl = custom_config['cache_ttl']
        if 'max_tokens' in custom_config:
            config.max_tokens = custom_config['max_tokens']
        
        return DirectProcessor(config)
    else:
        return DirectProcessor()
