"""
Â§çÊùÇÂõæÂ§ÑÁêÜÂô® (Complex Graph Processor)
ÊîØÊåÅÂèåÊ®°ÂºèÁöÑRAGÂ§ÑÁêÜÂô®Ôºö‰º†ÁªüÊ®°ÂºèÂíåÂ¢ûÂº∫Ê®°Âºè
- ‰º†ÁªüÊ®°ÂºèÔºöÂü∫‰∫éÊñáÊú¨ÁöÑÊ£ÄÁ¥¢ÂíåÂõæË∞±ÊûÑÂª∫
- Â¢ûÂº∫Ê®°ÂºèÔºöÁªìÂêàGraphEncoderÁöÑÂ§öÊ®°ÊÄÅÂ§ÑÁêÜ

Âü∫‰∫éG-RetrieverËÆ∫ÊñáÁöÑÂ§öÊ®°ÊÄÅËûçÂêàÊñπÊ≥ï
"""
import time
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from app.rag.processors.base_processor import BaseProcessor
from app.rag.components import ProcessorConfig
from app.rag.components.graph_encoder import GraphEncoder, MultimodalContext, create_graph_encoder

logger = logging.getLogger(__name__)

@dataclass
class ComplexGProcessorConfig(ProcessorConfig):
    """ComplexGProcessorÈÖçÁΩÆ"""
    # Â§ÑÁêÜÊ®°ÂºèÈÖçÁΩÆ
    use_enhanced_mode: bool = False  # ÊòØÂê¶‰ΩøÁî®Â¢ûÂº∫Ê®°Âºè
    enable_multimodal_fusion: bool = False  # ÊòØÂê¶ÂêØÁî®Â§öÊ®°ÊÄÅËûçÂêà
    
    # GraphEncoderÈÖçÁΩÆ
    graph_encoder_enabled: bool = False
    graph_encoder_config: Optional[Dict[str, Any]] = None
    
    # Â¢ûÂº∫Ê®°ÂºèÁâπÂÆöÈÖçÁΩÆ
    min_graph_nodes: int = 3  # ÊúÄÂ∞èÂõæËäÇÁÇπÊï∞Ôºå‰Ωé‰∫éÊ≠§ÂÄº‰ΩøÁî®‰º†ÁªüÊ®°Âºè
    fusion_strategy: str = "concatenate"  # ËûçÂêàÁ≠ñÁï•: concatenate, weighted, attention
    
    # ÊÄßËÉΩÈÖçÁΩÆ
    fallback_to_traditional: bool = True  # Â¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•Êó∂ÊòØÂê¶ÂõûÈÄÄÂà∞‰º†ÁªüÊ®°Âºè

class ComplexGProcessor(BaseProcessor):
    """Â§çÊùÇÂõæÂ§ÑÁêÜÂô® - ÊîØÊåÅ‰º†ÁªüÂíåÂ¢ûÂº∫ÂèåÊ®°Âºè"""
    
    def __init__(self, config: ComplexGProcessorConfig):
        super().__init__(config)
        self.complex_config = config
        
        # GraphEncoderÁªÑ‰ª∂
        self.graph_encoder = None
        
        # Ê®°ÂºèÁä∂ÊÄÅ
        self.current_mode = "traditional"  # traditional | enhanced
        self.mode_switch_count = 0
        
        # ÁªüËÆ°‰ø°ÊÅØ
        self.enhanced_stats = {
            'traditional_mode_count': 0,
            'enhanced_mode_count': 0,
            'mode_switches': 0,
            'graph_encoding_time': 0.0,
            'multimodal_fusion_time': 0.0
        }
    
    def initialize(self) -> bool:
        """ÂàùÂßãÂåñÂ§ÑÁêÜÂô®"""
        try:
            # Ë∞ÉÁî®Âü∫Á±ªÂàùÂßãÂåñ
            if not super().initialize():
                return False
            
            # ÂàùÂßãÂåñGraphEncoderÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.complex_config.graph_encoder_enabled:
                self._initialize_graph_encoder()
            
            # Á°ÆÂÆöÈªòËÆ§Ê®°Âºè
            self.current_mode = "enhanced" if self.complex_config.use_enhanced_mode else "traditional"
            
            logger.info(f"‚úÖ ComplexGProcessorÂàùÂßãÂåñÂÆåÊàêÔºåÈªòËÆ§Ê®°Âºè: {self.current_mode}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå ComplexGProcessorÂàùÂßãÂåñÂ§±Ë¥•: {str(e)}")
            return False
    
    def _initialize_graph_encoder(self):
        """ÂàùÂßãÂåñGraphEncoderÁªÑ‰ª∂"""
        try:
            graph_config = self.complex_config.graph_encoder_config or {}
            self.graph_encoder = create_graph_encoder(graph_config)
            
            # Ë∞ÉÁî®GraphEncoderÁöÑÂàùÂßãÂåñÊñπÊ≥ï
            if self.graph_encoder.initialize():
                logger.info("‚úÖ GraphEncoderÁªÑ‰ª∂ÂàùÂßãÂåñÂÆåÊàê")
            else:
                logger.error("‚ùå GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•")
                self.graph_encoder = None
                if not self.complex_config.fallback_to_traditional:
                    raise RuntimeError("GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•")
            
        except Exception as e:
            logger.error(f"‚ùå GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•: {str(e)}")
            self.graph_encoder = None
            if not self.complex_config.fallback_to_traditional:
                raise
    
    def _process_impl(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ÂÖ∑‰ΩìÂ§ÑÁêÜÈÄªËæë - ÊîØÊåÅÂèåÊ®°Âºè"""
        try:
            # Á°ÆÂÆöÂ§ÑÁêÜÊ®°Âºè
            processing_mode = self._determine_processing_mode(query, context)
            
            if processing_mode == "enhanced" and self.graph_encoder:
                return self._process_enhanced_mode(query, context)
            else:
                return self._process_traditional_mode(query, context)
                
        except Exception as e:
            logger.error(f"‚ùå ComplexGProcessorÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            
            # Â¶ÇÊûúÂ¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•‰∏îÂÖÅËÆ∏ÂõûÈÄÄÔºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè
            if self.current_mode == "enhanced" and self.complex_config.fallback_to_traditional:
                logger.warning("üîÑ Â¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞‰º†ÁªüÊ®°Âºè")
                return self._process_traditional_mode(query, context)
            
            raise
    
    def _determine_processing_mode(self, query: str, context: Optional[Dict[str, Any]]) -> str:
        """Á°ÆÂÆöÂ§ÑÁêÜÊ®°Âºè"""
        # Â¶ÇÊûúGraphEncoderÊú™ÂêØÁî®Ôºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè
        if not self.graph_encoder:
            return "traditional"
        
        # Â¶ÇÊûúÂº∫Âà∂‰ΩøÁî®ÊüêÁßçÊ®°Âºè
        if context and context.get('force_mode'):
            return context['force_mode']
        
        # Âü∫‰∫éÈÖçÁΩÆÂíåÂõæÂ§çÊùÇÂ∫¶ÂÜ≥ÂÆö
        if self.complex_config.use_enhanced_mode:
            # Ê£ÄÊü•ÊòØÂê¶Êª°Ë∂≥Â¢ûÂº∫Ê®°ÂºèÁöÑÊù°‰ª∂
            if self._should_use_enhanced_mode(query, context):
                return "enhanced"
        
        return "traditional"
    
    def _should_use_enhanced_mode(self, query: str, context: Optional[Dict[str, Any]]) -> bool:
        """Âà§Êñ≠ÊòØÂê¶Â∫îËØ•‰ΩøÁî®Â¢ûÂº∫Ê®°Âºè"""
        try:
            # Âü∫Êú¨Ê£ÄÊü•ÔºöÊòØÂê¶ÊúâË∂≥Â§üÁöÑÂõæÊï∞ÊçÆ
            if context and 'graph_data' in context:
                graph_data = context['graph_data']
                if isinstance(graph_data, dict) and 'nodes' in graph_data:
                    node_count = len(graph_data['nodes'])
                    return node_count >= self.complex_config.min_graph_nodes
            
            # ÂèØ‰ª•Ê∑ªÂä†Êõ¥Â§öÊô∫ËÉΩÂà§Êñ≠ÈÄªËæë
            # ‰æãÂ¶ÇÔºöÊü•ËØ¢Â§çÊùÇÂ∫¶„ÄÅÂÆû‰ΩìÊï∞ÈáèÁ≠â
            
            return True  # ÈªòËÆ§‰ΩøÁî®Â¢ûÂº∫Ê®°ÂºèÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ê®°ÂºèÂà§Êñ≠Â§±Ë¥•Ôºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè: {str(e)}")
            return False
    
    def _process_traditional_mode(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜ"""
        start_time = time.time()
        
        try:
            self.enhanced_stats['traditional_mode_count'] += 1
            logger.info(f"üîÑ ‰ΩøÁî®‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜ: {query[:50]}...")
            
            # 1. ÊñáÊ°£Ê£ÄÁ¥¢
            retrieval_result = self.retriever.retrieve(query, context)
            
            # 2. ÂõæË∞±ÊûÑÂª∫
            graph_result = self.graph_builder.build_graph(
                query, 
                retrieval_result, 
                context
            )
            
            # 3. ÊñáÊú¨Âåñ
            textual_result = self.textualizer.textualize(
                query,
                graph_result,
                context
            )
            
            # ÊûÑÂª∫ÁªìÊûú
            result = {
                'success': True,
                'mode': 'traditional',
                'query': query,
                'retrieval': retrieval_result,
                'graph': graph_result,
                'textual_context': textual_result,
                'processing_time': time.time() - start_time
            }
            
            logger.info(f"‚úÖ ‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {result['processing_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå ‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            raise
    
    def _process_enhanced_mode(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜ - ÁªìÂêàGraphEncoder"""
        start_time = time.time()
        
        try:
            self.enhanced_stats['enhanced_mode_count'] += 1
            logger.info(f"üöÄ ‰ΩøÁî®Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜ: {query[:50]}...")
            
            # 1. ÊâßË°å‰º†ÁªüÊµÅÁ®ãËé∑ÂèñÂü∫Á°ÄÁªìÊûú
            traditional_result = self._process_traditional_mode(query, context)
            
            # 2. ÂõæÁºñÁ†Å - ÁîüÊàêÂõæÂµåÂÖ•
            graph_encoding_start = time.time()
            graph_embedding = self._encode_graph_data(traditional_result['graph'])
            graph_encoding_time = time.time() - graph_encoding_start
            self.enhanced_stats['graph_encoding_time'] += graph_encoding_time
            
            # 3. Â§öÊ®°ÊÄÅËûçÂêà
            fusion_start = time.time()
            multimodal_context = self._create_multimodal_context(
                traditional_result['textual_context'],
                graph_embedding,
                query
            )
            fusion_time = time.time() - fusion_start
            self.enhanced_stats['multimodal_fusion_time'] += fusion_time
            
            # ÊûÑÂª∫Â¢ûÂº∫ÁªìÊûú
            result = {
                'success': True,
                'mode': 'enhanced',
                'query': query,
                'traditional_result': traditional_result,
                'graph_embedding': graph_embedding,
                'multimodal_context': multimodal_context,
                'enhanced_metrics': {
                    'graph_encoding_time': graph_encoding_time,
                    'fusion_time': fusion_time,
                    'total_time': time.time() - start_time
                }
            }
            
            logger.info(f"‚úÖ Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {result['enhanced_metrics']['total_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            raise
    
    def _encode_graph_data(self, graph_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ÁºñÁ†ÅÂõæÊï∞ÊçÆ‰∏∫ÂêëÈáèË°®Á§∫"""
        try:
            if not self.graph_encoder:
                logger.warning("‚ö†Ô∏è GraphEncoderÊú™ÂàùÂßãÂåñ")
                return None
            
            # ‰ΩøÁî®GraphEncoderÁºñÁ†ÅÂõæÊï∞ÊçÆ
            encoding_result = self.graph_encoder.encode_graph(graph_data)
            
            return {
                'embedding': encoding_result.get('embedding'),
                'node_embeddings': encoding_result.get('node_embeddings'),
                'encoding_metadata': encoding_result.get('metadata', {}),
                'encoding_success': True
            }
            
        except Exception as e:
            logger.error(f"‚ùå ÂõæÁºñÁ†ÅÂ§±Ë¥•: {str(e)}")
            return {
                'embedding': None,
                'encoding_success': False,
                'error': str(e)
            }
    
    def _create_multimodal_context(
        self, 
        textual_context: Dict[str, Any], 
        graph_embedding: Optional[Dict[str, Any]], 
        query: str
    ) -> MultimodalContext:
        """ÂàõÂª∫Â§öÊ®°ÊÄÅ‰∏ä‰∏ãÊñá"""
        try:
            # ÊèêÂèñÊñáÊú¨Ë°®Á§∫
            text_content = ""
            if isinstance(textual_context, dict):
                text_content = textual_context.get('formatted_text', '')
                if not text_content:
                    text_content = str(textual_context.get('content', ''))
            
            # ÊèêÂèñÂõæÂµåÂÖ•
            graph_embed = None
            if graph_embedding and graph_embedding.get('encoding_success'):
                graph_embed = graph_embedding.get('embedding')
            
            # ÂàõÂª∫MultimodalContext
            multimodal_context = MultimodalContext(
                text_context=text_content,
                graph_embedding=graph_embed,
                metadata={
                    'query': query,
                    'fusion_strategy': self.complex_config.fusion_strategy,
                    'creation_time': time.time(),
                    'graph_encoding_success': graph_embedding.get('encoding_success', False) if graph_embedding else False
                }
            )
            
            return multimodal_context
            
        except Exception as e:
            logger.error(f"‚ùå Â§öÊ®°ÊÄÅ‰∏ä‰∏ãÊñáÂàõÂª∫Â§±Ë¥•: {str(e)}")
            # ËøîÂõû‰ªÖÂåÖÂê´ÊñáÊú¨ÁöÑ‰∏ä‰∏ãÊñá
            return MultimodalContext(
                text_context=str(textual_context),
                graph_embedding=None,
                metadata={'error': str(e), 'fallback': True}
            )
    
    def get_enhanced_stats(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÂ¢ûÂº∫ÁªüËÆ°‰ø°ÊÅØ"""
        base_stats = self.get_stats()
        
        enhanced_info = {
            'processing_modes': self.enhanced_stats.copy(),
            'current_mode': self.current_mode,
            'graph_encoder_enabled': self.graph_encoder is not None,
            'multimodal_fusion_enabled': self.complex_config.enable_multimodal_fusion,
            'config': {
                'use_enhanced_mode': self.complex_config.use_enhanced_mode,
                'min_graph_nodes': self.complex_config.min_graph_nodes,
                'fusion_strategy': self.complex_config.fusion_strategy,
                'fallback_enabled': self.complex_config.fallback_to_traditional
            }
        }
        
        base_stats['enhanced_info'] = enhanced_info
        return base_stats
    
    def switch_mode(self, mode: str) -> bool:
        """ÊâãÂä®ÂàáÊç¢Â§ÑÁêÜÊ®°Âºè"""
        if mode not in ['traditional', 'enhanced']:
            logger.error(f"‚ùå Êó†ÊïàÁöÑÂ§ÑÁêÜÊ®°Âºè: {mode}")
            return False
        
        if mode == 'enhanced' and not self.graph_encoder:
            logger.error("‚ùå GraphEncoderÊú™ÂêØÁî®ÔºåÊó†Ê≥ïÂàáÊç¢Âà∞Â¢ûÂº∫Ê®°Âºè")
            return False
        
        old_mode = self.current_mode
        self.current_mode = mode
        self.mode_switch_count += 1
        self.enhanced_stats['mode_switches'] += 1
        
        logger.info(f"üîÑ Ê®°ÂºèÂàáÊç¢: {old_mode} ‚Üí {mode}")
        return True
    
    def test_graph_encoder(self, test_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ÊµãËØïGraphEncoderÂäüËÉΩ"""
        if not self.graph_encoder:
            return {'success': False, 'error': 'GraphEncoderÊú™ÂêØÁî®'}
        
        try:
            # ‰ΩøÁî®ÊµãËØïÊï∞ÊçÆÊàñÂàõÂª∫ÁÆÄÂçïÊµãËØïÂõæ
            if not test_data:
                test_data = {
                    'nodes': [
                        {'id': 'player_1', 'label': 'Player', 'name': 'Ê¢ÖË•ø'},
                        {'id': 'team_1', 'label': 'Team', 'name': 'Â∑¥Â°ûÁΩóÈÇ£'}
                    ],
                    'edges': [
                        {'source': 'player_1', 'target': 'team_1', 'relation': 'plays_for'}
                    ]
                }
            
            result = self.graph_encoder.encode_graph(test_data)
            
            return {
                'success': True,
                'test_result': result,
                'encoder_info': {
                    'model_type': type(self.graph_encoder).__name__,
                    'has_model': hasattr(self.graph_encoder, 'model')
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


# =============================================================================
# Â∑•ÂéÇÂáΩÊï∞
# =============================================================================

def create_complex_g_processor(config_dict: Dict[str, Any]) -> ComplexGProcessor:
    """ÂàõÂª∫ComplexGProcessorÂÆû‰æã"""
    
    # ËΩ¨Êç¢ÈÖçÁΩÆ
    config = ComplexGProcessorConfig(
        processor_name=config_dict.get('processor_name', 'complex_g_processor'),
        cache_enabled=config_dict.get('cache_enabled', True),
        cache_ttl=config_dict.get('cache_ttl', 3600),
        max_tokens=config_dict.get('max_tokens', 4000),
        
        # ComplexGÁâπÂÆöÈÖçÁΩÆ
        use_enhanced_mode=config_dict.get('use_enhanced_mode', False),
        enable_multimodal_fusion=config_dict.get('enable_multimodal_fusion', False),
        graph_encoder_enabled=config_dict.get('graph_encoder_enabled', False),
        graph_encoder_config=config_dict.get('graph_encoder_config', {}),
        min_graph_nodes=config_dict.get('min_graph_nodes', 3),
        fusion_strategy=config_dict.get('fusion_strategy', 'concatenate'),
        fallback_to_traditional=config_dict.get('fallback_to_traditional', True),
        
        # ÁªÑ‰ª∂ÈÖçÁΩÆ
        retriever_config=config_dict.get('retriever_config'),
        graph_builder_config=config_dict.get('graph_builder_config'),
        textualizer_config=config_dict.get('textualizer_config')
    )
    
    return ComplexGProcessor(config)
