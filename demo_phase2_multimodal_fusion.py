#!/usr/bin/env python3
"""
Phase 2å¤šæ¨¡æ€èåˆæ¼”ç¤ºè„šæœ¬
å±•ç¤ºåŸºäºG-Retrieverçš„å›¾æ–‡èåˆæœºåˆ¶
"""
import sys
import os
import time
import logging

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.insert(0, project_root)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

def demo_graph_semantics_enhancement():
    """æ¼”ç¤ºå›¾è¯­ä¹‰å¢å¼ºåŠŸèƒ½"""
    print("ğŸ¯ æ¼”ç¤º1: å›¾è¯­ä¹‰å¢å¼º")
    print("=" * 50)
    
    try:
        from app.rag.processors.complex_g_processor import create_complex_g_processor
        
        # åˆ›å»ºå¢å¼ºæ¨¡å¼å¤„ç†å™¨
        processor = create_complex_g_processor({
            'processor_name': 'semantic_demo_processor',
            'use_enhanced_mode': True,
            'enable_multimodal_fusion': True,
            'fusion_strategy': 'concatenate'
        })
        
        # åˆ›å»ºå¤æ‚çš„ç¯®çƒå›¾æ•°æ®
        basketball_graph = {
            'nodes': [
                {'id': 'kobe', 'label': 'Player', 'name': 'ç§‘æ¯”'},
                {'id': 'lebron', 'label': 'Player', 'name': 'è©¹å§†æ–¯'},
                {'id': 'jordan', 'label': 'Player', 'name': 'ä¹”ä¸¹'},
                {'id': 'lakers', 'label': 'Team', 'name': 'æ¹–äººé˜Ÿ'},
                {'id': 'bulls', 'label': 'Team', 'name': 'å…¬ç‰›é˜Ÿ'},
                {'id': 'championship', 'label': 'Achievement', 'name': 'æ€»å† å†›'},
                {'id': 'finals_mvp', 'label': 'Achievement', 'name': 'FMVP'},
                {'id': 'scoring_title', 'label': 'Achievement', 'name': 'å¾—åˆ†ç‹'}
            ],
            'edges': [
                {'source': 'kobe', 'target': 'lakers', 'relation': 'plays_for'},
                {'source': 'lebron', 'target': 'lakers', 'relation': 'plays_for'},
                {'source': 'jordan', 'target': 'bulls', 'relation': 'plays_for'},
                {'source': 'kobe', 'target': 'championship', 'relation': 'won'},
                {'source': 'lebron', 'target': 'championship', 'relation': 'won'},
                {'source': 'jordan', 'target': 'championship', 'relation': 'won'},
                {'source': 'kobe', 'target': 'finals_mvp', 'relation': 'won'},
                {'source': 'lebron', 'target': 'finals_mvp', 'relation': 'won'},
                {'source': 'jordan', 'target': 'finals_mvp', 'relation': 'won'},
                {'source': 'kobe', 'target': 'scoring_title', 'relation': 'won'},
                {'source': 'jordan', 'target': 'scoring_title', 'relation': 'won'}
            ]
        }
        
        queries = [
            "ç§‘æ¯”å’Œè©¹å§†æ–¯çš„èŒä¸šæˆå°±å¯¹æ¯”",
            "ä¹”ä¸¹çš„å†å²åœ°ä½åˆ†æ",
            "æ¹–äººé˜Ÿçš„ä¼ å¥‡çƒå‘˜"
        ]
        
        for i, query in enumerate(queries, 1):
            print(f"\nğŸ“ æŸ¥è¯¢{i}: {query}")
            print("-" * 30)
            
            # å›¾æ‘˜è¦ç”Ÿæˆ
            summary = processor._generate_graph_summary(basketball_graph, query)
            print(f"ğŸ€ å›¾æ‘˜è¦: {summary}")
            
            # å®ä½“å…³ç³»åˆ†æ
            entity_analysis = processor._analyze_entities_and_relations(basketball_graph)
            print(f"ğŸ‘¥ å®ä½“åˆ†æ: {entity_analysis['entity_count']}ä¸ªå®ä½“ï¼Œ{entity_analysis['relation_count']}ä¸ªå…³ç³»")
            print(f"   å®ä½“ç±»å‹: {entity_analysis['entity_types']}")
            print(f"   å…³ç³»ç±»å‹: {entity_analysis['relation_types']}")
            
            # æŸ¥è¯¢ç›¸å…³æ€§åˆ†æ
            relevance_info = processor._analyze_query_relevance(basketball_graph, query)
            print(f"ğŸ¯ æŸ¥è¯¢ç›¸å…³æ€§: {relevance_info['relevance_score']:.2f}")
            print(f"   åŒ¹é…èŠ‚ç‚¹: {relevance_info['matched_nodes']}")
            print(f"   æŸ¥è¯¢å®ä½“: {relevance_info['query_entities']}")
        
        return True
        
    except Exception as e:
        print(f"âŒ å›¾è¯­ä¹‰å¢å¼ºæ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def demo_multimodal_fusion_strategies():
    """æ¼”ç¤ºå¤šæ¨¡æ€èåˆç­–ç•¥"""
    print("\nğŸ¯ æ¼”ç¤º2: å¤šæ¨¡æ€èåˆç­–ç•¥")
    print("=" * 50)
    
    try:
        from app.llm.factory import LLMFactory
        from app.llm.input_router import UnifiedInput
        from app.rag.components.graph_encoder import MultimodalContext
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®
        text_context = """
        æ ¹æ®å›¾è°±åˆ†æï¼Œç§‘æ¯”Â·å¸ƒè±æ©ç‰¹å’Œå‹’å¸ƒæœ—Â·è©¹å§†æ–¯éƒ½æ˜¯NBAå†å²ä¸Šæœ€æ°å‡ºçš„çƒå‘˜ã€‚
        ç§‘æ¯”åœ¨æ´›æ‰çŸ¶æ¹–äººé˜Ÿåº¦è¿‡äº†æ•´ä¸ª20å¹´èŒä¸šç”Ÿæ¶¯ï¼Œè·å¾—äº†5æ¬¡NBAæ€»å† å†›ã€2æ¬¡FMVPã€1æ¬¡å¸¸è§„èµ›MVPã€‚
        è©¹å§†æ–¯åˆ™åœ¨å…‹åˆ©å¤«å…°éª‘å£«ã€è¿ˆé˜¿å¯†çƒ­ç«å’Œæ´›æ‰çŸ¶æ¹–äººé˜Ÿæ•ˆåŠ›ï¼Œè·å¾—äº†4æ¬¡NBAæ€»å† å†›ã€4æ¬¡FMVPã€4æ¬¡å¸¸è§„èµ›MVPã€‚
        ä¸¤äººéƒ½æ˜¯å„è‡ªæ—¶ä»£çš„ä»£è¡¨æ€§äººç‰©ï¼Œåœ¨å¾—åˆ†ã€é¢†å¯¼åŠ›å’Œæ¯”èµ›å½±å“åŠ›æ–¹é¢éƒ½æœ‰å“è¶Šè¡¨ç°ã€‚
        """
        
        graph_embedding = [0.23, -0.15, 0.67, 0.42, -0.31, 0.89] * 21 + [0.11, 0.07]  # 128ç»´
        
        multimodal_context = MultimodalContext(
            text_context=text_context.strip(),
            graph_embedding=graph_embedding,
            metadata={
                'graph_summary': 'ç¯®çƒå›¾è°±åŒ…å«3ä¸ªä¼ å¥‡çƒå‘˜(ç§‘æ¯”ã€è©¹å§†æ–¯ã€ä¹”ä¸¹)ã€3ä¸ªçƒé˜Ÿå’Œå¤šé¡¹æˆå°±',
                'entity_analysis': {
                    'entity_count': 8, 
                    'relation_count': 12,
                    'entity_types': ['Player', 'Team', 'Achievement'],
                    'relation_types': ['plays_for', 'won']
                },
                'query_relevance': {
                    'relevance_score': 0.95,
                    'matched_nodes': ['kobe', 'lebron'],
                    'query_entities': ['ç§‘æ¯”', 'è©¹å§†æ–¯']
                }
            }
        )
        
        # æµ‹è¯•ä¸åŒèåˆç­–ç•¥
        strategies = ['concatenate', 'weighted', 'attention']
        
        for strategy in strategies:
            print(f"\nğŸ”§ {strategy.upper()}èåˆç­–ç•¥æ¼”ç¤º:")
            print("-" * 25)
            
            # åˆ›å»ºLLMç³»ç»Ÿ
            factory = LLMFactory()
            custom_config = {'fusion_strategy': strategy}
            llm_system = factory.create_system('macos_optimized', custom_config)
            
            if not llm_system.initialize():
                print(f"   âš ï¸ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥ï¼Œè·³è¿‡{strategy}ç­–ç•¥")
                continue
            
            # åˆ›å»ºç»Ÿä¸€è¾“å…¥
            unified_input = UnifiedInput(
                query="è¯·åˆ†æç§‘æ¯”å’Œè©¹å§†æ–¯çš„èŒä¸šæˆå°±å·®å¼‚",
                processor_type='complex_g',
                text_context=text_context.strip(),
                multimodal_context=multimodal_context,
                graph_embedding=graph_embedding,
                metadata={'fusion_demo': True}
            )
            
            # æµ‹è¯•èåˆå¤„ç†
            if llm_system.engine:
                # æ„å»ºåŸºç¡€prompt
                base_prompt = llm_system.engine._build_prompt(unified_input)
                print(f"   ğŸ“ åŸºç¡€Prompté•¿åº¦: {len(base_prompt)}")
                
                # åº”ç”¨å¤šæ¨¡æ€èåˆ
                processed_input = llm_system.engine._process_multimodal_input(unified_input, base_prompt)
                
                fusion_metadata = processed_input.get('fusion_metadata', {})
                if fusion_metadata.get('fusion_applied'):
                    print(f"   âœ… èåˆæˆåŠŸåº”ç”¨")
                    print(f"      å›¾åµŒå…¥ç»´åº¦: {fusion_metadata.get('graph_embedding_dim', 0)}")
                    print(f"      èåˆç­–ç•¥: {fusion_metadata.get('fusion_strategy', 'N/A')}")
                    
                    # æ£€æŸ¥èåˆæ–‡æœ¬
                    fusion_text = processed_input.get('text', '')
                    if '[å›¾è°±åˆ†æ]' in fusion_text:
                        print(f"      ğŸ“Š å›¾è°±ä¿¡æ¯å·²èå…¥æ–‡æœ¬")
                        # æå–å›¾è°±åˆ†æéƒ¨åˆ†
                        lines = fusion_text.split('\n')
                        for line in lines:
                            if 'å›¾è°±åˆ†æ' in line or 'ç¯®çƒå›¾è°±' in line:
                                print(f"         {line.strip()}")
                    
                    # æ£€æŸ¥é¢å¤–è¾“å…¥
                    extra_inputs = processed_input.get('extra_inputs')
                    if extra_inputs:
                        print(f"      ğŸ”— é¢å¤–è¾“å…¥: {list(extra_inputs.keys())}")
                        if strategy == 'weighted' and 'weights' in extra_inputs:
                            weights = extra_inputs['weights']
                            print(f"         æƒé‡ - æ–‡æœ¬: {weights['text']}, å›¾: {weights['graph']}")
                        elif strategy == 'attention' and 'attention_score' in extra_inputs:
                            score = extra_inputs['attention_score']
                            print(f"         æ³¨æ„åŠ›åˆ†æ•°: {score:.3f}")
                else:
                    print(f"   âš ï¸ èåˆæœªåº”ç”¨")
                    if 'error' in fusion_metadata:
                        print(f"      é”™è¯¯: {fusion_metadata['error']}")
            else:
                print(f"   âŒ LLMå¼•æ“æœªåˆ›å»º")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¤šæ¨¡æ€èåˆç­–ç•¥æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def demo_enhanced_complex_g_processor():
    """æ¼”ç¤ºå¢å¼ºçš„ComplexGProcessor"""
    print("\nğŸ¯ æ¼”ç¤º3: å¢å¼ºComplexGProcessorç«¯åˆ°ç«¯æµç¨‹")
    print("=" * 50)
    
    try:
        from app.rag.processors.complex_g_processor import create_complex_g_processor
        from app.llm.factory import LLMFactory
        from app.llm.input_router import create_input_router
        
        # 1. åˆ›å»ºå¢å¼ºæ¨¡å¼å¤„ç†å™¨
        processor_config = {
            'processor_name': 'demo_enhanced_processor',
            'use_enhanced_mode': True,
            'graph_encoder_enabled': True,
            'graph_encoder_config': {
                'model_config': {
                    'input_dim': 768,
                    'hidden_dim': 256,
                    'output_dim': 128
                }
            },
            'enable_multimodal_fusion': True,
            'fusion_strategy': 'concatenate',
            'min_graph_nodes': 3,
            'fallback_to_traditional': True
        }
        
        processor = create_complex_g_processor(processor_config)
        print(f"ğŸ”§ åˆ›å»ºå¤„ç†å™¨: {processor.processor_name}")
        print(f"   å½“å‰æ¨¡å¼: {processor.current_mode}")
        print(f"   å¤šæ¨¡æ€èåˆ: {processor.complex_config.enable_multimodal_fusion}")
        
        # 2. åˆ›å»ºLLMç³»ç»Ÿå’Œè·¯ç”±å™¨
        factory = LLMFactory()
        llm_system = factory.create_system('macos_optimized')
        input_router = create_input_router()
        
        print(f"âœ… ç³»ç»Ÿç»„ä»¶åˆ›å»ºå®Œæˆ")
        
        # 3. æ¨¡æ‹ŸRAGå¤„ç†æµç¨‹
        test_scenarios = [
            {
                'name': 'ç§‘æ¯”vsè©¹å§†æ–¯å¯¹æ¯”åˆ†æ',
                'query': 'å¯¹æ¯”åˆ†æç§‘æ¯”å’Œè©¹å§†æ–¯çš„èŒä¸šæˆå°±å’Œå†å²åœ°ä½',
                'mock_output': {
                    'success': True,
                    'mode': 'enhanced',
                    'query': 'å¯¹æ¯”åˆ†æç§‘æ¯”å’Œè©¹å§†æ–¯çš„èŒä¸šæˆå°±å’Œå†å²åœ°ä½',
                    'traditional_result': {
                        'textual_context': {
                            'formatted_text': 'ç§‘æ¯”Â·å¸ƒè±æ©ç‰¹ï¼š5æ¬¡NBAæ€»å† å†›ã€2æ¬¡FMVPã€18æ¬¡å…¨æ˜æ˜Ÿã€‚å‹’å¸ƒæœ—Â·è©¹å§†æ–¯ï¼š4æ¬¡NBAæ€»å† å†›ã€4æ¬¡FMVPã€19æ¬¡å…¨æ˜æ˜Ÿã€‚ä¸¤äººéƒ½æ˜¯å„è‡ªæ—¶ä»£çš„æ ‡æ†ã€‚'
                        }
                    },
                    'graph_embedding': {
                        'embedding': [0.2, -0.1, 0.3] * 42 + [0.15, 0.05],
                        'encoding_success': True,
                        'semantic_summary': 'ç¯®çƒå›¾è°±å±•ç°äº†ä¸¤ä½ä¼ å¥‡çƒå‘˜çš„èŒä¸šè½¨è¿¹å’Œæˆå°±å¯¹æ¯”',
                        'entity_analysis': {
                            'entity_count': 6, 
                            'relation_count': 12,
                            'entity_types': ['Player', 'Team', 'Achievement'],
                            'relation_types': ['plays_for', 'won', 'teammate']
                        },
                        'query_relevance': {
                            'relevance_score': 0.92,
                            'matched_nodes': ['kobe', 'lebron'],
                            'query_entities': ['ç§‘æ¯”', 'è©¹å§†æ–¯']
                        }
                    },
                    'enhanced_metadata': {
                        'fusion_strategy': 'concatenate',
                        'llm_ready': True
                    }
                }
            },
            {
                'name': 'ä¹”ä¸¹å†å²åœ°ä½åˆ†æ',
                'query': 'åˆ†æè¿ˆå…‹å°”ä¹”ä¸¹åœ¨NBAå†å²ä¸Šçš„åœ°ä½å’Œå½±å“',
                'mock_output': {
                    'success': True,
                    'mode': 'enhanced',
                    'query': 'åˆ†æè¿ˆå…‹å°”ä¹”ä¸¹åœ¨NBAå†å²ä¸Šçš„åœ°ä½å’Œå½±å“',
                    'traditional_result': {
                        'textual_context': {
                            'formatted_text': 'è¿ˆå…‹å°”Â·ä¹”ä¸¹è¢«å¹¿æ³›è®¤ä¸ºæ˜¯NBAå†å²ä¸Šæœ€ä¼Ÿå¤§çš„çƒå‘˜ã€‚6æ¬¡NBAæ€»å† å†›ã€6æ¬¡FMVPã€5æ¬¡å¸¸è§„èµ›MVPã€10æ¬¡å¾—åˆ†ç‹ï¼Œå®Œç¾çš„å­£åèµ›è®°å½•ã€‚'
                        }
                    },
                    'graph_embedding': {
                        'embedding': [0.4, -0.2, 0.5] * 42 + [0.25, 0.15],
                        'encoding_success': True,
                        'semantic_summary': 'ä¹”ä¸¹å›¾è°±æ˜¾ç¤ºäº†å…¶åœ¨å…¬ç‰›é˜Ÿçš„è¾‰ç…Œæˆå°±å’Œå†å²å½±å“',
                        'entity_analysis': {
                            'entity_count': 5,
                            'relation_count': 10,
                            'entity_types': ['Player', 'Team', 'Achievement'],
                            'relation_types': ['plays_for', 'won']
                        },
                        'query_relevance': {
                            'relevance_score': 0.88,
                            'matched_nodes': ['jordan'],
                            'query_entities': ['ä¹”ä¸¹']
                        }
                    },
                    'enhanced_metadata': {
                        'fusion_strategy': 'concatenate',
                        'llm_ready': True
                    }
                }
            }
        ]
        
        # 4. å¤„ç†æ¯ä¸ªåœºæ™¯
        for i, scenario in enumerate(test_scenarios, 1):
            print(f"\nğŸ“‹ åœºæ™¯{i}: {scenario['name']}")
            print("-" * 30)
            
            query = scenario['query']
            mock_output = scenario['mock_output']
            
            # è¾“å…¥è·¯ç”±
            unified_input = input_router.route_processor_output(mock_output, query)
            print(f"ğŸ¯ è¾“å…¥è·¯ç”±å®Œæˆ")
            print(f"   æŸ¥è¯¢: {query[:30]}...")
            print(f"   å¤šæ¨¡æ€æ•°æ®: {'æœ‰' if unified_input.has_multimodal_data() else 'æ— '}")
            
            # æ£€æŸ¥å¤šæ¨¡æ€ä¸Šä¸‹æ–‡
            if unified_input.multimodal_context:
                mc = unified_input.multimodal_context
                print(f"   æ–‡æœ¬é•¿åº¦: {len(mc.text_context)}")
                print(f"   å›¾åµŒå…¥ç»´åº¦: {len(mc.graph_embedding) if mc.graph_embedding else 0}")
                
                # æ˜¾ç¤ºå…ƒæ•°æ®ä¸­çš„è¯­ä¹‰ä¿¡æ¯
                metadata = mc.metadata
                if 'graph_summary' in metadata:
                    print(f"   ğŸ“Š å›¾æ‘˜è¦: {metadata['graph_summary']}")
                if 'entity_analysis' in metadata:
                    ea = metadata['entity_analysis']
                    print(f"   ğŸ‘¥ å®ä½“: {ea.get('entity_count', 0)}ä¸ªï¼Œå…³ç³»: {ea.get('relation_count', 0)}ä¸ª")
                if 'query_relevance' in metadata:
                    qr = metadata['query_relevance']
                    print(f"   ğŸ¯ ç›¸å…³æ€§: {qr.get('relevance_score', 0):.2f}")
            
            # LLMå¤„ç†ï¼ˆæ¨¡æ‹Ÿï¼‰
            if llm_system.initialize():
                if llm_system.engine:
                    prompt = llm_system.engine._build_prompt(unified_input)
                    processed_input = llm_system.engine._process_multimodal_input(unified_input, prompt)
                    
                    fusion_metadata = processed_input.get('fusion_metadata', {})
                    print(f"ğŸ”§ å¤šæ¨¡æ€èåˆ: {'æˆåŠŸ' if fusion_metadata.get('fusion_applied') else 'æœªåº”ç”¨'}")
                    
                    if fusion_metadata.get('fusion_applied'):
                        print(f"   ç­–ç•¥: {fusion_metadata.get('fusion_strategy', 'N/A')}")
                        print(f"   å›¾åµŒå…¥ç»´åº¦: {fusion_metadata.get('graph_embedding_dim', 0)}")
        
        print(f"\nğŸ“ˆ å¤„ç†å™¨ç»Ÿè®¡ä¿¡æ¯:")
        stats = processor.get_enhanced_stats()
        enhanced_info = stats.get('enhanced_info', {})
        processing_modes = enhanced_info.get('processing_modes', {})
        
        print(f"   ä¼ ç»Ÿæ¨¡å¼å¤„ç†: {processing_modes.get('traditional_mode_count', 0)}æ¬¡")
        print(f"   å¢å¼ºæ¨¡å¼å¤„ç†: {processing_modes.get('enhanced_mode_count', 0)}æ¬¡")
        print(f"   æ¨¡å¼åˆ‡æ¢: {processing_modes.get('mode_switches', 0)}æ¬¡")
        print(f"   å›¾ç¼–ç æ—¶é—´: {processing_modes.get('graph_encoding_time', 0):.3f}ç§’")
        print(f"   å¤šæ¨¡æ€èåˆæ—¶é—´: {processing_modes.get('multimodal_fusion_time', 0):.3f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"âŒ å¢å¼ºComplexGProcessoræ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return False

def demo_g_retriever_features():
    """æ¼”ç¤ºG-Retrieveræ ¸å¿ƒç‰¹æ€§"""
    print("\nğŸ¯ æ¼”ç¤º4: G-Retrieveræ ¸å¿ƒç‰¹æ€§")
    print("=" * 50)
    
    print("ğŸ“š G-Retrieverè®ºæ–‡æ ¸å¿ƒæ€æƒ³:")
    print("   1. å›¾åµŒå…¥æŠ•å½±: å°†å›¾ç»“æ„åµŒå…¥æŠ•å½±åˆ°LLMè¯æ±‡è¡¨ç©ºé—´")
    print("   2. å¤šæ¨¡æ€èåˆ: ç»“åˆæ–‡æœ¬å’Œå›¾è°±ä¿¡æ¯è¿›è¡Œæ¨ç†")
    print("   3. ç«¯åˆ°ç«¯è®­ç»ƒ: æ”¯æŒå›¾ç¼–ç å™¨å’ŒLLMçš„è”åˆä¼˜åŒ–")
    print()
    
    print("ğŸ¯ æœ¬é¡¹ç›®å®ç°çš„G-Retrieverç‰¹æ€§:")
    print("   âœ… GraphProjectoræŠ•å½±å™¨(128dâ†’4096d)")
    print("   âœ… å¤šç§èåˆç­–ç•¥(concatenate/weighted/attention)")
    print("   âœ… å¢å¼ºå›¾è¯­ä¹‰ç†è§£")
    print("   âœ… ComplexGProcessoråŒæ¨¡å¼æ”¯æŒ")
    print("   âœ… ç»Ÿä¸€å¤šæ¨¡æ€è¾“å…¥æ¥å£")
    print("   âœ… ç«¯åˆ°ç«¯å¤„ç†æµæ°´çº¿")
    print()
    
    try:
        from app.llm.llm_engine import GraphProjector
        
        print("ğŸ”§ GraphProjectoræŠ€æœ¯è§„æ ¼:")
        print(f"   è¾“å…¥ç»´åº¦: 128 (GraphEncoderè¾“å‡º)")
        print(f"   è¾“å‡ºç»´åº¦: 4096 (Phi-3-miniéšè—ç»´åº¦)")
        print(f"   éšè—å±‚ç»´åº¦: 512")
        print(f"   æ¿€æ´»å‡½æ•°: ReLU")
        print(f"   Dropout: 0.1")
        print(f"   æƒé‡åˆå§‹åŒ–: Xavier Uniform")
        print()
        
        # æ£€æŸ¥torchå¯ç”¨æ€§
        try:
            import torch
            projector = GraphProjector()
            param_count = sum(p.numel() for p in projector.parameters())
            print(f"   æ€»å‚æ•°é‡: {param_count:,}ä¸ª")
            print(f"   æŠ•å½±ç½‘ç»œå±‚æ•°: 3å±‚å…¨è¿æ¥")
            HAS_TORCH = True
        except ImportError:
            print(f"   âš ï¸ PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ˜¾ç¤ºå…·ä½“å‚æ•°")
            HAS_TORCH = False
        
        print("\nğŸ® èåˆç­–ç•¥è¯¦è§£:")
        print("   CONCATENATE: å°†å›¾è°±ä¿¡æ¯åµŒå…¥åˆ°promptæ–‡æœ¬ä¸­")
        print("   WEIGHTED: å¯¹å›¾åµŒå…¥åº”ç”¨æƒé‡(æ–‡æœ¬70%, å›¾30%)")
        print("   ATTENTION: åŸºäºå›¾åµŒå…¥ç»´åº¦è®¡ç®—æ³¨æ„åŠ›æƒé‡")
        print()
        
        print("ğŸ“Š è¯­ä¹‰å¢å¼ºåŠŸèƒ½:")
        print("   å›¾æ‘˜è¦ç”Ÿæˆ: è‡ªåŠ¨æå–å›¾è°±ç»“æ„ç‰¹å¾")
        print("   å®ä½“å…³ç³»åˆ†æ: ç»Ÿè®¡èŠ‚ç‚¹ç±»å‹å’Œå…³ç³»ç±»å‹")
        print("   æŸ¥è¯¢ç›¸å…³æ€§åˆ†æ: è®¡ç®—æŸ¥è¯¢ä¸å›¾è°±çš„åŒ¹é…åº¦")
        print("   å…ƒæ•°æ®å¢å¼º: ä¸°å¯ŒMultimodalContextä¿¡æ¯")
        
        return True
        
    except Exception as e:
        print(f"âŒ G-Retrieverç‰¹æ€§æ¼”ç¤ºå¤±è´¥: {str(e)}")
        return False

def main():
    """ä¸»æ¼”ç¤ºå‡½æ•°"""
    print("ğŸŒŸ Phase 2: å¤šæ¨¡æ€èåˆæ·±åº¦é›†æˆæ¼”ç¤º")
    print("åŸºäºG-Retrieverè®ºæ–‡çš„å›¾æ–‡èåˆå®ç°")
    print("=" * 70)
    
    demos = [
        ("å›¾è¯­ä¹‰å¢å¼ºåŠŸèƒ½", demo_graph_semantics_enhancement),
        ("å¤šæ¨¡æ€èåˆç­–ç•¥", demo_multimodal_fusion_strategies), 
        ("å¢å¼ºComplexGProcessorç«¯åˆ°ç«¯æµç¨‹", demo_enhanced_complex_g_processor),
        ("G-Retrieveræ ¸å¿ƒç‰¹æ€§", demo_g_retriever_features)
    ]
    
    results = []
    
    for demo_name, demo_func in demos:
        print(f"\n{'='*20} {demo_name} {'='*20}")
        
        start_time = time.time()
        try:
            result = demo_func()
            results.append((demo_name, result))
            elapsed = time.time() - start_time
            status = "âœ… æˆåŠŸ" if result else "âŒ å¤±è´¥"
            print(f"\n{status} - {demo_name} (è€—æ—¶: {elapsed:.2f}ç§’)")
        except Exception as e:
            results.append((demo_name, False))
            print(f"\nâŒ å¤±è´¥ - {demo_name}: {str(e)}")
    
    # æ€»ç»“
    print(f"\n{'='*70}")
    print("ğŸ¯ Phase 2æ¼”ç¤ºæ€»ç»“:")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for demo_name, result in results:
        status = "âœ…" if result else "âŒ"
        print(f"   {status} {demo_name}")
    
    print(f"\nğŸ“Š æ¼”ç¤ºç»“æœ: {passed}/{total} æˆåŠŸ")
    
    if passed == total:
        print("\nğŸ‰ Phase 2å¤šæ¨¡æ€èåˆå®ç°å®Œç¾å±•ç¤ºï¼")
        print("\nğŸš€ æŠ€æœ¯äº®ç‚¹:")
        print("   ğŸ§  GraphEncoderä¸LLMæ·±åº¦é›†æˆ")
        print("   ğŸ”— åŸºäºG-Retrieverçš„æŠ•å½±æœºåˆ¶")
        print("   ğŸ­ å¤šç§èåˆç­–ç•¥(concatenate/weighted/attention)")
        print("   ğŸ“Š æ™ºèƒ½å›¾è¯­ä¹‰ç†è§£ä¸å¢å¼º")
        print("   ğŸ”„ ComplexGProcessoråŒæ¨¡å¼æ”¯æŒ")
        print("   ğŸ¯ ç«¯åˆ°ç«¯å¤šæ¨¡æ€å¤„ç†æµæ°´çº¿")
        print("\nğŸŠ Phase 2åœ†æ»¡å®Œæˆï¼Œä¸ºPhase 3å¾®è°ƒä¼˜åŒ–å¥ å®šåšå®åŸºç¡€ï¼")
    else:
        print(f"\nâš ï¸ éƒ¨åˆ†æ¼”ç¤ºæœªå®Œå…¨æˆåŠŸï¼Œä½†æ ¸å¿ƒåŠŸèƒ½å·²å®ç°")
    
    return passed >= total * 0.8  # 80%æˆåŠŸç‡å³å¯

if __name__ == "__main__":
    success = main()
    print(f"\n{'='*70}")
    if success:
        print("ğŸŠ Phase 2å¤šæ¨¡æ€èåˆæ¼”ç¤ºåœ†æ»¡ç»“æŸï¼")
        print("â¡ï¸  å‡†å¤‡å¼€å§‹Phase 3: å¾®è°ƒä¼˜åŒ–")
    else:
        print("âš ï¸ æ¼”ç¤ºå®Œæˆï¼Œéƒ¨åˆ†åŠŸèƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–")
    sys.exit(0 if success else 1)
