"""
Â§çÊùÇÂõæÂ§ÑÁêÜÂô® (Complex Graph Processor)
ÊîØÊåÅÂèåÊ®°ÂºèÁöÑRAGÂ§ÑÁêÜÂô®Ôºö‰º†ÁªüÊ®°ÂºèÂíåÂ¢ûÂº∫Ê®°Âºè
- ‰º†ÁªüÊ®°ÂºèÔºöÂü∫‰∫éÊñáÊú¨ÁöÑÊ£ÄÁ¥¢ÂíåÂõæË∞±ÊûÑÂª∫
- Â¢ûÂº∫Ê®°ÂºèÔºöÁªìÂêàGraphEncoderÁöÑÂ§öÊ®°ÊÄÅÂ§ÑÁêÜ

Âü∫‰∫éG-RetrieverËÆ∫ÊñáÁöÑÂ§öÊ®°ÊÄÅËûçÂêàÊñπÊ≥ï
"""
import time
import logging
from typing import Dict, Any, Optional, List
from dataclasses import dataclass

from app.rag.processors.base_processor import BaseProcessor
from app.rag.components import ProcessorConfig
from app.rag.components.graph_encoder import GraphEncoder, MultimodalContext, create_graph_encoder

logger = logging.getLogger(__name__)

@dataclass
class ComplexGProcessorConfig(ProcessorConfig):
    """ComplexGProcessorÈÖçÁΩÆ"""
    # Â§ÑÁêÜÊ®°ÂºèÈÖçÁΩÆ
    use_enhanced_mode: bool = False  # ÊòØÂê¶‰ΩøÁî®Â¢ûÂº∫Ê®°Âºè
    enable_multimodal_fusion: bool = False  # ÊòØÂê¶ÂêØÁî®Â§öÊ®°ÊÄÅËûçÂêà
    
    # GraphEncoderÈÖçÁΩÆ
    graph_encoder_enabled: bool = False
    graph_encoder_config: Optional[Dict[str, Any]] = None
    
    # Â¢ûÂº∫Ê®°ÂºèÁâπÂÆöÈÖçÁΩÆ
    min_graph_nodes: int = 3  # ÊúÄÂ∞èÂõæËäÇÁÇπÊï∞Ôºå‰Ωé‰∫éÊ≠§ÂÄº‰ΩøÁî®‰º†ÁªüÊ®°Âºè
    fusion_strategy: str = "concatenate"  # ËûçÂêàÁ≠ñÁï•: concatenate, weighted, attention
    
    # ÊÄßËÉΩÈÖçÁΩÆ
    fallback_to_traditional: bool = True  # Â¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•Êó∂ÊòØÂê¶ÂõûÈÄÄÂà∞‰º†ÁªüÊ®°Âºè

class ComplexGProcessor(BaseProcessor):
    """Â§çÊùÇÂõæÂ§ÑÁêÜÂô® - ÊîØÊåÅ‰º†ÁªüÂíåÂ¢ûÂº∫ÂèåÊ®°Âºè"""
    
    def __init__(self, config: ComplexGProcessorConfig):
        super().__init__(config)
        self.complex_config = config
        
        # GraphEncoderÁªÑ‰ª∂
        self.graph_encoder = None
        
        # Ê®°ÂºèÁä∂ÊÄÅ
        self.current_mode = "traditional"  # traditional | enhanced
        self.mode_switch_count = 0
        
        # ÁªüËÆ°‰ø°ÊÅØ
        self.enhanced_stats = {
            'traditional_mode_count': 0,
            'enhanced_mode_count': 0,
            'mode_switches': 0,
            'graph_encoding_time': 0.0,
            'multimodal_fusion_time': 0.0
        }
    
    def initialize(self) -> bool:
        """ÂàùÂßãÂåñÂ§ÑÁêÜÂô®"""
        try:
            # Ë∞ÉÁî®Âü∫Á±ªÂàùÂßãÂåñ
            if not super().initialize():
                return False
            
            # ÂàùÂßãÂåñGraphEncoderÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            if self.complex_config.graph_encoder_enabled:
                self._initialize_graph_encoder()
            
            # Á°ÆÂÆöÈªòËÆ§Ê®°Âºè
            self.current_mode = "enhanced" if self.complex_config.use_enhanced_mode else "traditional"
            
            logger.info(f"‚úÖ ComplexGProcessorÂàùÂßãÂåñÂÆåÊàêÔºåÈªòËÆ§Ê®°Âºè: {self.current_mode}")
            return True
            
        except Exception as e:
            logger.error(f"‚ùå ComplexGProcessorÂàùÂßãÂåñÂ§±Ë¥•: {str(e)}")
            return False
    
    def _initialize_graph_encoder(self):
        """ÂàùÂßãÂåñGraphEncoderÁªÑ‰ª∂"""
        try:
            graph_config = self.complex_config.graph_encoder_config or {}
            self.graph_encoder = create_graph_encoder(graph_config)
            
            # Ë∞ÉÁî®GraphEncoderÁöÑÂàùÂßãÂåñÊñπÊ≥ï
            if self.graph_encoder.initialize():
                logger.info("‚úÖ GraphEncoderÁªÑ‰ª∂ÂàùÂßãÂåñÂÆåÊàê")
            else:
                logger.error("‚ùå GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•")
                self.graph_encoder = None
                if not self.complex_config.fallback_to_traditional:
                    raise RuntimeError("GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•")
            
        except Exception as e:
            logger.error(f"‚ùå GraphEncoderÂàùÂßãÂåñÂ§±Ë¥•: {str(e)}")
            self.graph_encoder = None
            if not self.complex_config.fallback_to_traditional:
                raise
    
    def _process_impl(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """ÂÖ∑‰ΩìÂ§ÑÁêÜÈÄªËæë - ÊîØÊåÅÂèåÊ®°Âºè"""
        try:
            # Á°ÆÂÆöÂ§ÑÁêÜÊ®°Âºè
            processing_mode = self._determine_processing_mode(query, context)
            
            if processing_mode == "enhanced" and self.graph_encoder:
                return self._process_enhanced_mode(query, context)
            else:
                return self._process_traditional_mode(query, context)
                
        except Exception as e:
            logger.error(f"‚ùå ComplexGProcessorÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            
            # Â¶ÇÊûúÂ¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•‰∏îÂÖÅËÆ∏ÂõûÈÄÄÔºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè
            if self.current_mode == "enhanced" and self.complex_config.fallback_to_traditional:
                logger.warning("üîÑ Â¢ûÂº∫Ê®°ÂºèÂ§±Ë¥•ÔºåÂõûÈÄÄÂà∞‰º†ÁªüÊ®°Âºè")
                return self._process_traditional_mode(query, context)
            
            raise
    
    def _determine_processing_mode(self, query: str, context: Optional[Dict[str, Any]]) -> str:
        """Á°ÆÂÆöÂ§ÑÁêÜÊ®°Âºè"""
        # Â¶ÇÊûúGraphEncoderÊú™ÂêØÁî®Ôºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè
        if not self.graph_encoder:
            return "traditional"
        
        # Â¶ÇÊûúÂº∫Âà∂‰ΩøÁî®ÊüêÁßçÊ®°Âºè
        if context and context.get('force_mode'):
            return context['force_mode']
        
        # Âü∫‰∫éÈÖçÁΩÆÂíåÂõæÂ§çÊùÇÂ∫¶ÂÜ≥ÂÆö
        if self.complex_config.use_enhanced_mode:
            # Ê£ÄÊü•ÊòØÂê¶Êª°Ë∂≥Â¢ûÂº∫Ê®°ÂºèÁöÑÊù°‰ª∂
            if self._should_use_enhanced_mode(query, context):
                return "enhanced"
        
        return "traditional"
    
    def _should_use_enhanced_mode(self, query: str, context: Optional[Dict[str, Any]]) -> bool:
        """Âà§Êñ≠ÊòØÂê¶Â∫îËØ•‰ΩøÁî®Â¢ûÂº∫Ê®°Âºè"""
        try:
            # Âü∫Êú¨Ê£ÄÊü•ÔºöÊòØÂê¶ÊúâË∂≥Â§üÁöÑÂõæÊï∞ÊçÆ
            if context and 'graph_data' in context:
                graph_data = context['graph_data']
                if isinstance(graph_data, dict) and 'nodes' in graph_data:
                    node_count = len(graph_data['nodes'])
                    return node_count >= self.complex_config.min_graph_nodes
            
            # ÂèØ‰ª•Ê∑ªÂä†Êõ¥Â§öÊô∫ËÉΩÂà§Êñ≠ÈÄªËæë
            # ‰æãÂ¶ÇÔºöÊü•ËØ¢Â§çÊùÇÂ∫¶„ÄÅÂÆû‰ΩìÊï∞ÈáèÁ≠â
            
            return True  # ÈªòËÆ§‰ΩøÁî®Â¢ûÂº∫Ê®°ÂºèÔºàÂ¶ÇÊûúÂêØÁî®Ôºâ
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Ê®°ÂºèÂà§Êñ≠Â§±Ë¥•Ôºå‰ΩøÁî®‰º†ÁªüÊ®°Âºè: {str(e)}")
            return False
    
    def _process_traditional_mode(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜ"""
        start_time = time.time()
        
        try:
            self.enhanced_stats['traditional_mode_count'] += 1
            logger.info(f"üîÑ ‰ΩøÁî®‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜ: {query[:50]}...")
            
            # 1. ÊñáÊ°£Ê£ÄÁ¥¢
            retrieval_result = self.retriever.retrieve(query, context)
            
            # 2. ÂõæË∞±ÊûÑÂª∫
            graph_result = self.graph_builder.build_graph(
                query, 
                retrieval_result, 
                context
            )
            
            # 3. ÊñáÊú¨Âåñ
            textual_result = self.textualizer.textualize(
                query,
                graph_result,
                context
            )
            
            # ÊûÑÂª∫ÁªìÊûú
            result = {
                'success': True,
                'mode': 'traditional',
                'query': query,
                'retrieval': retrieval_result,
                'graph': graph_result,
                'textual_context': textual_result,
                'processing_time': time.time() - start_time
            }
            
            logger.info(f"‚úÖ ‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {result['processing_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå ‰º†ÁªüÊ®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            raise
    
    def _process_enhanced_mode(self, query: str, context: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜ - ÁªìÂêàGraphEncoder"""
        start_time = time.time()
        
        try:
            self.enhanced_stats['enhanced_mode_count'] += 1
            logger.info(f"üöÄ ‰ΩøÁî®Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜ: {query[:50]}...")
            
            # 1. ÊâßË°å‰º†ÁªüÊµÅÁ®ãËé∑ÂèñÂü∫Á°ÄÁªìÊûú
            traditional_result = self._process_traditional_mode(query, context)
            
            # 2. ÂõæÁºñÁ†Å - ÁîüÊàêÂõæÂµåÂÖ•
            graph_encoding_start = time.time()
            graph_embedding = self._encode_graph_data(traditional_result['graph'])
            graph_encoding_time = time.time() - graph_encoding_start
            self.enhanced_stats['graph_encoding_time'] += graph_encoding_time
            
            # 3. Â¢ûÂº∫ÂõæÂµåÂÖ•ÁöÑËØ≠‰πâÁêÜËß£
            enhanced_graph_info = self._enhance_graph_semantics(
                graph_embedding, 
                traditional_result['graph'], 
                query
            )
            
            # 4. Â§öÊ®°ÊÄÅËûçÂêà
            fusion_start = time.time()
            multimodal_context = self._create_multimodal_context(
                traditional_result['textual_context'],
                enhanced_graph_info,
                query
            )
            fusion_time = time.time() - fusion_start
            self.enhanced_stats['multimodal_fusion_time'] += fusion_time
            
            # ÊûÑÂª∫Â¢ûÂº∫ÁªìÊûú
            result = {
                'success': True,
                'mode': 'enhanced',
                'query': query,
                'traditional_result': traditional_result,
                'graph_embedding': enhanced_graph_info,
                'multimodal_context': multimodal_context,
                'enhanced_metadata': {
                    'graph_summary': enhanced_graph_info.get('semantic_summary', ''),
                    'fusion_strategy': self.complex_config.fusion_strategy,
                    'llm_ready': True
                },
                'enhanced_metrics': {
                    'graph_encoding_time': graph_encoding_time,
                    'fusion_time': fusion_time,
                    'total_time': time.time() - start_time
                }
            }
            
            logger.info(f"‚úÖ Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜÂÆåÊàêÔºåËÄóÊó∂: {result['enhanced_metrics']['total_time']:.2f}s")
            return result
            
        except Exception as e:
            logger.error(f"‚ùå Â¢ûÂº∫Ê®°ÂºèÂ§ÑÁêÜÂ§±Ë¥•: {str(e)}")
            raise
    
    def _enhance_graph_semantics(self, graph_embedding: Optional[Dict[str, Any]], 
                                graph_data: Dict[str, Any], query: str) -> Dict[str, Any]:
        """Â¢ûÂº∫ÂõæÂµåÂÖ•ÁöÑËØ≠‰πâÁêÜËß£"""
        try:
            if not graph_embedding or not graph_embedding.get('encoding_success'):
                return graph_embedding or {}
            
            # Âü∫Á°Ä‰ø°ÊÅØ
            enhanced_info = graph_embedding.copy()
            
            # Ê∑ªÂä†ËØ≠‰πâÊëòË¶Å
            semantic_summary = self._generate_graph_summary(graph_data, query)
            enhanced_info['semantic_summary'] = semantic_summary
            
            # Ê∑ªÂä†ÂÆû‰ΩìÂÖ≥Á≥ªÂàÜÊûê
            entity_analysis = self._analyze_entities_and_relations(graph_data)
            enhanced_info['entity_analysis'] = entity_analysis
            
            # Ê∑ªÂä†Êü•ËØ¢Áõ∏ÂÖ≥ÊÄßÂàÜÊûê
            relevance_info = self._analyze_query_relevance(graph_data, query)
            enhanced_info['query_relevance'] = relevance_info
            
            return enhanced_info
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ÂõæËØ≠‰πâÂ¢ûÂº∫Â§±Ë¥•: {str(e)}")
            return graph_embedding or {}
    
    def _generate_graph_summary(self, graph_data: Dict[str, Any], query: str) -> str:
        """ÁîüÊàêÂõæË∞±ÊëòË¶Å"""
        try:
            summary_parts = []
            
            # ÂàÜÊûêÂõæÁªìÊûÑ
            if 'graph_structure' in graph_data:
                structure = graph_data['graph_structure']
                node_count = structure.get('num_nodes', 0)
                edge_count = structure.get('num_edges', 0)
                summary_parts.append(f"ÂåÖÂê´{node_count}‰∏™ÂÆû‰ΩìÂíå{edge_count}‰∏™ÂÖ≥Á≥ª")
            
            # ÂàÜÊûêÂÆû‰ΩìÁ±ªÂûã
            if 'metadata' in graph_data:
                metadata = graph_data['metadata']
                if 'entity_types' in metadata and metadata['entity_types']:
                    types = metadata['entity_types'][:3]  # ÂèñÂâç3‰∏™Á±ªÂûã
                    summary_parts.append(f"‰∏ªË¶ÅÂÆû‰ΩìÁ±ªÂûãÔºö{', '.join(types)}")
            
            # ÂàÜÊûêÂÖ≥ÈîÆËäÇÁÇπ
            if 'key_nodes' in graph_data:
                key_nodes = graph_data['key_nodes'][:3]  # ÂèñÂâç3‰∏™ÂÖ≥ÈîÆËäÇÁÇπ
                if key_nodes:
                    summary_parts.append(f"ÂÖ≥ÈîÆÂÆû‰ΩìÔºö{', '.join(key_nodes)}")
            
            base_summary = "ÂõæË∞±" + "Ôºå".join(summary_parts) if summary_parts else "ÂõæË∞±ÁªìÊûÑ‰ø°ÊÅØ"
            
            # Ê∑ªÂä†Êü•ËØ¢Áõ∏ÂÖ≥ÊÄß
            if query:
                base_summary += f"Ôºå‰∏éÊü•ËØ¢'{query[:20]}...'Áõ∏ÂÖ≥"
            
            return base_summary
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ÂõæË∞±ÊëòË¶ÅÁîüÊàêÂ§±Ë¥•: {str(e)}")
            return "ÂõæË∞±ÁªìÊûÑÁâπÂæÅ"
    
    def _analyze_entities_and_relations(self, graph_data: Dict[str, Any]) -> Dict[str, Any]:
        """ÂàÜÊûêÂÆû‰ΩìÂíåÂÖ≥Á≥ª"""
        try:
            analysis = {
                'entity_count': 0,
                'relation_count': 0,
                'entity_types': [],
                'relation_types': []
            }
            
            # ÂàÜÊûêËäÇÁÇπ
            if 'nodes' in graph_data:
                nodes = graph_data['nodes']
                analysis['entity_count'] = len(nodes)
                
                # Êî∂ÈõÜÂÆû‰ΩìÁ±ªÂûã
                entity_types = set()
                for node in nodes:
                    if 'label' in node:
                        entity_types.add(node['label'])
                analysis['entity_types'] = list(entity_types)
            
            # ÂàÜÊûêËæπ
            if 'edges' in graph_data:
                edges = graph_data['edges']
                analysis['relation_count'] = len(edges)
                
                # Êî∂ÈõÜÂÖ≥Á≥ªÁ±ªÂûã
                relation_types = set()
                for edge in edges:
                    if 'relation' in edge:
                        relation_types.add(edge['relation'])
                analysis['relation_types'] = list(relation_types)
            
            return analysis
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è ÂÆû‰ΩìÂÖ≥Á≥ªÂàÜÊûêÂ§±Ë¥•: {str(e)}")
            return {}
    
    def _analyze_query_relevance(self, graph_data: Dict[str, Any], query: str) -> Dict[str, Any]:
        """ÂàÜÊûêÊü•ËØ¢Áõ∏ÂÖ≥ÊÄß"""
        try:
            relevance_info = {
                'query_entities': [],
                'matched_nodes': [],
                'relevance_score': 0.0
            }
            
            # ÁÆÄÂçïÁöÑÊü•ËØ¢ÂÆû‰ΩìÊèêÂèñÔºàÂÆûÈôÖÂ∫îÁî®‰∏≠ÂèØËÉΩÈúÄË¶ÅÊõ¥Â§çÊùÇÁöÑNERÔºâ
            query_lower = query.lower()
            query_entities = []
            
            # ‰ªéÂõæ‰∏≠ÂØªÊâæÂåπÈÖçÁöÑÂÆû‰Ωì
            if 'nodes' in graph_data:
                matched_nodes = []
                for node in graph_data['nodes']:
                    node_name = node.get('name', '').lower()
                    if node_name and node_name in query_lower:
                        matched_nodes.append(node['id'])
                        query_entities.append(node_name)
                
                relevance_info['query_entities'] = query_entities
                relevance_info['matched_nodes'] = matched_nodes
                
                # ËÆ°ÁÆóÁõ∏ÂÖ≥ÊÄßÂàÜÊï∞
                if len(matched_nodes) > 0:
                    relevance_info['relevance_score'] = min(1.0, len(matched_nodes) / 3.0)
            
            return relevance_info
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Êü•ËØ¢Áõ∏ÂÖ≥ÊÄßÂàÜÊûêÂ§±Ë¥•: {str(e)}")
            return {}
    
    def _encode_graph_data(self, graph_data: Dict[str, Any]) -> Optional[Dict[str, Any]]:
        """ÁºñÁ†ÅÂõæÊï∞ÊçÆ‰∏∫ÂêëÈáèË°®Á§∫"""
        try:
            if not self.graph_encoder:
                logger.warning("‚ö†Ô∏è GraphEncoderÊú™ÂàùÂßãÂåñ")
                return None
            
            # ‰ΩøÁî®GraphEncoderÁºñÁ†ÅÂõæÊï∞ÊçÆ
            encoding_result = self.graph_encoder.encode_graph(graph_data)
            
            return {
                'embedding': encoding_result.get('embedding'),
                'node_embeddings': encoding_result.get('node_embeddings'),
                'encoding_metadata': encoding_result.get('metadata', {}),
                'encoding_success': True
            }
            
        except Exception as e:
            logger.error(f"‚ùå ÂõæÁºñÁ†ÅÂ§±Ë¥•: {str(e)}")
            return {
                'embedding': None,
                'encoding_success': False,
                'error': str(e)
            }
    
    def _create_multimodal_context(
        self, 
        textual_context: Dict[str, Any], 
        graph_embedding: Optional[Dict[str, Any]], 
        query: str
    ) -> MultimodalContext:
        """ÂàõÂª∫Â§öÊ®°ÊÄÅ‰∏ä‰∏ãÊñá"""
        try:
            # ÊèêÂèñÊñáÊú¨Ë°®Á§∫
            text_content = ""
            if isinstance(textual_context, dict):
                text_content = textual_context.get('formatted_text', '')
                if not text_content:
                    text_content = str(textual_context.get('content', ''))
            
            # ÊèêÂèñÂõæÂµåÂÖ•
            graph_embed = None
            if graph_embedding and graph_embedding.get('encoding_success'):
                graph_embed = graph_embedding.get('embedding')
            
            # ÊûÑÂª∫Â¢ûÂº∫ÁöÑÂÖÉÊï∞ÊçÆ
            enhanced_metadata = {
                'query': query,
                'fusion_strategy': self.complex_config.fusion_strategy,
                'creation_time': time.time(),
                'graph_encoding_success': graph_embedding.get('encoding_success', False) if graph_embedding else False
            }
            
            # Ê∑ªÂä†ÂõæËØ≠‰πâ‰ø°ÊÅØÂà∞ÂÖÉÊï∞ÊçÆ
            if graph_embedding:
                if 'semantic_summary' in graph_embedding:
                    enhanced_metadata['graph_summary'] = graph_embedding['semantic_summary']
                if 'entity_analysis' in graph_embedding:
                    enhanced_metadata['entity_analysis'] = graph_embedding['entity_analysis']
                if 'query_relevance' in graph_embedding:
                    enhanced_metadata['query_relevance'] = graph_embedding['query_relevance']
            
            # ÂàõÂª∫MultimodalContext
            multimodal_context = MultimodalContext(
                text_context=text_content,
                graph_embedding=graph_embed,
                metadata=enhanced_metadata
            )
            
            return multimodal_context
            
        except Exception as e:
            logger.error(f"‚ùå Â§öÊ®°ÊÄÅ‰∏ä‰∏ãÊñáÂàõÂª∫Â§±Ë¥•: {str(e)}")
            # ËøîÂõû‰ªÖÂåÖÂê´ÊñáÊú¨ÁöÑ‰∏ä‰∏ãÊñá
            return MultimodalContext(
                text_context=str(textual_context),
                graph_embedding=None,
                metadata={'error': str(e), 'fallback': True}
            )
    
    def get_enhanced_stats(self) -> Dict[str, Any]:
        """Ëé∑ÂèñÂ¢ûÂº∫ÁªüËÆ°‰ø°ÊÅØ"""
        base_stats = self.get_stats()
        
        enhanced_info = {
            'processing_modes': self.enhanced_stats.copy(),
            'current_mode': self.current_mode,
            'graph_encoder_enabled': self.graph_encoder is not None,
            'multimodal_fusion_enabled': self.complex_config.enable_multimodal_fusion,
            'config': {
                'use_enhanced_mode': self.complex_config.use_enhanced_mode,
                'min_graph_nodes': self.complex_config.min_graph_nodes,
                'fusion_strategy': self.complex_config.fusion_strategy,
                'fallback_enabled': self.complex_config.fallback_to_traditional
            }
        }
        
        base_stats['enhanced_info'] = enhanced_info
        return base_stats
    
    def switch_mode(self, mode: str) -> bool:
        """ÊâãÂä®ÂàáÊç¢Â§ÑÁêÜÊ®°Âºè"""
        if mode not in ['traditional', 'enhanced']:
            logger.error(f"‚ùå Êó†ÊïàÁöÑÂ§ÑÁêÜÊ®°Âºè: {mode}")
            return False
        
        if mode == 'enhanced' and not self.graph_encoder:
            logger.error("‚ùå GraphEncoderÊú™ÂêØÁî®ÔºåÊó†Ê≥ïÂàáÊç¢Âà∞Â¢ûÂº∫Ê®°Âºè")
            return False
        
        old_mode = self.current_mode
        self.current_mode = mode
        self.mode_switch_count += 1
        self.enhanced_stats['mode_switches'] += 1
        
        logger.info(f"üîÑ Ê®°ÂºèÂàáÊç¢: {old_mode} ‚Üí {mode}")
        return True
    
    def test_graph_encoder(self, test_data: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """ÊµãËØïGraphEncoderÂäüËÉΩ"""
        if not self.graph_encoder:
            return {'success': False, 'error': 'GraphEncoderÊú™ÂêØÁî®'}
        
        try:
            # ‰ΩøÁî®ÊµãËØïÊï∞ÊçÆÊàñÂàõÂª∫ÁÆÄÂçïÊµãËØïÂõæ
            if not test_data:
                test_data = {
                    'nodes': [
                        {'id': 'player_1', 'label': 'Player', 'name': 'Ê¢ÖË•ø'},
                        {'id': 'team_1', 'label': 'Team', 'name': 'Â∑¥Â°ûÁΩóÈÇ£'}
                    ],
                    'edges': [
                        {'source': 'player_1', 'target': 'team_1', 'relation': 'plays_for'}
                    ]
                }
            
            result = self.graph_encoder.encode_graph(test_data)
            
            return {
                'success': True,
                'test_result': result,
                'encoder_info': {
                    'model_type': type(self.graph_encoder).__name__,
                    'has_model': hasattr(self.graph_encoder, 'model')
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e)
            }


# =============================================================================
# Â∑•ÂéÇÂáΩÊï∞
# =============================================================================

def create_complex_g_processor(config_dict: Dict[str, Any]) -> ComplexGProcessor:
    """ÂàõÂª∫ComplexGProcessorÂÆû‰æã"""
    
    # ËΩ¨Êç¢ÈÖçÁΩÆ
    config = ComplexGProcessorConfig(
        processor_name=config_dict.get('processor_name', 'complex_g_processor'),
        cache_enabled=config_dict.get('cache_enabled', True),
        cache_ttl=config_dict.get('cache_ttl', 3600),
        max_tokens=config_dict.get('max_tokens', 4000),
        
        # ComplexGÁâπÂÆöÈÖçÁΩÆ
        use_enhanced_mode=config_dict.get('use_enhanced_mode', False),
        enable_multimodal_fusion=config_dict.get('enable_multimodal_fusion', False),
        graph_encoder_enabled=config_dict.get('graph_encoder_enabled', False),
        graph_encoder_config=config_dict.get('graph_encoder_config', {}),
        min_graph_nodes=config_dict.get('min_graph_nodes', 3),
        fusion_strategy=config_dict.get('fusion_strategy', 'concatenate'),
        fallback_to_traditional=config_dict.get('fallback_to_traditional', True),
        
        # ÁªÑ‰ª∂ÈÖçÁΩÆ
        retriever_config=config_dict.get('retriever_config'),
        graph_builder_config=config_dict.get('graph_builder_config'),
        textualizer_config=config_dict.get('textualizer_config')
    )
    
    return ComplexGProcessor(config)
