"""
RAG (æ£€ç´¢å¢å¼ºç”Ÿæˆ) æ ¸å¿ƒåŠŸèƒ½
"""
import os
import json
from typing import List, Dict, Any
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
from app.database import NebulaGraphConnection
from config import Config

class SimpleRAG:
    """ç®€å•çš„RAGå®ç°"""
    
    def __init__(self):
        """åˆå§‹åŒ–RAGç³»ç»Ÿ"""
        self.embedding_model = None
        self.knowledge_base = []
        self.embeddings = None
        self.nebula_conn = NebulaGraphConnection()
        
    def initialize(self):
        """åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®"""
        print("ğŸ”„ æ­£åœ¨åˆå§‹åŒ–RAGç³»ç»Ÿ...")
        
        # åˆå§‹åŒ–åµŒå…¥æ¨¡å‹
        try:
            print(f"ğŸ“¥ åŠ è½½åµŒå…¥æ¨¡å‹: {Config.EMBEDDING_MODEL}")
            self.embedding_model = SentenceTransformer(Config.EMBEDDING_MODEL)
            print("âœ… åµŒå…¥æ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ åµŒå…¥æ¨¡å‹åŠ è½½å¤±è´¥: {str(e)}")
            return False
            
        # è¿æ¥NebulaGraph
        if not self.nebula_conn.connect():
            print("âŒ NebulaGraphè¿æ¥å¤±è´¥")
            return False
            
        # æ„å»ºçŸ¥è¯†åº“
        self._build_knowledge_base()
        print("âœ… RAGç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        return True
        
    def _build_knowledge_base(self):
        """ä»NebulaGraphæ„å»ºçŸ¥è¯†åº“"""
        print("ğŸ—ï¸  æ­£åœ¨æ„å»ºçŸ¥è¯†åº“...")
        
        # è·å–çƒå‘˜ä¿¡æ¯
        players_query = """
        MATCH (p:player)
        RETURN p.player.name AS name, p.player.age AS age
        LIMIT 50
        """
        
        players_result = self.nebula_conn.execute_query(players_query)
        if players_result['success']:
            for row in players_result['rows']:
                name, age = row[0], row[1]
                text = f"çƒå‘˜ {name} çš„å¹´é¾„æ˜¯ {age} å²"
                self.knowledge_base.append({
                    'text': text,
                    'type': 'player_info',
                    'metadata': {'name': name, 'age': age}
                })
        
        # è·å–çƒé˜Ÿä¿¡æ¯
        teams_query = """
        MATCH (t:team)
        RETURN t.team.name AS name
        LIMIT 20
        """
        
        teams_result = self.nebula_conn.execute_query(teams_query)
        if teams_result['success']:
            for row in teams_result['rows']:
                team_name = row[0]
                text = f"çƒé˜Ÿ {team_name}"
                self.knowledge_base.append({
                    'text': text,
                    'type': 'team_info',
                    'metadata': {'name': team_name}
                })
        
        # è·å–å…³ç³»ä¿¡æ¯
        relations_query = """
        MATCH (p:player)-[s:serve]->(t:team)
        RETURN p.player.name AS player, t.team.name AS team
        LIMIT 30
        """
        
        relations_result = self.nebula_conn.execute_query(relations_query)
        if relations_result['success']:
            for row in relations_result['rows']:
                player_name, team_name = row[0], row[1]
                text = f"çƒå‘˜ {player_name} æ•ˆåŠ›äºçƒé˜Ÿ {team_name}"
                self.knowledge_base.append({
                    'text': text,
                    'type': 'player_team_relation',
                    'metadata': {'player': player_name, 'team': team_name}
                })
        
        print(f"ğŸ“š çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼Œå…±æ”¶é›† {len(self.knowledge_base)} æ¡ä¿¡æ¯")
        
        # ç”ŸæˆåµŒå…¥å‘é‡
        if self.knowledge_base:
            texts = [item['text'] for item in self.knowledge_base]
            print("ğŸ”¢ æ­£åœ¨ç”ŸæˆåµŒå…¥å‘é‡...")
            self.embeddings = self.embedding_model.encode(texts)
            print("âœ… åµŒå…¥å‘é‡ç”Ÿæˆå®Œæˆ")
    
    def retrieve(self, query: str, top_k: int = 5) -> List[Dict[str, Any]]:
        """æ£€ç´¢ç›¸å…³ä¿¡æ¯"""
        if not self.embedding_model or not self.embeddings.any():
            return []
        
        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode([query])
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(query_embedding, self.embeddings)[0]
        
        # è·å–top_kæœ€ç›¸ä¼¼çš„ç»“æœ
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = []
        for idx in top_indices:
            results.append({
                'text': self.knowledge_base[idx]['text'],
                'type': self.knowledge_base[idx]['type'],
                'metadata': self.knowledge_base[idx]['metadata'],
                'similarity': float(similarities[idx])
            })
        
        return results
    
    def answer_question(self, question: str) -> Dict[str, Any]:
        """å›ç­”é—®é¢˜"""
        print(f"ğŸ¤” é—®é¢˜: {question}")
        
        # æ£€ç´¢ç›¸å…³ä¿¡æ¯
        retrieved_docs = self.retrieve(question, top_k=3)
        
        if not retrieved_docs:
            return {
                'answer': 'æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°ç›¸å…³ä¿¡æ¯ã€‚',
                'sources': [],
                'confidence': 0.0
            }
        
        # ç®€å•çš„å›ç­”ç”Ÿæˆï¼ˆåŸºäºæ£€ç´¢åˆ°çš„ä¿¡æ¯ï¼‰
        relevant_info = []
        for doc in retrieved_docs:
            if doc['similarity'] > 0.3:  # ç›¸ä¼¼åº¦é˜ˆå€¼
                relevant_info.append(doc['text'])
        
        if relevant_info:
            answer = "æ ¹æ®æˆ‘çš„çŸ¥è¯†åº“ï¼Œæˆ‘æ‰¾åˆ°ä»¥ä¸‹ç›¸å…³ä¿¡æ¯ï¼š\n" + "\n".join(relevant_info)
            confidence = max([doc['similarity'] for doc in retrieved_docs])
        else:
            answer = "æŠ±æ­‰ï¼Œæˆ‘æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿç›¸å…³çš„ä¿¡æ¯æ¥å›ç­”æ‚¨çš„é—®é¢˜ã€‚"
            confidence = 0.0
        
        return {
            'answer': answer,
            'sources': retrieved_docs,
            'confidence': float(confidence)
        }
    
    def close(self):
        """å…³é—­è¿æ¥"""
        if self.nebula_conn:
            self.nebula_conn.close()

# å…¨å±€RAGå®ä¾‹
rag_system = SimpleRAG()
