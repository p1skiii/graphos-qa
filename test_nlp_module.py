#!/usr/bin/env python
"""
NLPæ¨¡å—åŠŸèƒ½æµ‹è¯•
æµ‹è¯•åˆšå®ç°çš„NLPç»„ä»¶åŠŸèƒ½
"""
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.insert(0, os.path.abspath('.'))

from app.core.schemas import QueryContextFactory
from app.services.nlp import NLPPipeline, create_default_nlp_pipeline

def test_individual_components():
    """æµ‹è¯•å„ä¸ªNLPç»„ä»¶çš„ç‹¬ç«‹åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•NLPç»„ä»¶ç‹¬ç«‹åŠŸèƒ½...")
    
    # åˆ›å»ºç®¡é“
    pipeline = create_default_nlp_pipeline()
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "How old is Kobe Bryant?",
        "What position does LeBron James play?", 
        "Who is taller, Michael Jordan or Yao Ming?",
        "I love basketball"
    ]
    
    for query in test_queries:
        print(f"\nğŸ“ æµ‹è¯•æŸ¥è¯¢: '{query}'")
        print("-" * 60)
        
        try:
            # æµ‹è¯•å„ç»„ä»¶
            component_results = pipeline.test_individual_components(query)
            
            # æ˜¾ç¤ºç»“æœ
            for component, result in component_results.items():
                print(f"ğŸ”§ {component}:")
                if "error" in result:
                    print(f"   âŒ é”™è¯¯: {result['error']}")
                else:
                    print(f"   âœ… ç»“æœ: {result}")
                    
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")

def test_full_pipeline():
    """æµ‹è¯•å®Œæ•´çš„NLPç®¡é“"""
    print("\n" + "="*80)
    print("ğŸ”„ æµ‹è¯•å®Œæ•´NLPç®¡é“...")
    
    # åˆ›å»ºç®¡é“
    pipeline = create_default_nlp_pipeline()
    
    # åˆå§‹åŒ–
    if not pipeline.initialize():
        print("âŒ NLPç®¡é“åˆå§‹åŒ–å¤±è´¥")
        return
    
    print("âœ… NLPç®¡é“åˆå§‹åŒ–æˆåŠŸ")
    
    # æµ‹è¯•æŸ¥è¯¢
    test_queries = [
        "How old is Kobe Bryant?",
        "What team does LeBron James play for?",
        "Who is the greatest basketball player?",
        "Compare Michael Jordan and Kobe Bryant"
    ]
    
    for query in test_queries:
        print(f"\nğŸ“ å¤„ç†æŸ¥è¯¢: '{query}'")
        print("-" * 60)
        
        try:
            # å®Œæ•´å¤„ç†
            result_context = pipeline.process_query(query)
            
            # æ˜¾ç¤ºç»“æœ
            print(f"ğŸ” è¯­è¨€æ£€æµ‹: {result_context.language_info.original_language if result_context.language_info else 'None'}")
            print(f"ğŸ”¤ åˆ†è¯æ•°é‡: {len(result_context.tokens) if hasattr(result_context, 'tokens') else 0}")
            
            if result_context.entity_info:
                print(f"ğŸ€ å®ä½“æå–:")
                print(f"   - çƒå‘˜: {result_context.entity_info.players}")
                print(f"   - å±æ€§: {result_context.entity_info.attributes}")
                print(f"   - ç›®æ ‡å®ä½“: {result_context.entity_info.target_entity}")
            
            if result_context.intent_info:
                print(f"ğŸ¯ æ„å›¾åˆ†ç±»:")
                print(f"   - æ„å›¾: {result_context.intent_info.intent}")
                print(f"   - ç½®ä¿¡åº¦: {result_context.intent_info.confidence:.2f}")
                print(f"   - å±æ€§ç±»å‹: {result_context.intent_info.attribute_type}")
                print(f"   - å¤æ‚åº¦: {result_context.intent_info.complexity}")
            
            # æ˜¾ç¤ºå¤„ç†è½¨è¿¹
            print(f"ğŸ“Š å¤„ç†è½¨è¿¹: {len(result_context.processing_trace)} æ­¥éª¤")
            for trace in result_context.processing_trace[-3:]:  # æ˜¾ç¤ºæœ€å3ä¸ªæ­¥éª¤
                print(f"   - {trace['component']}: {trace['action']}")
                
        except Exception as e:
            print(f"âŒ å¤„ç†å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

def test_core_integration():
    """æµ‹è¯•ä¸coreæ¨¡å—çš„é›†æˆ"""
    print("\n" + "="*80)
    print("ğŸ”— æµ‹è¯•ä¸Coreæ¨¡å—çš„é›†æˆ...")
    
    # åˆ›å»ºQueryContext
    context = QueryContextFactory.create("How old is Kobe Bryant?")
    print(f"âœ… åˆ›å»ºQueryContext: {context.request_id[:8]}...")
    
    # åˆ›å»ºNLPç®¡é“
    pipeline = create_default_nlp_pipeline()
    
    if not pipeline.initialize():
        print("âŒ åˆå§‹åŒ–å¤±è´¥")
        return
    
    # å¤„ç†
    try:
        result = pipeline.process(context)
        
        print(f"ğŸ¯ å¤„ç†ç»“æœ:")
        print(f"   - åŸå§‹æŸ¥è¯¢: {result.original_query}")
        print(f"   - è¯­è¨€: {result.language_info.original_language if result.language_info else 'unknown'}")
        print(f"   - æ„å›¾: {result.intent_info.intent if result.intent_info else 'unknown'}")
        print(f"   - çŠ¶æ€: {result.status}")
        print(f"   - å¤„ç†æ—¶é—´: {result.total_processing_time}")
        
        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        assert result.request_id == context.request_id, "RequestIDä¸åŒ¹é…"
        assert result.original_query == context.original_query, "åŸå§‹æŸ¥è¯¢ä¸åŒ¹é…"
        
        print("âœ… Coreé›†æˆæµ‹è¯•é€šè¿‡")
        
    except Exception as e:
        print(f"âŒ Coreé›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ NLPæ¨¡å—æµ‹è¯•å¼€å§‹")
    print("="*80)
    
    # ä¾èµ–æ£€æŸ¥
    try:
        import langdetect
        import spacy
        print("âœ… ä¾èµ–æ£€æŸ¥é€šè¿‡")
    except ImportError as e:
        print(f"âŒ ä¾èµ–ç¼ºå¤±: {e}")
        print("è¯·å®‰è£…å¿…è¦ä¾èµ–:")
        print("pip install langdetect spacy")
        print("python -m spacy download en_core_web_sm")
        return
    
    # è¿è¡Œæµ‹è¯•
    try:
        test_individual_components()
        test_full_pipeline()
        test_core_integration()
        
        print("\n" + "="*80)
        print("ğŸ‰ NLPæ¨¡å—æµ‹è¯•å®Œæˆ!")
        
    except Exception as e:
        print(f"\nâŒ æµ‹è¯•è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()
