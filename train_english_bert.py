#!/usr/bin/env python3
"""
è‹±æ–‡BERTæ„å›¾åˆ†ç±»å™¨è®­ç»ƒè„šæœ¬
ä½¿ç”¨æœ¬åœ°ä¸­æ–‡BERTæ¨¡åž‹ä½œä¸ºåŸºç¡€ï¼Œè®­ç»ƒè‹±æ–‡5ç±»æ•°æ®
"""

import torch
import pandas as pd
from transformers import (
    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,
    TrainingArguments, Trainer, EarlyStoppingCallback
)
from datasets import Dataset
from sklearn.metrics import accuracy_score, classification_report
from sklearn.model_selection import train_test_split
import numpy as np
import logging
from pathlib import Path
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class EnglishBERTTrainer:
    """è‹±æ–‡BERTè®­ç»ƒå™¨"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # 5ç±»æ„å›¾æ ‡ç­¾æ˜ å°„
        self.id2label = {
            0: "ATTRIBUTE_QUERY",        # å±žæ€§æŸ¥è¯¢
            1: "SIMPLE_RELATION_QUERY",  # ç®€å•å…³ç³»æŸ¥è¯¢  
            2: "COMPLEX_RELATION_QUERY", # å¤æ‚å…³ç³»æŸ¥è¯¢
            3: "COMPARATIVE_QUERY",      # æ¯”è¾ƒæŸ¥è¯¢
            4: "DOMAIN_CHITCHAT"         # é¢†åŸŸå†…é—²èŠ
        }
        self.label2id = {
            "ATTRIBUTE_QUERY": 0,
            "SIMPLE_RELATION_QUERY": 1, 
            "COMPLEX_RELATION_QUERY": 2,
            "COMPARATIVE_QUERY": 3,
            "DOMAIN_CHITCHAT": 4
        }
        
        logger.info(f"ðŸ’» è®¾å¤‡: {self.device}")
        
    def load_local_model(self, model_path="models/bert_intent_classifier_final"):
        """åŠ è½½æœ¬åœ°æ¨¡åž‹ä½œä¸ºåŸºç¡€"""
        
        logger.info(f"ðŸ“¥ åŠ è½½æœ¬åœ°æ¨¡åž‹: {model_path}")
        
        # åŠ è½½tokenizerï¼ˆä¿æŒä¸­æ–‡tokenizerï¼‰
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        
        # åŠ è½½configå¹¶ä¿®æ”¹ä¸º5ç±»
        config = AutoConfig.from_pretrained(model_path)
        config.num_labels = 5
        config.id2label = self.id2label
        config.label2id = self.label2id
        
        # é‡æ–°åˆå§‹åŒ–æ¨¡åž‹ï¼ˆåˆ†ç±»å¤´ä¼šè¢«é‡æ–°åˆå§‹åŒ–ï¼‰
        self.model = AutoModelForSequenceClassification.from_config(config)
        
        # åŠ è½½é¢„è®­ç»ƒæƒé‡ï¼ˆé™¤äº†åˆ†ç±»å¤´ï¼‰
        pretrained_model = AutoModelForSequenceClassification.from_pretrained(model_path)
        
        # å¤åˆ¶é™¤åˆ†ç±»å¤´ä»¥å¤–çš„æ‰€æœ‰æƒé‡
        model_dict = self.model.state_dict()
        pretrained_dict = pretrained_model.state_dict()
        
        # è¿‡æ»¤æŽ‰åˆ†ç±»å¤´çš„æƒé‡
        pretrained_dict = {k: v for k, v in pretrained_dict.items() 
                          if k in model_dict and 'classifier' not in k}
        
        model_dict.update(pretrained_dict)
        self.model.load_state_dict(model_dict)
        
        self.model.to(self.device)
        logger.info("âœ… æ¨¡åž‹åŠ è½½å®Œæˆï¼Œåˆ†ç±»å¤´å·²é‡æ–°åˆå§‹åŒ–ä¸º5ç±»")
        
    def tokenize_function(self, examples):
        """åˆ†è¯å‡½æ•°"""
        return self.tokenizer(
            examples['text'], 
            truncation=True, 
            padding=True, 
            max_length=128
        )
    
    def compute_metrics(self, eval_pred):
        """è®¡ç®—è¯„ä¼°æŒ‡æ ‡"""
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)
        
        accuracy = accuracy_score(labels, predictions)
        
        return {
            'accuracy': accuracy,
        }
    
    def load_data(self, csv_path):
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        
        logger.info(f"ðŸ“Š åŠ è½½è®­ç»ƒæ•°æ®: {csv_path}")
        df = pd.read_csv(csv_path)
        
        # æ•°æ®ç»Ÿè®¡
        logger.info(f"ðŸ“ˆ æ•°æ®ç»Ÿè®¡:")
        logger.info(f"   æ€»æ•°æ®é‡: {len(df)}")
        
        for label_id, label_name in self.id2label.items():
            count = (df['label'] == label_id).sum()
            logger.info(f"   {label_name}: {count} samples")
        
        # åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
        train_texts, test_texts, train_labels, test_labels = train_test_split(
            df['text'].tolist(),
            df['label'].tolist(),
            test_size=0.2,
            random_state=42,
            stratify=df['label']
        )
        
        # åˆ›å»ºDataset
        train_dataset = Dataset.from_dict({
            'text': train_texts,
            'labels': train_labels  # æ³¨æ„è¿™é‡Œæ˜¯'labels'ä¸æ˜¯'label'
        })
        
        test_dataset = Dataset.from_dict({
            'text': test_texts,
            'labels': test_labels
        })
        
        # åˆ†è¯å¤„ç†
        train_dataset = train_dataset.map(self.tokenize_function, batched=True)
        test_dataset = test_dataset.map(self.tokenize_function, batched=True)
        
        return train_dataset, test_dataset
    
    def train(self, csv_path, epochs=3, batch_size=16):
        """è®­ç»ƒæ¨¡åž‹"""
        
        # åŠ è½½æ¨¡åž‹
        self.load_local_model()
        
        # åŠ è½½æ•°æ®
        train_dataset, test_dataset = self.load_data(csv_path)
        
        # åˆ›å»ºè¾“å‡ºç›®å½•
        output_dir = Path("models/bert_english_5class")
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # è®­ç»ƒå‚æ•°
        training_args = TrainingArguments(
            output_dir=str(output_dir),
            num_train_epochs=epochs,
            per_device_train_batch_size=batch_size,
            per_device_eval_batch_size=batch_size,
            warmup_steps=50,
            weight_decay=0.01,
            logging_dir="results/logs",
            logging_steps=10,
            evaluation_strategy="epoch",
            save_strategy="epoch",
            load_best_model_at_end=True,
            metric_for_best_model="eval_accuracy",
            greater_is_better=True,
            save_total_limit=2,
            seed=42
        )
        
        # åˆ›å»ºè®­ç»ƒå™¨
        trainer = Trainer(
            model=self.model,
            args=training_args,
            train_dataset=train_dataset,
            eval_dataset=test_dataset,
            compute_metrics=self.compute_metrics,
            callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]
        )
        
        # å¼€å§‹è®­ç»ƒ
        logger.info("â³ å¼€å§‹è®­ç»ƒ...")
        trainer.train()
        
        # ä¿å­˜æœ€ç»ˆæ¨¡åž‹
        final_model_path = Path("models/bert_english_5class_final")
        final_model_path.mkdir(parents=True, exist_ok=True)
        
        self.model.save_pretrained(str(final_model_path))
        self.tokenizer.save_pretrained(str(final_model_path))
        
        logger.info(f"ðŸ’¾ æ¨¡åž‹å·²ä¿å­˜åˆ°: {final_model_path}")
        
        # è¯„ä¼°
        eval_results = trainer.evaluate()
        logger.info(f"ðŸ“Š æœ€ç»ˆè¯„ä¼°ç»“æžœ: {eval_results}")
        
        # ä¿å­˜è¯„ä¼°ç»“æžœ
        results_file = Path("results/evaluations/english_5class_results.json")
        results_file.parent.mkdir(parents=True, exist_ok=True)
        
        with open(results_file, 'w') as f:
            json.dump(eval_results, f, indent=2)
        
        return trainer, eval_results
    
    def test_examples(self):
        """æµ‹è¯•ç¤ºä¾‹"""
        
        test_cases = [
            "How old is Yao Ming?",                           # ATTRIBUTE_QUERY
            "Which team does LeBron James play for?",         # SIMPLE_RELATION_QUERY  
            "What's Kobe's height?",                          # ATTRIBUTE_QUERY
            "Who is better, LeBron James or Kobe Bryant?",    # COMPARATIVE_QUERY
            "Which city are the Lakers located in?",         # ATTRIBUTE_QUERY
            "Analyze the Lakers' historical achievements",    # COMPLEX_RELATION_QUERY
            "What do you think about basketball?",            # DOMAIN_CHITCHAT
            "List all MVP players who played with Shaq",     # COMPLEX_RELATION_QUERY
        ]
        
        logger.info("ðŸ§ª æµ‹è¯•ç¤ºä¾‹:")
        
        for text in test_cases:
            # åˆ†è¯
            inputs = self.tokenizer(text, return_tensors="pt", 
                                  truncation=True, padding=True, max_length=128)
            inputs = {k: v.to(self.device) for k, v in inputs.items()}
            
            # é¢„æµ‹
            with torch.no_grad():
                outputs = self.model(**inputs)
                logits = outputs.logits
                probs = torch.softmax(logits, dim=-1)
                
                predicted_id = torch.argmax(probs, dim=-1).item()
                confidence = probs[0][predicted_id].item()
                predicted_label = self.id2label[predicted_id]
                
                logger.info(f"   '{text}' -> {predicted_label} ({confidence:.3f})")

if __name__ == "__main__":
    trainer = EnglishBERTTrainer()
    
    # è®­ç»ƒ
    csv_path = "data/training/english_fine_grained_training_dataset.csv"
    model_trainer, results = trainer.train(csv_path, epochs=5)
    
    # æµ‹è¯•
    trainer.test_examples()
